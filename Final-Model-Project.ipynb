{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jp-ishimwe/Projects/blob/master/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mC1GOaVUZ0tj"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install transformers==3.0.2 \n",
    "#!pip install transformers -q\n",
    "#!pip install wandb -q\n",
    "!pip3 install --upgrade wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "vxxkIi-xDrUz",
    "outputId": "3089c626-558c-4033-df7a-4a87e7c3743a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "#@title Import packages { run: \"auto\", vertical-output: true, display-mode: \"both\" }\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "\n",
    "from collections import defaultdict, OrderedDict\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import progressbar\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "#import dill\n",
    "import tarfile\n",
    "import json, gzip\n",
    "from typing import Optional, Union, Iterable, NamedTuple\n",
    "import math\n",
    "from typing import Optional, Union, Iterable, NamedTuple, Dict\n",
    "\n",
    "\n",
    "#!pip install transformers==3.0.2 -qq\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "from transformers.modeling_t5 import T5Stack, T5LayerCrossAttention, T5Block, T5Attention\n",
    "\n",
    "# Ignore excessive warnings\n",
    "import logging\n",
    "logging.propagate = False \n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed():\n",
    "    SEED = 123\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "LME26NCmM8ne",
    "outputId": "70fadb92-ca06-4952-aa13-baf78a7f8000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting the environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'Final-Model-Project.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-t7E9fLj8Zjd"
   },
   "outputs": [],
   "source": [
    "#!cp '/root/optimizers.py' '/root/Projects/' # SSH\n",
    "#!cp '/home/jupyter/optimizers.py' '/home/jupyter/Projects/' # for GCP\n",
    "#!cp '/content/drive/My Drive/Colab Notebooks/optimizers.py' .\n",
    "#from optimizers import AdaFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "colab_type": "code",
    "id": "7rF67H7GnK2U",
    "outputId": "73b7b959-b7c0-46b0-dfab-5d17f41d8b1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 23 12:50:12 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P8    27W / 149W |     11MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!/usr/local/cuda/bin/nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1g1xKdoCnMAq",
    "outputId": "eb74740f-11c0-4e87-86c3-ab1bcc3a6255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#@title To proceed should be cuda { run: \"auto\", vertical-output: true }\n",
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jvIoL5I0Eb5"
   },
   "source": [
    "## Getting dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wGVOHhrk0GOP"
   },
   "source": [
    "You can find the dataset [here](http://lil.nlp.cornell.edu/newsroom/download/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkDYkbKV0SUM"
   },
   "source": [
    "**Loading dataset and unzip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AoIiFXg1juKC"
   },
   "outputs": [],
   "source": [
    "fname = '/content/drive/My Drive/Colab Notebooks/newsroom-release.tar'\n",
    "\n",
    "tar = tarfile.open(fname, \"r:\")\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1YuQmBQpP3C7"
   },
   "outputs": [],
   "source": [
    "!mv '/content/data/' '/content/drive/My Drive/Colab Notebooks'\n",
    "!cp -r '/content/release/' '/content/drive/My Drive/Colab Notebooks/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Z9YGB5TmYqR"
   },
   "outputs": [],
   "source": [
    "#path = '/home/jupyter/' # For GCp\n",
    "path = '/root/release/' # For SSH\n",
    "#path = \"/content/drive/My Drive/Colab Notebooks/data/release/\" # For Colab\n",
    "\n",
    "def read_data(path, name):\n",
    "  data = []\n",
    "  with gzip.open(path + name + \".jsonl.gz\") as f: #+\".jsonl.gz\" with GCP\n",
    "      for ln in f:\n",
    "          obj = json.loads(ln)\n",
    "          data.append(obj)\n",
    "  return data\n",
    "\n",
    "trainset = read_data(path, 'train') \n",
    "devset = read_data(path, 'dev')\n",
    "testset = read_data(path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gv1SfBCrIaW4"
   },
   "outputs": [],
   "source": [
    "def get_data(data):\n",
    "  data_dict = {'text': [], 'summary': []}\n",
    "  for article in data:\n",
    "    data_dict['text'].append(article['text'])\n",
    "    data_dict['summary'].append(article['summary'])\n",
    "  return pd.DataFrame(data_dict)\n",
    "\n",
    "train_data = get_data(trainset)\n",
    "valid_data = get_data(devset)\n",
    "test_data = get_data(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "id": "k3sSaZA_Z0ul",
    "outputId": "56ff0a7d-bb37-4fc0-88f6-1d37b35dfee6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAMBURG, Germany, June 3  As he left the socc...</td>\n",
       "      <td>A surge in discriminatory behavior toward blac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WASHINGTON, Dec. 23 - The National Security Ag...</td>\n",
       "      <td>The volume of information harvested, without \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IF outsized executive pay has indeed become a ...</td>\n",
       "      <td>The battle between Pfizer Inc.'s investors and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BY A.J. BENZA &amp; MICHAEL LEWITTES\\n\\nIf Simon R...</td>\n",
       "      <td>If Simon Rex looks a little familiar, it may n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spinach has terrorized generations of veggie-p...</td>\n",
       "      <td>POPEYE-WORTHY PIE. PHYLLO DOUGH WRAPS SPINACH ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                                            summary\n",
       "0  HAMBURG, Germany, June 3  As he left the socc...  A surge in discriminatory behavior toward blac...\n",
       "1  WASHINGTON, Dec. 23 - The National Security Ag...  The volume of information harvested, without \\...\n",
       "2  IF outsized executive pay has indeed become a ...  The battle between Pfizer Inc.'s investors and...\n",
       "3  BY A.J. BENZA & MICHAEL LEWITTES\\n\\nIf Simon R...  If Simon Rex looks a little familiar, it may n...\n",
       "4  Spinach has terrorized generations of veggie-p...  POPEYE-WORTHY PIE. PHYLLO DOUGH WRAPS SPINACH ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eia69USAvek8",
    "outputId": "5de67e80-2788-4f05-ba70-f3e43ca044ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of training dataset:(995041, 2) | validation dataset: (108837, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'The size of training dataset:{train_data.shape} | validation dataset: {valid_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JX6clAc9wHuy"
   },
   "outputs": [],
   "source": [
    "contraction = {\"isn't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you ll\":\"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you re\": \"you are\" , \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E38ktgfStkI9"
   },
   "source": [
    "###### Checking for NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "b-NTfClirfL3",
    "outputId": "10a3b951-f509-471f-9549-dae2a8f265d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(text       0\n",
       " summary    0\n",
       " dtype: int64, text       0\n",
       " summary    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum(), valid_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0HQ2wJrXEAcr"
   },
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6_qmLtaZp9s0"
   },
   "outputs": [],
   "source": [
    "class TextProccessing(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, column, contraction):\n",
    "    self.column = column\n",
    "    self.contraction = contraction\n",
    "  def fit(self, x, y=None):\n",
    "    return self\n",
    "  @staticmethod\n",
    "  def preprocessing(line):\n",
    "    date_pattern = r'(0?[1-9]/|1[0-2]/)(0?[1-9]/|[1-2][0-9]/|3[0-1]/)[0-9]{4}'\n",
    "    line = line.split(\"\\n\")\n",
    "    clean_line = []\n",
    "    for l in line:\n",
    "        if re.match(date_pattern, l) is not None:\n",
    "            pass\n",
    "        else:\n",
    "            clean_line.append(l)\n",
    "    line = \"\\n\".join(clean_line)\n",
    "\n",
    "    line = re.sub(r\"http\\S+\", \" \",line)\n",
    "    line = re.sub(r\"www\\S+\", \" \",line)\n",
    "    line = line.replace('—', ' ')\n",
    "    line = line.replace('-', ' ')\n",
    "    line = line.replace('&', 'and')\n",
    "    line = line.replace('[...]', '')\n",
    "    line = line.replace('...', '.')\n",
    "    line = line.replace('…', ' ')\n",
    "    line = re.sub(re.compile('<.*?>'), '', line)\n",
    "    line = re.sub(re.compile('@\\S+'), r'', line)\n",
    "    line = re.sub(r'#\\S+ ', r'', line)\n",
    "    line = line.replace(\"â\", \"'\") \n",
    "    line = line.replace('--', ' ')\n",
    "    line = re.sub(r'[^\\sa-zA-Z0-9.,!?]',' ',line)\n",
    "    line = line.strip()\n",
    "    line = line.replace(\"\\xa0\", \"\")\n",
    "    line = line.replace(\"click to share on twitter\", \"\")\n",
    "\n",
    "    line = re.sub(r'[ \\t]{2,}',' ', line)\n",
    "    return line\n",
    "\n",
    "  def transform(self, X):\n",
    "    return X[self.column].replace(self.contraction).fillna('').apply(lambda x: self.preprocessing(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m-XAtbFVI24a"
   },
   "outputs": [],
   "source": [
    "class Processor:\n",
    "\n",
    "  def __init__(self, data, \n",
    "               contraction,\n",
    "               max_length = None):\n",
    "    \n",
    "    self.max_length = max_length\n",
    "    self.data = data\n",
    "    self.contraction = contraction\n",
    "\n",
    "    \n",
    "  def cleaning(self, data):\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "      raise TypeError('Only Dataframes are allowed, but got data={}'.format(data))\n",
    "    else:\n",
    "      print('Please wait, we are cleaning...')\n",
    "      titles = ['text', 'summary']\n",
    "      data_dict = {}\n",
    "\n",
    "      for title in titles:\n",
    "        proc = TextProccessing(title, self.contraction)\n",
    "        res = proc.fit_transform(data)\n",
    "        data_dict[title] = res\n",
    "\n",
    "      ss = pd.DataFrame(data_dict)\n",
    "      \n",
    "      return ss\n",
    "\n",
    "  @staticmethod\n",
    "  def split(data):\n",
    "    return len(data.split())\n",
    "\n",
    "  def get_max_tokens(self, dataframe):\n",
    "\n",
    "    dataframe['article_len'] = dataframe['text'].apply(self.split)\n",
    "    dataframe['summary_len'] = dataframe['summary'].apply(self.split)\n",
    "    \n",
    "    max_len = {'max_article_tokens': max(dataframe['article_len']), \n",
    "                'min_article_tokens': min(dataframe['article_len']),\n",
    "                'max_summary_tokens': max(dataframe['summary_len']),\n",
    "                'min_summary_tokens': min(dataframe['summary_len'])}\n",
    "    return max_len, dataframe\n",
    "\n",
    "  def cleaned_data(self):\n",
    "    dataframe = self.cleaning(self.data)\n",
    "    \n",
    "    if self.max_length is None:\n",
    "      min_len, dataframe = self.get_max_tokens(dataframe)\n",
    "    else:\n",
    "      min_len = self.max_length\n",
    "\n",
    "    min_length = min_len['min_article_tokens']\n",
    "    idx_list = []\n",
    "    for idx, paragraph in tqdm(enumerate(dataframe['text'])):\n",
    "        pragraph = len(paragraph.split())\n",
    "        if pragraph < min_length:\n",
    "          idx_list.append(idx)\n",
    "    final_data = dataframe.drop(idx_list)\n",
    "    final_data = final_data.reset_index(drop=True)\n",
    "    \n",
    "    if self.max_length is not None:\n",
    "        min_len, final_data = self.get_max_tokens(final_data)\n",
    "\n",
    "    print('Done!')\n",
    "    \n",
    "    return final_data, min_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bNRiUhXoVkvY"
   },
   "outputs": [],
   "source": [
    "maxlen = {'max_article_tokens': 512,\n",
    "          'max_summary_tokens': 300,\n",
    "          'min_article_tokens': 100,\n",
    "          'min_summary_tokens': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oBiSvEkhz2ol",
    "outputId": "1e7a03cb-5f67-456c-e00c-5cca001aad15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait, we are cleaning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "995041it [00:31, 31844.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "textproc = Processor(train_data, contraction, maxlen)\n",
    "train_processed, doc_lengths = textproc.cleaned_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AeW5BNIkZ0u7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait, we are cleaning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "108837it [00:03, 32442.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "textproc = Processor(valid_data, contraction, maxlen)\n",
    "valid_processed, valid_doc_lengths = textproc.cleaned_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed.to_pickle(\"./train_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_processed.to_pickle(\"./valid_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "MNmq9Mgx_BNx",
    "outputId": "76787690-88a2-49c8-eed6-de45a698b67f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 951381 entries, 0 to 951380\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   text         951381 non-null  object\n",
      " 1   summary      951381 non-null  object\n",
      " 2   article_len  951381 non-null  int64 \n",
      " 3   summary_len  951381 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 29.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_processed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ko-HBLqNZ0vA"
   },
   "source": [
    "Only one article droped that was having zeros length. However we still have some article with no summaries. Therefore we can get rid off them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading pre-processed data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "ngCA4TwV1YBW",
    "outputId": "35a242e0-e94a-434d-e6ab-2f4dcaf6022d"
   },
   "outputs": [],
   "source": [
    "train_processed = pd.read_pickle(\"./train_processed.pkl\")\n",
    "valid_processed = pd.read_pickle(\"./valid_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6jOAe_ZbZ0vD"
   },
   "outputs": [],
   "source": [
    "indices = np.where(train_processed['summary_len'] < 10)\n",
    "train_processed_data = train_processed.drop(indices[0])\n",
    "train_processed_data = train_processed_data.reset_index(drop=True)\n",
    "#train_processed.iloc[indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tcp3ytvbZ0vF"
   },
   "outputs": [],
   "source": [
    "#train_data.iloc[954753]['summary'] # '<ul>\\n\\t<li><b>£', 'Ø¨Ø§ Ø§Û\\x8cÙ\\x86 Ø§Ø\\xadØ³Ø§Ø³ Ø¯Ø±Ù\\x85Ø§Ù\\x86Ø¯Ú¯Û\\x8cØ\\x8c Ø¨Ù\\x87 Ù\\x86Ø¸Ø±Øª Ù\\x85Û\\x8câ\\x80\\x8fØ±Ø³Ø¯ Ú©Ù\\x87 ØªØ\\xadØ±Û\\x8cÙ\\x85â\\x80\\x8fÙ\\x87Ø§ Ø¯Ø§Ø±Ù\\x86Ø¯ Ú©Ø§Ø± Ù\\x85Û\\x8câ\\x80\\x8fÚ©Ù\\x86Ù\\x86Ø¯'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m3FQWdFDZ0vK",
    "outputId": "25b1562f-26fc-4abb-b594-65e3be8cdd6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 882676 entries, 0 to 882675\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   text         882676 non-null  object\n",
      " 1   summary      882676 non-null  object\n",
      " 2   article_len  882676 non-null  int64 \n",
      " 3   summary_len  882676 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 26.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_processed_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "x9chLqw-PK9e",
    "outputId": "e2cebd34-52fa-4767-d432-c8b0c9af6d9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000     24.0\n",
       "0.7500     31.0\n",
       "0.9000     44.0\n",
       "0.9500     58.0\n",
       "0.9900    141.0\n",
       "0.9990    343.0\n",
       "0.9999    663.0\n",
       "Name: summary_len, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed_data['summary_len'].quantile([0.5, 0.75, 0.9, 0.95, 0.99, 0.999, 0.9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "hBlW5wqJpmJK",
    "outputId": "7a8991bf-5f84-4e1a-9a00-e071c1ee35e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1000      192.000\n",
       "0.2500      322.000\n",
       "0.4000      465.000\n",
       "0.5000      574.000\n",
       "0.7500      890.000\n",
       "0.9000     1237.000\n",
       "0.9500     1575.000\n",
       "0.9900     3206.250\n",
       "0.9990     8660.600\n",
       "0.9999    23091.975\n",
       "Name: article_len, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed_data['article_len'].quantile([0.1,0.25,0.4,0.5, 0.75, 0.9, 0.95, 0.99, 0.999, 0.9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kv13R15mZ0vR",
    "outputId": "65161116-70d3-47cb-891a-6ab9b410c845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104147 entries, 0 to 104146\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   text         104147 non-null  object\n",
      " 1   summary      104147 non-null  object\n",
      " 2   article_len  104147 non-null  int64 \n",
      " 3   summary_len  104147 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "valid_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lAWgJ8x4Z0vW"
   },
   "outputs": [],
   "source": [
    "inds = np.where(valid_processed['summary_len'] < 10)\n",
    "valid_processed_data = valid_processed.drop(inds[0])\n",
    "valid_processed_data = valid_processed_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7yoTzCmZ0vZ",
    "outputId": "5a1ff212-0dbf-403f-8b94-fe2078e9104a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96581 entries, 0 to 96580\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   text         96581 non-null  object\n",
      " 1   summary      96581 non-null  object\n",
      " 2   article_len  96581 non-null  int64 \n",
      " 3   summary_len  96581 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "valid_processed_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nMUVVJVZ0vc",
    "outputId": "d29ff526-5af4-4521-f8c4-bea7da5bd62d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000      571.000\n",
       "0.7500      885.000\n",
       "0.9000     1228.000\n",
       "0.9500     1568.000\n",
       "0.9900     3119.600\n",
       "0.9990     8641.460\n",
       "0.9999    22122.936\n",
       "Name: article_len, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_processed_data['article_len'].quantile([0.5, 0.75, 0.9, 0.95, 0.99, 0.999, 0.9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70NxcZwHZ0ve",
    "outputId": "23d8a423-31aa-4394-abdc-9c85a4b93123"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000     24.000\n",
       "0.7500     31.000\n",
       "0.9000     45.000\n",
       "0.9500     60.000\n",
       "0.9900    146.000\n",
       "0.9990    364.000\n",
       "0.9999    724.234\n",
       "Name: summary_len, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_processed_data['summary_len'].quantile([0.5, 0.75, 0.9, 0.95, 0.99, 0.999, 0.9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bFFt1a_35GZR",
    "outputId": "f0e6781d-9141-4f4b-d915-9c6d5000a5dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "art len:700, sum len:250\n"
     ]
    }
   ],
   "source": [
    "art = 700 #int(train_processed_data['article_len'].quantile(0.9900))\n",
    "sum_ = 250# int(train_processed_data['summary_len'].quantile(0.9900))\n",
    "\n",
    "print(f'art len:{art}, sum len:{sum_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dxo2FbB0Z0vj",
    "outputId": "ea4b1e36-8de2-4621-f5b1-4d61bb65c352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "art len:700, sum len:250\n"
     ]
    }
   ],
   "source": [
    "artV = 700 #int(valid_processed_data['article_len'].quantile(0.9900))\n",
    "sumV = 250# int(valid_processed_data['summary_len'].quantile(0.9900))\n",
    "\n",
    "print(f'art len:{artV}, sum len:{sumV}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dtuTFeLttppa"
   },
   "source": [
    "#### Creating Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYEBtk-Ctyy4"
   },
   "outputs": [],
   "source": [
    "class CustomDataReader(Dataset):\n",
    "  \"\"\"\n",
    "  Loading data to be used in pytorch pre-trained models\n",
    "  \n",
    "  \"\"\"\n",
    "  def __init__(self, dataframe, T5tokenizer, max_article_tokens=None,max_summary_tokens=None ):\n",
    "    self.tokenizer = T5tokenizer\n",
    "    self.dataframe = dataframe\n",
    "    self.eos = ' </s>'  #tokenizer.eos_token\n",
    "    self.sos = '<pad> ' #tokenizer.pad_token\n",
    "    self.source_len = max_article_tokens\n",
    "    self.target_len = max_summary_tokens\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.dataframe)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    articles = \"summarize: \" + self.dataframe.text[idx] + self.eos\n",
    "    articles = ' '.join(articles.split())\n",
    "\n",
    "    summary = self.sos + self.dataframe.summary[idx] + self.eos\n",
    "    summary = ' '.join(summary.split())\n",
    "\n",
    "    source_tokenized = self.tokenizer.batch_encode_plus([articles], max_length= self.source_len, pad_to_max_length=True, truncation=True,return_tensors='pt')\n",
    "    target_tokenized = self.tokenizer.batch_encode_plus([summary], max_length= self.target_len, pad_to_max_length=True, truncation=True,return_tensors='pt')\n",
    "\n",
    "    source_ids = source_tokenized['input_ids'].squeeze(0)\n",
    "    source_mask = source_tokenized['attention_mask'].squeeze(0)\n",
    "\n",
    "    summary_ids = target_tokenized['input_ids'].squeeze(0)\n",
    "    summary_mask = target_tokenized['attention_mask'].squeeze(0)\n",
    "\n",
    "    return source_ids, source_mask, summary_ids, summary_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqfiCrePYQIK"
   },
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hQwJS66iz0uS"
   },
   "outputs": [],
   "source": [
    "def training(model, dataset_loader, optimizer,log_interval,regularizer, eps_sched=None, batchs=None,epoch=0):\n",
    "\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    nItem = 0\n",
    "\n",
    "\n",
    "    print(f'\\nStart training for epoch: {epoch}')\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    tqdok = tqdm(dataset_loader, total=len(dataset_loader))\n",
    " \n",
    "    for idx, data_train in enumerate(tqdok):\n",
    "\n",
    "        input_ids, source_mask, summary_ids, summary_mask = data_train\n",
    "\n",
    "        input_ids = input_ids.to(device, dtype = torch.long)\n",
    "        source_mask = source_mask.to(device, dtype = torch.float)\n",
    "        summary_ids = summary_ids.to(device, dtype = torch.long)\n",
    "\n",
    "        target_labels = summary_ids[:, :-1].contiguous()\n",
    "        langm_labels = summary_ids[:, 1:].clone().detach()\n",
    "        langm_labels[summary_ids[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(input_ids=input_ids, attention_mask = source_mask, decoder_input_ids=target_labels, labels=langm_labels, lambd=regularizer)\n",
    "\n",
    "        loss = output[0]\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = input_ids.size(0)\n",
    "        nItem += bs\n",
    "        \n",
    "        # Before next loop: anneal optimizer variables \n",
    "        \n",
    "        if eps_sched is not None and  batchs is not None:\n",
    "            itr = epoch*(len(dataset_loader.dataset)//batchs) + idx\n",
    "            optimizer.param_groups[0]['eps'] = eps_sched[itr]\n",
    "\n",
    "        avg_loss += loss.item() * bs\n",
    "\n",
    "        if idx%log_interval == 0:\n",
    "            wandb.log({\"Training Loss\": loss.item()})\n",
    "#         if idx % 5000 == 0:\n",
    "#             print(f'[{idx * len(input_ids)}/{len(dataset_loader.dataset)} ({100. * idx / len(dataset_loader):.0f})%] \\t Training loss: {loss:.3f}')\n",
    "   \n",
    "\n",
    "        losses.update(loss.item(), bs)\n",
    "        tqdok.set_postfix(loss=losses.avg)\n",
    "        \n",
    "    avg_loss /= nItem\n",
    "  \n",
    "    return avg_loss, output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYQaqTmxRtzQ"
   },
   "outputs": [],
   "source": [
    "def validation(model, dataset_loader, regularizer):\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss = 0\n",
    "    nItem = 0\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    tqdok = tqdm(dataset_loader, total=len(dataset_loader))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data_val in enumerate(tqdok):\n",
    "            input_ids, source_mask, summary_ids, summary_mask = data_val\n",
    "\n",
    "            input_ids = input_ids.to(device, dtype = torch.long)\n",
    "            source_mask = source_mask.to(device, dtype = torch.float)\n",
    "            summary_ids = summary_ids.to(device, dtype = torch.long)\n",
    "\n",
    "            target_labels = summary_ids[:, :-1].contiguous()\n",
    "            langm_labels = summary_ids[:, 1:].clone().detach()\n",
    "            langm_labels[summary_ids[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "            output = model(input_ids=input_ids, attention_mask = source_mask, decoder_input_ids=target_labels, labels=langm_labels, lambd=regularizer)\n",
    "\n",
    "            loss = output[0]\n",
    "\n",
    "            bs = input_ids.size(0)\n",
    "            nItem += bs\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            losses.update(loss.item(), bs)\n",
    "            tqdok.set_postfix(loss=losses.avg)\n",
    "\n",
    "    eval_loss /= nItem\n",
    "\n",
    "    return eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h5ZhapbZawXG"
   },
   "outputs": [],
   "source": [
    "def saving(PATH, epoch, optm, model, LEARNING_RATE):\n",
    "  torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optm.state_dict(),\n",
    "            'learning_rate': LEARNING_RATE\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZsdXt4STdroJ"
   },
   "source": [
    "#### The model evaluation\n",
    "\n",
    "The perplexity:\n",
    "\n",
    "\\begin{align}\n",
    "\\large \\text{ppl}(p, D) &\\large = 2^{-\\frac{1}{N_{total}}\\log_2 p(D)}\n",
    "\\end{align}\n",
    "\n",
    "where $D=\\{(w_1,\\ldots,w_{N_i})_i\\}_{i=1}^M$ is a dataset of $M$ sequences with total length $N_{\\text{total}}=\\sum_{i}N_i$.\n",
    "\n",
    "\n",
    "#### Computing perplexity\n",
    "\n",
    "Our model's loss is the (negative) log probability of every token in the output sequence, which can be used to compute perplexity.\n",
    "\n",
    "We define perplexity using the **base 2** logarithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FarmceVkcm-Y"
   },
   "outputs": [],
   "source": [
    "def get_perplexity(epoc_loss):\n",
    "  rs = epoc_loss/np.log(2)\n",
    "  pp = 2**rs\n",
    "  return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "eDlcT25-F-sO"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c402aef8d548ca8e28206a70ea9234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d7e652df4d4c6eb05ce86c350778bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891691430.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f277cc3e60f64d1a91b587a29dbd8b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#@title #### Loading T5 model and its Tokenizer { run: \"auto\" }\n",
    "\n",
    "LEARNING_RATE = 3.55e-4\n",
    "MODEL_NAME = 't5-base' # or T5-Large:770 params, T5-3B, T5-Base: 220 Params, T5-11B\n",
    "t5model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedFilterLayer(nn.Module):\n",
    "  r\"\"\"\n",
    "  Receives the keys from the encoder output.\n",
    "\n",
    "  Returns:\n",
    "    Output the values between [0,1]\n",
    "   \"\"\"\n",
    "\n",
    "  def __init__(self, config ):\n",
    "    super(GatedFilterLayer, self).__init__()\n",
    "\n",
    "    self.d_kv = config.d_kv\n",
    "    self.n_heads = config.num_heads\n",
    "    self.projector = nn.Linear(self.d_kv, 1,bias=False)\n",
    "\n",
    "  def forward(self, last_hidden_encoder):\n",
    "    \n",
    "    bs = last_hidden_encoder.shape[0]\n",
    "    keys = last_hidden_encoder.view(bs, -1, self.n_heads, self.d_kv).transpose(1, 2)\n",
    "    proj = self.projector(keys)\n",
    "    gate = torch.sigmoid(proj)\n",
    "\n",
    "    return gate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderStack(T5Stack):\n",
    "\n",
    "  def __init__(self,config, embed_tokens=None):\n",
    "    super().__init__(config)\n",
    "\n",
    "    self.embed_tokens = embed_tokens \n",
    "    self.is_decoder = config.is_decoder\n",
    "    self.config = config\n",
    "    self.gatefilter = GatedFilterLayer(config)\n",
    "\n",
    "  def forward(self, \n",
    "              input_ids=None,\n",
    "              attention_mask=None,\n",
    "              encoder_hidden_states=None,\n",
    "              encoder_attention_mask=None,\n",
    "              inputs_embeds=None,\n",
    "              head_mask=None,\n",
    "              past_key_value_states=None,\n",
    "              use_cache=False,\n",
    "              output_attentions=None,\n",
    "              output_hidden_states=None,\n",
    "          ):\n",
    "    \n",
    "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "            input_ids = input_ids.view(-1, input_shape[-1])\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            if self.is_decoder:\n",
    "                raise ValueError(\"You have to specify either decoder_input_ids or decoder_inputs_embeds\")\n",
    "            else:\n",
    "                raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            assert self.embed_tokens is not None, \"You have to intialize the model with valid token embeddings\"\n",
    "            inputs_embeds = self.embed_tokens(input_ids)\n",
    "\n",
    "        batch_size, seq_length = input_shape\n",
    "\n",
    "        if past_key_value_states is not None:\n",
    "            assert seq_length == 1, \"Input shape is {}, but should be {} when using past_key_value_sates\".format(\n",
    "                input_shape, (batch_size, 1)\n",
    "            )\n",
    "            # required mask seq length can be calculated via length of past\n",
    "            # key value states and seq_length = 1 for the last token\n",
    "            mask_seq_length = past_key_value_states[0][0].shape[2] + seq_length\n",
    "        else:\n",
    "            mask_seq_length = seq_length\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(batch_size, mask_seq_length).to(inputs_embeds.device)\n",
    "        if self.is_decoder and encoder_attention_mask is None and encoder_hidden_states is not None:\n",
    "            encoder_seq_length = encoder_hidden_states.shape[1]\n",
    "            encoder_attention_mask = torch.ones(\n",
    "                batch_size, encoder_seq_length, device=inputs_embeds.device, dtype=torch.long\n",
    "            )\n",
    "\n",
    "        # initialize past_key_value_states with `None` if past does not exist\n",
    "        if past_key_value_states is None:\n",
    "            past_key_value_states = [None] * len(self.block)\n",
    "\n",
    "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "        extended_attention_mask = self.get_extended_attention_mask(attention_mask, input_shape, inputs_embeds.device)\n",
    "\n",
    "        if self.is_decoder and encoder_attention_mask is not None:\n",
    "            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        head_mask = self.get_head_mask(head_mask, self.config.num_layers)\n",
    "        present_key_value_states = ()\n",
    "        all_hidden_states = ()\n",
    "        all_attentions = ()\n",
    "        position_bias = None\n",
    "        encoder_decoder_position_bias = None\n",
    "\n",
    "        hidden_states = self.dropout(inputs_embeds)\n",
    "\n",
    "        for i, (layer_module, past_key_value_state) in enumerate(zip(self.block, past_key_value_states)):\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            layer_outputs = layer_module(\n",
    "                hidden_states,\n",
    "                attention_mask=extended_attention_mask,\n",
    "                position_bias=position_bias,\n",
    "                encoder_hidden_states=encoder_hidden_states,\n",
    "                encoder_attention_mask=encoder_extended_attention_mask,\n",
    "                encoder_decoder_position_bias=encoder_decoder_position_bias,\n",
    "                head_mask=head_mask[i],\n",
    "                past_key_value_state=past_key_value_state,\n",
    "                use_cache=use_cache,\n",
    "                output_attentions=output_attentions,\n",
    "            )\n",
    "            # layer_outputs is a tuple with:\n",
    "            # hidden-states, key-value-states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)\n",
    "            hidden_states, present_key_value_state = layer_outputs[:2]\n",
    "\n",
    "            if i == 0:\n",
    "                # We share the position biases between the layers - the first layer store them\n",
    "                # layer_outputs = hidden-states, key-value-states (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)\n",
    "                position_bias = layer_outputs[3 if output_attentions else 2]\n",
    "                if self.is_decoder and encoder_hidden_states is not None:\n",
    "                    encoder_decoder_position_bias = layer_outputs[5 if output_attentions else 3]\n",
    "            # append next layer key value states\n",
    "            present_key_value_states = present_key_value_states + (present_key_value_state,)\n",
    "\n",
    "            if output_attentions:\n",
    "                all_attentions = all_attentions + (layer_outputs[2],)  # We keep only self-attention weights for now\n",
    "\n",
    "        hidden_states = self.final_layer_norm(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        \n",
    "        # Add last layer\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        outputs = (hidden_states,)\n",
    "        if use_cache is True:\n",
    "            assert self.is_decoder, \"`use_cache` can only be set to `True` if {} is used as a decoder\".format(self)\n",
    "            outputs = outputs + (present_key_value_states,)\n",
    "        if output_hidden_states:\n",
    "            outputs = outputs + (all_hidden_states,)\n",
    "        if output_attentions:\n",
    "            outputs = outputs + (all_attentions,)\n",
    "\n",
    "        # Defining gates\n",
    "\n",
    "        last_hidden_state = outputs[0]\n",
    "        gates = self.gatefilter(last_hidden_state)\n",
    "        outputs = outputs + (gates,)\n",
    "\n",
    "        return outputs  # last-layer hidden state, (presents,) (all hidden states), (all attentions), (gates,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(scores,g):\n",
    "\n",
    "  scores_max = torch.max(scores,dim=-1)[0].unsqueeze(-1)\n",
    "  scores = scores - scores_max\n",
    "  A = torch.exp(scores) # (bs, n_heads, qlen, klen)\n",
    "  g= g.permute(0,1,3,2) # (bs, n_heads,1, klen)\n",
    "  A_g = g * A\n",
    "  sum_norm = torch.sum(A_g,axis=-1).unsqueeze(-1)\n",
    "  weights = A_g/sum_norm\n",
    "  return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5GatedAtention(T5Attention):\n",
    "  r\"\"\"\n",
    "  The source code is from huggingface. For more details, check their github \n",
    "  @https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_t5.py#L204\n",
    "  \n",
    "  Retuns:\n",
    "    Context, attentions weights on the keys for the provided queries  \n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, config, has_relative_attention_bias = False): \n",
    "    super(T5GatedAtention, self).__init__(config)\n",
    "\n",
    "    self.has_relative_attention_bias = has_relative_attention_bias \n",
    "    self.relative_attention_num_buckets = config.relative_attention_num_buckets\n",
    "    self.config = config\n",
    "    self.config.is_decoder = True\n",
    "    self.n_heads = config.num_heads\n",
    "\n",
    "    if self.has_relative_attention_bias:\n",
    "      self.relative_attention_bias = nn.Embedding(self.relative_attention_num_buckets, self.n_heads)\n",
    "\n",
    "  def extract_for_test(self, hidden_states, gates):\n",
    "    \n",
    "    # thresholding gates values\n",
    "    gate_indices = gates > self.config.threshold \n",
    "    # Creating gate mask\n",
    "    gate_mask = gate_indices * 1\n",
    "    # getting extracted valid values of gates and last hidden states\n",
    "    extracted_gates = gate_mask * gates\n",
    "    extracted_hidden_state = hidden_states * gate_mask\n",
    "\n",
    "    return extracted_hidden_state, extracted_gates\n",
    "\n",
    "  def forward(\n",
    "        self,\n",
    "        input,\n",
    "        gates,\n",
    "        mask=None,\n",
    "        kv=None,\n",
    "        position_bias=None,\n",
    "        past_key_value_state=None,\n",
    "        head_mask=None,\n",
    "        query_length=None,\n",
    "        use_cache=True,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Self-attention (if kv is None) or attention over source sentence (provided by kv).\n",
    "        \"\"\"\n",
    "        # Input is (bs, qlen, dim)\n",
    "        # Mask is (bs, klen) (non-causal) or (bs, klen, klen)\n",
    "        # past_key_value_state[0] is (bs, n_heads, q_len - 1, dim_per_head)\n",
    "        bs, qlen, dim = input.size()\n",
    "\n",
    "        if past_key_value_state is not None:\n",
    "            assert self.config.is_decoder is True, \"Encoder cannot cache past key value states\"\n",
    "            assert (\n",
    "                len(past_key_value_state) == 2\n",
    "            ), \"past_key_value_state should have 2 past states: keys and values. Got {} past states\".format(\n",
    "                len(past_key_value_state)\n",
    "            )\n",
    "            real_qlen = qlen + past_key_value_state[0].shape[2] if query_length is None else query_length\n",
    "        else:\n",
    "            real_qlen = qlen\n",
    "\n",
    "        if kv is None:\n",
    "            klen = real_qlen\n",
    "        else:\n",
    "            klen = kv.size(1)\n",
    "\n",
    "        def shape(x):\n",
    "            \"\"\"  projection \"\"\"\n",
    "            return x.view(bs, -1, self.n_heads, self.d_kv).transpose(1, 2)\n",
    "\n",
    "        def unshape(x):\n",
    "            \"\"\"  compute context \"\"\"\n",
    "            return x.transpose(1, 2).contiguous().view(bs, -1, self.inner_dim)\n",
    "\n",
    "        q = shape(self.q(input))  # (bs, n_heads, qlen, dim_per_head)\n",
    "        \n",
    "\n",
    "        if kv is None:\n",
    "            k = shape(self.k(input))  # (bs, n_heads, qlen, dim_per_head)\n",
    "            v = shape(self.v(input))  # (bs, n_heads, qlen, dim_per_head)\n",
    "\n",
    "        elif past_key_value_state is None:\n",
    "            k = v = kv\n",
    "            k = shape(self.k(k))  # (bs, n_heads, qlen, dim_per_head)\n",
    "            v = shape(self.v(v))  # (bs, n_heads, qlen, dim_per_head)\n",
    "\n",
    "        if past_key_value_state is not None:\n",
    "            if kv is None:\n",
    "                k_, v_ = past_key_value_state\n",
    "                k = torch.cat([k_, k], dim=2)  # (bs, n_heads, klen, dim_per_head)\n",
    "                v = torch.cat([v_, v], dim=2)  # (bs, n_heads, klen, dim_per_head)\n",
    "            else:\n",
    "                k, v = past_key_value_state\n",
    "\n",
    "        if self.config.is_decoder and use_cache is True:\n",
    "            present_key_value_state = ((k, v),)\n",
    "        else:\n",
    "            present_key_value_state = (None,)\n",
    "\n",
    "        # For evaluation remove irrelevant if we want to\n",
    "        if not self.training:\n",
    "            k, gates = self.extract_for_test(k, gates)\n",
    "            v, _ = self.extract_for_test(v, gates)\n",
    "\n",
    "        scores = torch.einsum(\"bnqd,bnkd->bnqk\", q, k)  # (bs, n_heads, qlen, klen)\n",
    "\n",
    "        if position_bias is None:\n",
    "            if not self.has_relative_attention_bias:\n",
    "                raise ValueError(\"No position_bias provided and no weights to compute position_bias\")\n",
    "            position_bias = self.compute_bias(real_qlen, klen)\n",
    "\n",
    "            # if key and values are already calculated\n",
    "            # we want only the last query position bias\n",
    "            if past_key_value_state is not None:\n",
    "                position_bias = position_bias[:, :, -1:, :]\n",
    "\n",
    "            if mask is not None:\n",
    "                position_bias = position_bias + mask  # (bs, n_heads, qlen, klen)\n",
    "\n",
    "        scores += position_bias\n",
    "\n",
    "        #if gate_filter_output is not None:\n",
    "        bsk, n_headsk, klenk, _ = k.size()\n",
    "        bsg, n_headsg, kleng, _ = gates.size()\n",
    "\n",
    "        error_message = \"Shapes missmatch. There should be gate of shape {}. Got {}\".format(k.shape,gates.shape)\n",
    "        assert (bsg, n_headsg, kleng) == (bsk, n_headsk, klenk), error_message\n",
    "\n",
    "\n",
    "        weights = softmax(scores.float(), g=gates).type_as(scores)  # (bs, n_heads, qlen, klen)\n",
    "        #weights = F.softmax(scores.float()).type_as(scores)  # (bs, n_heads, qlen, klen)\n",
    "\n",
    "        weights = F.dropout(weights, p=self.dropout, training=self.training)  # (bs, n_heads, qlen, klen)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if head_mask is not None:\n",
    "            weights = weights * head_mask\n",
    "\n",
    "        context = torch.matmul(weights, v)  # (bs, n_heads, qlen, dim_per_head)\n",
    "        context = unshape(context)  # (bs, qlen, dim)\n",
    "\n",
    "        context = self.o(context)\n",
    "\n",
    "        outputs = (context,) + present_key_value_state\n",
    "\n",
    "        if output_attentions: \n",
    "            outputs = outputs + (weights,)\n",
    "        if self.has_relative_attention_bias:\n",
    "            outputs = outputs + (position_bias,)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5LayerGatedCrossAttention(T5LayerCrossAttention):\n",
    "\n",
    "  def __init__(self, config, has_relative_attention_bias=False):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.EncDecAttention = T5GatedAtention(config, has_relative_attention_bias)\n",
    "\n",
    "  def forward(\n",
    "      self,\n",
    "      hidden_states,\n",
    "      gates,\n",
    "      kv,\n",
    "      attention_mask=None,\n",
    "      position_bias=None,\n",
    "      head_mask=None,\n",
    "      past_key_value_state=None,\n",
    "      use_cache=True,\n",
    "      query_length=None,\n",
    "      output_attentions=False,\n",
    "  ):\n",
    "      norm_x = self.layer_norm(hidden_states)\n",
    "      attention_output = self.EncDecAttention(\n",
    "          norm_x,\n",
    "          gates = gates,\n",
    "          mask=attention_mask,\n",
    "          kv=kv,\n",
    "          position_bias=position_bias,\n",
    "          head_mask=head_mask,\n",
    "          past_key_value_state=past_key_value_state,\n",
    "          use_cache=use_cache,\n",
    "          query_length=query_length,\n",
    "          output_attentions=output_attentions,\n",
    "      )\n",
    "      y = attention_output[0]\n",
    "      layer_output = hidden_states + self.dropout(y)\n",
    "      outputs = (layer_output,) + attention_output[1:]  # add attentions if we output them\n",
    "      return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedT5Block(T5Block):\n",
    "\n",
    "  def __init__(self,config,DecodBlock):\n",
    "    super(GatedT5Block, self).__init__(config)\n",
    "\n",
    "    self.config = config\n",
    "    self.layer = DecodBlock.layer\n",
    "\n",
    "  def forward(\n",
    "      self,\n",
    "      hidden_states,\n",
    "      gates,\n",
    "      attention_mask=None,\n",
    "      position_bias=None,\n",
    "      encoder_hidden_states=None,\n",
    "      encoder_attention_mask=None,\n",
    "      encoder_decoder_position_bias=None,\n",
    "      head_mask=None,\n",
    "      past_key_value_state=None,\n",
    "      use_cache=True,\n",
    "      output_attentions=False,\n",
    "  ):\n",
    "\n",
    "      if past_key_value_state is not None:\n",
    "          assert self.config.is_decoder, \"Only decoder can use `past_key_value_states`\"\n",
    "          expected_num_past_key_value_states = 2 if encoder_hidden_states is None else 4\n",
    "\n",
    "          error_message = \"There should be {} past states. 2 (past / key) for self attention.{} Got {} past key / value states\".format(\n",
    "              expected_num_past_key_value_states,\n",
    "              \"2 (past / key) for cross attention\" if expected_num_past_key_value_states == 4 else \"\",\n",
    "              len(past_key_value_state),\n",
    "          )\n",
    "          assert len(past_key_value_state) == expected_num_past_key_value_states, error_message\n",
    "\n",
    "          self_attn_past_key_value_state = past_key_value_state[:2]\n",
    "          cross_attn_past_key_value_state = past_key_value_state[2:]\n",
    "      else:\n",
    "          self_attn_past_key_value_state, cross_attn_past_key_value_state = None, None\n",
    "\n",
    "      self_attention_outputs = self.layer[0](\n",
    "          hidden_states,\n",
    "          attention_mask=attention_mask,\n",
    "          position_bias=position_bias,\n",
    "          head_mask=head_mask,\n",
    "          past_key_value_state=self_attn_past_key_value_state,\n",
    "          use_cache=use_cache,\n",
    "          output_attentions=output_attentions,\n",
    "      )\n",
    "      hidden_states, present_key_value_state = self_attention_outputs[:2]\n",
    "      attention_outputs = self_attention_outputs[2:]  # Keep self-attention outputs and relative position weights\n",
    "\n",
    "      if self.config.is_decoder and encoder_hidden_states is not None:\n",
    "          # the actual query length is unknown for cross attention\n",
    "          # if using past key value states. Need to inject it here\n",
    "          if present_key_value_state is not None:\n",
    "              query_length = present_key_value_state[0].shape[2]\n",
    "          else:\n",
    "              query_length = None\n",
    "\n",
    "          cross_attention_outputs = self.layer[1](\n",
    "              hidden_states,\n",
    "              gates=gates,\n",
    "              kv=encoder_hidden_states,\n",
    "              attention_mask=encoder_attention_mask,\n",
    "              position_bias=encoder_decoder_position_bias,\n",
    "              head_mask=head_mask,\n",
    "              past_key_value_state=cross_attn_past_key_value_state,\n",
    "              query_length=query_length,\n",
    "              use_cache=use_cache,\n",
    "              output_attentions=output_attentions,\n",
    "          )\n",
    "          hidden_states = cross_attention_outputs[0]\n",
    "          # Combine self attn and cross attn key value states\n",
    "          \n",
    "          # print('present_key_value_state',present_key_value_state)\n",
    "          # print('cross_attention_outputs[1]', cross_attention_outputs[1])\n",
    "          \n",
    "          if present_key_value_state is not None:\n",
    "              present_key_value_state = present_key_value_state + cross_attention_outputs[1]\n",
    "\n",
    "          # Keep cross-attention outputs and relative position weights\n",
    "          attention_outputs = attention_outputs + cross_attention_outputs[2:]\n",
    "\n",
    "      # Apply Feed Forward layer\n",
    "      hidden_states = self.layer[-1](hidden_states)\n",
    "      outputs = (hidden_states,)\n",
    "\n",
    "      # Add attentions if we output them\n",
    "      outputs = outputs + (present_key_value_state,) + attention_outputs\n",
    "      return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedT5Stack(T5Stack):\n",
    "    def __init__(self, config, t5model, embed_tokens=None):\n",
    "        super(GatedT5Stack, self).__init__(config)\n",
    "\n",
    "        self.embed_tokens = embed_tokens\n",
    "        self.block = nn.ModuleList([GatedT5Block(config, t5model.decoder.block[i]) for i in range(config.num_layers)])\n",
    "        self.config = config\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        gates,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        head_mask=None,\n",
    "        past_key_value_states=None,\n",
    "        use_cache=True,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "    ):\n",
    "\n",
    "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "            input_ids = input_ids.view(-1, input_shape[-1])\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            if self.config.is_decoder:\n",
    "                raise ValueError(\"You have to specify either decoder_input_ids or decoder_inputs_embeds\")\n",
    "            else:\n",
    "                raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            assert self.embed_tokens is not None, \"You have to intialize the model with valid token embeddings\"\n",
    "            inputs_embeds = self.embed_tokens(input_ids)\n",
    "\n",
    "        batch_size, seq_length = input_shape\n",
    "\n",
    "        if past_key_value_states is not None:\n",
    "            assert seq_length == 1, \"Input shape is {}, but should be {} when using past_key_value_sates\".format(\n",
    "                input_shape, (batch_size, 1)\n",
    "            )\n",
    "            # required mask seq length can be calculated via length of past\n",
    "            # key value states and seq_length = 1 for the last token\n",
    "            mask_seq_length = past_key_value_states[0][0].shape[2] + seq_length\n",
    "        else:\n",
    "            mask_seq_length = seq_length\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(batch_size, mask_seq_length).to(inputs_embeds.device)\n",
    "        if self.config.is_decoder and encoder_attention_mask is None and encoder_hidden_states is not None:\n",
    "            encoder_seq_length = encoder_hidden_states.shape[1]\n",
    "            encoder_attention_mask = torch.ones(\n",
    "                batch_size, encoder_seq_length, device=inputs_embeds.device, dtype=torch.long\n",
    "            )\n",
    "\n",
    "        # initialize past_key_value_states with `None` if past does not exist\n",
    "        if past_key_value_states is None:\n",
    "            past_key_value_states = [None] * len(self.block)\n",
    "\n",
    "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "        extended_attention_mask = self.get_extended_attention_mask(attention_mask, input_shape, inputs_embeds.device)\n",
    "\n",
    "        if self.config.is_decoder and encoder_attention_mask is not None:\n",
    "            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        head_mask = self.get_head_mask(head_mask, self.config.num_layers)\n",
    "        present_key_value_states = ()\n",
    "        all_hidden_states = ()\n",
    "        all_attentions = ()\n",
    "        position_bias = None\n",
    "        encoder_decoder_position_bias = None\n",
    "\n",
    "        hidden_states = self.dropout(inputs_embeds)\n",
    "\n",
    "        for i, (layer_module, past_key_value_state) in enumerate(zip(self.block, past_key_value_states)):\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            layer_outputs = layer_module(\n",
    "                hidden_states,\n",
    "                gates = gates,\n",
    "                attention_mask=extended_attention_mask,\n",
    "                position_bias=position_bias,\n",
    "                encoder_hidden_states=encoder_hidden_states,\n",
    "                encoder_attention_mask=encoder_extended_attention_mask,\n",
    "                encoder_decoder_position_bias=encoder_decoder_position_bias,\n",
    "                head_mask=head_mask[i],\n",
    "                past_key_value_state=past_key_value_state,\n",
    "                use_cache=use_cache,\n",
    "                output_attentions=output_attentions,\n",
    "            )\n",
    "            # layer_outputs is a tuple with:\n",
    "            # hidden-states, key-value-states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)\n",
    "            hidden_states, present_key_value_state = layer_outputs[:2]\n",
    "\n",
    "            if i == 0:\n",
    "                # We share the position biases between the layers - the first layer store them\n",
    "                # layer_outputs = hidden-states, key-value-states (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)\n",
    "                position_bias = layer_outputs[3 if output_attentions else 2]\n",
    "                if self.config.is_decoder and encoder_hidden_states is not None:\n",
    "                    encoder_decoder_position_bias = layer_outputs[5 if output_attentions else 3]\n",
    "            # append next layer key value states\n",
    "            present_key_value_states = present_key_value_states + (present_key_value_state,)\n",
    "\n",
    "            if output_attentions:\n",
    "                all_attentions = all_attentions + (layer_outputs[2],)  # We keep only self-attention weights for now\n",
    "\n",
    "        hidden_states = self.final_layer_norm(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "\n",
    "        # Add last layer\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        outputs = (hidden_states,)\n",
    "        if use_cache is True:\n",
    "            assert self.config.is_decoder, \"`use_cache` can only be set to `True` if {} is used as a decoder\".format(self)\n",
    "            outputs = outputs + (present_key_value_states,)\n",
    "        if output_hidden_states:\n",
    "            outputs = outputs + (all_hidden_states,)\n",
    "        if output_attentions:\n",
    "            outputs = outputs + (all_attentions,)\n",
    "        return outputs  # last-layer hidden state, (presents,) (all hidden states), (all attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5ForGenerationWithGate(T5ForConditionalGeneration):\n",
    "\n",
    "  def __init__(self, config, t5model):\n",
    "    super().__init__(config)\n",
    "\n",
    "    encoder_config = copy.deepcopy(t5model.encoder.config)\n",
    "    encoder_config.is_decoder = False   \n",
    "    encoder_config.use_cache = False \n",
    "\n",
    "    self.encoder = EncoderStack(encoder_config, embed_tokens=self.shared)\n",
    "\n",
    "    decoder_config = copy.deepcopy(t5model.decoder.config)\n",
    "    decoder_config.is_decoder = True\n",
    "    self.config = config\n",
    "    self.decoder = GatedT5Stack(decoder_config, t5model, embed_tokens=self.shared)\n",
    "\n",
    "  def forward(self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        encoder_outputs=None,\n",
    "        decoder_input_ids=None,\n",
    "        decoder_attention_mask=None,\n",
    "        decoder_past_key_value_states=None,\n",
    "        use_cache=True,\n",
    "        labels=None,\n",
    "        inputs_embeds=None,\n",
    "        decoder_inputs_embeds=None,\n",
    "        head_mask=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        lambd = 0.0,\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        if \"lm_labels\" in kwargs:\n",
    "            warnings.warn(\n",
    "                \"The `lm_labels` argument is deprecated and will be removed in a future version, use `labels` instead.\",\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "            labels = kwargs.pop(\"lm_labels\")\n",
    "        assert kwargs == {}, f\"Unexpected keyword arguments: {list(kwargs.keys())}.\"\n",
    "\n",
    "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "\n",
    "        # Encode if needed (training, first prediction pass)\n",
    "        if encoder_outputs is None:\n",
    "            # Convert encoder inputs in embeddings if needed\n",
    "            encoder_outputs = self.encoder(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                inputs_embeds=inputs_embeds,\n",
    "                head_mask=head_mask,\n",
    "                output_attentions=output_attentions,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "            )\n",
    "\n",
    "        # Getting the last hidden states and the gates\n",
    "        \n",
    "        hidden_states = encoder_outputs[0]\n",
    "        gates = encoder_outputs[-1]\n",
    "\n",
    "\n",
    "        if labels is not None and decoder_input_ids is None and decoder_inputs_embeds is None:\n",
    "            # get decoder inputs from shifting lm labels to the right\n",
    "            decoder_input_ids = self._shift_right(labels)\n",
    "\n",
    "        # If decoding with past key value states, only the last tokens\n",
    "        # should be given as an input\n",
    "        if decoder_past_key_value_states is not None:\n",
    "            assert labels is None, \"Decoder should not use cached key value states when training.\"\n",
    "            if decoder_input_ids is not None:\n",
    "                decoder_input_ids = decoder_input_ids[:, -1:]\n",
    "            if decoder_inputs_embeds is not None:\n",
    "                decoder_inputs_embeds = decoder_inputs_embeds[:, -1:]\n",
    "\n",
    "        # Decode\n",
    "        decoder_outputs = self.decoder(\n",
    "            gates = gates,\n",
    "            input_ids=decoder_input_ids,\n",
    "            attention_mask=decoder_attention_mask,\n",
    "            inputs_embeds=decoder_inputs_embeds,\n",
    "            past_key_value_states=decoder_past_key_value_states,\n",
    "            encoder_hidden_states=hidden_states,\n",
    "            encoder_attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "        )\n",
    "\n",
    "        # insert decoder past at right place\n",
    "        # to speed up decoding\n",
    "        if use_cache is True:\n",
    "            past = ((encoder_outputs, decoder_outputs[1]),)\n",
    "            decoder_outputs = decoder_outputs[:1] + past + decoder_outputs[2:]\n",
    "\n",
    "        sequence_output = decoder_outputs[0]\n",
    "\n",
    "        # print('\\ndecoder hidden nan', torch.sum(torch.isnan(sequence_output)))\n",
    "\n",
    "        # Rescale output before projecting on vocab\n",
    "        # See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586\n",
    "        sequence_output = sequence_output * (self.model_dim ** -0.5)\n",
    "        lm_logits = self.lm_head(sequence_output)\n",
    "\n",
    "        decoder_outputs = (lm_logits,) + decoder_outputs[1:]  # Add hidden states and attention if they are here\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "            loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), labels.view(-1))\n",
    "\n",
    "            # print('MLE loss', loss)\n",
    "            \n",
    "            loss_gate = torch.sum(gates.squeeze(-1))/(gates.shape[0]*gates.shape[1]*gates.shape[2])\n",
    "            \n",
    "            # print('loss_gate', loss_gate)\n",
    "            \n",
    "            Loss = loss + loss_gate * lambd\n",
    "\n",
    "            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666\n",
    "            decoder_outputs = (Loss,) + decoder_outputs\n",
    "\n",
    "        return decoder_outputs + encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = t5model.config\n",
    "config.reg = 0.4\n",
    "config.threshold = 0.01\n",
    "\n",
    "torch.save(t5model.state_dict(),\"pretrained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_to_replace=[]\n",
    "for block in t5model.decoder.block:\n",
    "  layers_to_replace.append(block)\n",
    "for idx,block in enumerate(layers_to_replace):\n",
    "\n",
    "  # Attention\n",
    "  EncoderDecodBlock = t5model.decoder.block[idx]\n",
    "  block.layer[1].EncDecAttention = T5GatedAtention(config)\n",
    "\n",
    "  # CrossAttention\n",
    "  if idx == 0:\n",
    "    block.layer[1] = T5LayerGatedCrossAttention(config, has_relative_attention_bias=True)\n",
    "  else:\n",
    "    block.layer[1] = T5LayerGatedCrossAttention(config, has_relative_attention_bias=False)\n",
    "\n",
    "\n",
    "# Define Decoder\n",
    "t5model.decoder = GatedT5Stack(config, t5model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "my_model = T5ForGenerationWithGate(config, t5model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0186,  0.0228, -0.0548, -0.1152, -0.1108, -0.0474, -0.0583,  0.0563,\n",
       "          0.0075,  0.0517,  0.0720,  0.1039, -0.0671,  0.0496,  0.0926, -0.0469,\n",
       "         -0.1166, -0.1006, -0.0283,  0.0552, -0.0391,  0.0619, -0.0700,  0.0848,\n",
       "         -0.0694,  0.0975,  0.1065,  0.0522,  0.0717,  0.1050, -0.0337,  0.1131,\n",
       "         -0.0279, -0.0629, -0.0430,  0.0558, -0.0695,  0.1159,  0.0308, -0.0247,\n",
       "         -0.0604,  0.1077, -0.0623, -0.0089,  0.0450, -0.0511, -0.0115,  0.1028,\n",
       "         -0.0040, -0.0589,  0.0636, -0.1211,  0.1223, -0.0208,  0.0862, -0.0779,\n",
       "         -0.0568, -0.0436, -0.1195,  0.0342, -0.0306, -0.0107, -0.0947, -0.0909]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"pretrained.pth\")\n",
    "state_dict[\"encoder.gatefilter.projector.weight\"] = my_model.encoder.gatefilter.projector.weight\n",
    "state_dict[\"encoder.gatefilter.projector.weight\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Jkp7dIU9-ZO3",
    "outputId": "f18b53f5-38d8-4bc1-c664-98b01f61f546"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('</s>', '<pad>')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos = tokenizer.eos_token\n",
    "sos = tokenizer.pad_token\n",
    "eos, sos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W51Hk0xEz0sH"
   },
   "outputs": [],
   "source": [
    "#@title Train, Validation and Test splits { run: \"auto\" }\n",
    "\n",
    "columns = [\"text\",\"summary\"]\n",
    "\n",
    "X_train = train_processed_data[columns] #X_train.reset_index(drop=True)\n",
    "X_valid = valid_processed_data[columns] #X_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "sQeVMTtGz0p7",
    "outputId": "3e428252-9f55-4243-8cd2-a5d6f4c6641d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAMBURG, Germany, June 3 As he left the soccer...</td>\n",
       "      <td>A surge in discriminatory behavior toward blac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WASHINGTON, Dec. 23 The National Security Agen...</td>\n",
       "      <td>The volume of information harvested, without \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IF outsized executive pay has indeed become a ...</td>\n",
       "      <td>The battle between Pfizer Inc. s investors and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BY A.J. BENZA and MICHAEL LEWITTES\\n\\nIf Simon...</td>\n",
       "      <td>If Simon Rex looks a little familiar, it may n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spinach has terrorized generations of veggie p...</td>\n",
       "      <td>POPEYE WORTHY PIE. PHYLLO DOUGH WRAPS SPINACH ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                                            summary\n",
       "0  HAMBURG, Germany, June 3 As he left the soccer...  A surge in discriminatory behavior toward blac...\n",
       "1  WASHINGTON, Dec. 23 The National Security Agen...  The volume of information harvested, without \\...\n",
       "2  IF outsized executive pay has indeed become a ...  The battle between Pfizer Inc. s investors and...\n",
       "3  BY A.J. BENZA and MICHAEL LEWITTES\\n\\nIf Simon...  If Simon Rex looks a little familiar, it may n...\n",
       "4  Spinach has terrorized generations of veggie p...  POPEYE WORTHY PIE. PHYLLO DOUGH WRAPS SPINACH ..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n97QsOoCZ0v8"
   },
   "outputs": [],
   "source": [
    "def get_dataloader(X, BATCH_SIZE,valid=None, **kwargs):\n",
    "\n",
    "    if valid == 'valid':\n",
    "        val_params = {\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'shuffle': False,\n",
    "            'num_workers': 2\n",
    "            }\n",
    "        data_set = CustomDataReader(X, tokenizer,**kwargs)\n",
    "        data_loader = DataLoader(data_set, **val_params)\n",
    "        \n",
    "    else:\n",
    "        data_set = CustomDataReader(X, tokenizer,**kwargs)     \n",
    "        train_params = {\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'shuffle': True,\n",
    "            'num_workers': 2\n",
    "            }\n",
    "        data_loader = DataLoader(data_set, **train_params)\n",
    "    \n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting samples of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08lW8ejhmgya"
   },
   "outputs": [],
   "source": [
    "# Xtrain_trial = X_train.iloc[:50000]\n",
    "# Xvalid_trial = X_valid.iloc[:3600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(X_train))\n",
    "valind = np.random.permutation(len(X_valid))\n",
    "\n",
    "ind = indices[:70000]\n",
    "vind = valind[:5000]\n",
    "\n",
    "Xtrain_trial = X_train.iloc[ind]\n",
    "Xvalid_trial = X_valid.iloc[vind]\n",
    "\n",
    "Xtrain_trial = Xtrain_trial.reset_index(drop=True)\n",
    "Xvalid_trial = Xvalid_trial.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGaGMwWLzfVE"
   },
   "outputs": [],
   "source": [
    "def load_pretrained_weights(model, optimizer, PATH, pretrained: Optional[bool]=False):\n",
    "\n",
    "    if pretrained:\n",
    "        checkpoint = torch.load(PATH)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        #LEARNING_RATE = checkpoint['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csfO3UdlJtEf"
   },
   "outputs": [],
   "source": [
    "def run(model,\n",
    "        X_train, X_valid, \n",
    "        weights_dir=None,filename=None,\n",
    "        eps_aneal = False, pretrained=False,\n",
    "        lr= LEARNING_RATE):\n",
    "\n",
    "    # WandB – Initialize a new run\n",
    "    wandb.init(entity=\"jp-ishimwe\", project=\"final-summarization-model\")\n",
    "    \n",
    "#     wandb.init(entity=\"jp-ishimwe\", project=\"test-summaries\") \n",
    "#     wandb.init(entity=\"jp-ishimwe\", project=\"document-summarization-test\")\n",
    "#     wandb.init(entity=\"jp-ishimwe\", project=\"document-summarization-using-transformer\")\n",
    " \n",
    "    config = wandb.config          \n",
    "    config.BATCH_SIZE = 4\n",
    "    config.EVAL_BATCH_SIZE = 5\n",
    "    config.N_EPOCHS = 2 \n",
    "    config.LEARNING_RATE = lr\n",
    "    config.SEED = 123               \n",
    "    config.art_maxlen = art\n",
    "    config.summary_maxlen = sum_\n",
    "    config.Valid_art_maxlen = artV\n",
    "    config.Valid_summary_maxlen = sumV\n",
    "    config.log_interval = 500     # how many batches to wait before logging training status\n",
    "    config.reg = 0.4\n",
    "\n",
    "    set_seed()\n",
    "    \n",
    "    kwargs = {'max_article_tokens': config.art_maxlen,\n",
    "                'max_summary_tokens': config.summary_maxlen\n",
    "             }\n",
    "    \n",
    "    kwargsval = {'max_article_tokens': config.Valid_art_maxlen,\n",
    "                'max_summary_tokens': config.Valid_summary_maxlen\n",
    "             }\n",
    "    \n",
    "    \n",
    "    train_loader = get_dataloader(X_train, config.BATCH_SIZE,valid=None, **kwargs)\n",
    "    val_loader  = get_dataloader(X_valid, config.EVAL_BATCH_SIZE,valid='valid', **kwargsval)\n",
    "    \n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    perplexity = []\n",
    "    \n",
    "    model = model.to(device)\n",
    "    params = {'params': model.parameters()}\n",
    "    optimizer = optim.Adam([params], lr=config.LEARNING_RATE)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=0)\n",
    "    \n",
    "    if pretrained and weights_dir is not None:\n",
    "        path = os.path.join(weights_dir, \"final_model.pth\")\n",
    "        if os.path.exists(path):\n",
    "            load_pretrained_weights(model, optimizer, path, pretrained=pretrained)\n",
    "        else:\n",
    "            raise NameError(\"The specified weight path does not exist\")\n",
    "            \n",
    "\n",
    "    if eps_aneal:\n",
    "        maxiter = config.N_EPOCHS*(len(train_loader.dataset)//config.BATCH_SIZE)\n",
    "        eps_sched = 1e-8 + 0.5-0.5*np.cos(np.linspace(0, np.pi, maxiter))\n",
    "        batchs = config.BATCH_SIZE\n",
    "    else:\n",
    "        eps_sched = None\n",
    "        batchs = None\n",
    "    \n",
    "    wandb.watch(model, log=\"all\")\n",
    "\n",
    "    for epoch in range(config.N_EPOCHS): \n",
    "\n",
    "        avg_loss, outputs = training(model, train_loader, optimizer, config.log_interval,regularizer=config.reg, eps_sched=eps_sched, batchs=batchs,epoch=epoch)\n",
    "        \n",
    "        print('\\nValidation start:')\n",
    "        eval_loss = validation(model, val_loader, regularizer=config.reg)\n",
    "\n",
    "        pp = get_perplexity(eval_loss)\n",
    "\n",
    "        perplexity.append(pp)\n",
    "        train_loss.append(avg_loss)\n",
    "        val_loss.append(eval_loss)\n",
    "        scheduler.step(eval_loss)\n",
    "\n",
    "\n",
    "        print(f'Epoch loss: {avg_loss:.4f}')\n",
    "        print(f'Perplexity: {pp:.4f} | Eval loss: {eval_loss:.4f}')\n",
    "        print(\"--------------\")\n",
    "\n",
    "\n",
    "        wandb.log({\n",
    "            \"Training Loss\": avg_loss,\n",
    "            \"Perplexity \": pp,\n",
    "            \"Eval Loss\": eval_loss})\n",
    "\n",
    "\n",
    "        # Save model to wandb\n",
    "\n",
    "        PATH = os.path.join(wandb.run.dir, 'final_model.pth')\n",
    "        saving(PATH, epoch, optimizer, model, config.LEARNING_RATE)\n",
    "\n",
    "    return train_loss, perplexity, val_loss, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "cb47163880b644e99674d508f1407349",
      "e94c000d5060445ca93691f6af42e70c",
      "6e1089fcff4a4ad19de6fc9dfb87c171",
      "c5b5410811de4ab59ff76737f353ce27",
      "2f28dc0b45cc4b30acb85fecdc128397",
      "0551f8a91cb547948703416f5c200c93",
      "e8fbc6f859784253a0cf6fe88cc0d9ca",
      "cd662889ecd24a5fbfbf078039e270a8",
      "ddd0f5a0f838494daf3d0581081c3e86",
      "3856954e8b1e47a08fce9fff7a038027",
      "f842c10d414f41c6846c1dc74200f301",
      "a694fbafc40c41e98fe568668e4db732",
      "8365405f8a1c4d178b5ab5cd9d905e32",
      "4800749f8151430c8cc49570cd4ccaf7",
      "dc75ce283dff4270b9c537d4e057d416",
      "992143ed056d4a23afff16b83c514432",
      "dffe3b78e72e4c309bda155884c2c7a7",
      "00632d7b23cc45f59515669601334fcd",
      "d9fb635e32cd4ed4bcddf6574de80b1b",
      "1523672396354424b0658ce14786fbd2",
      "273de981090749b29ce385706c449722",
      "3353a6712b3a482d8907ca80a0824020",
      "ffc60b07ad704ea2afc0ac2c79c10c11",
      "864cb033af344f22b288a320088ec71c",
      "2d96618428094902b80450d649566a66",
      "c7a670342db348f0b703a95438137574",
      "a33ce8bb19284323a89a317403263c0d",
      "90937a3fdc314010948a13e9e2c70e40",
      "b506bbd1464b407980a6ef55a7819828",
      "a2026ad15de541eebf332cb4ce4e1ad2",
      "a56cd84f576841259aace5b34b0efda7",
      "2004cd6b66034fdda39e09c4ea44b3ce",
      "90f39af76e9846b18c45633dce765584",
      "4a42cbf2455346818c8fb92da5665bca",
      "d2a4e7e937804562a63d0191223c0dd0",
      "02d1d8ffcf3a4873880bb4ec2b7eefbf",
      "d689f347b2e040d186d0353abaa96dd4",
      "17e87d4a9a974aa6828c5ae0f9e0cf3a",
      "1f778937b7484fac8de6530ea10a5470",
      "7a0883324f8b4256adf0e8a54c77524f",
      "53c9e46489fc4d708c7fe856173f3b12",
      "27afa2d568d6441690a6d0ee44e40e1c",
      "0cdd1f83587643f68b9cc4659ba75fb8",
      "2732c77700724db3beb39d1c64469852",
      "598b0d3d4ba64ed48d511ce9dd360f64",
      "9efdf4e9fd8c42598cced165c426f5bf",
      "f1010194505c44b588ba44a39e4afd9f",
      "a504d4571ae54c97a6fb586051f17b07",
      "a633f4726f6a4ba5babb0e0414e6c5e1",
      "007752d9ce5e47f480ae606afeb2cd16",
      "58fa30020dc14801a78967796be9df3e",
      "9712936912b84e498783132d111037bf",
      "89f6bfd52126419ab7c6b6ba00894c24",
      "501fe7de2d29471c9ad3580ba42b274d",
      "9e0d68b268384372ae1ec48b6c363b3a",
      "e595378941654a4dbe560a646dc52272",
      "c56a3c25a1284582bdfb1ad9e02ccb06",
      "888804a45395411cb9db622b0e6878cb",
      "b986d76f127a48669bfaf9c674079d87",
      "e941a8dd61c641c88445eb5497fd2760",
      "6736870c4aa94b20adeed80a00507dce",
      "4d3bd152e2b14612bdec4f9692d48739",
      "63ff13ee95f64beea555e0660be15eec",
      "ce7dc5c992754af5a545aa408ed67c88",
      "430de0fcf9ce45799f8cec7b508a8f7f",
      "99791d40ec534ebc9a7f4b01767f9aad",
      "e2be21b2cc584489b535309b9c8904e3",
      "354fdd4a6e064367be8398d996b63d38",
      "8503f63352114056ace6ee5662d746da",
      "fca884b72b1946cd8403edac7d41924e",
      "3008461ae4e440d081f2f3ac46afa685",
      "22e8567701184b729be80c57098badc4",
      "40ef9fea4c03417db6bdc76b480fb59e",
      "3c42fdea3dcd4f2bbd6ba10777f27db3",
      "8b5212a3ed9f49aea201644e1ed1ac53",
      "a637e9d5dda44c3e9c8c3b9154b1b20d",
      "e7ccb000bd83423fb4693a908c638ddb",
      "4e394e72017442e989642afdc2b8abcb",
      "87a5e794f5ff408ebbf2a740a7560adb",
      "200ba008099045719694899c681c2d16",
      "8b0a112033ab4a3a9a970c6eaaec5531",
      "9acb641a7ede4dd6b68097dbff290ce1",
      "8ef3688940ae4ff4840fc3ca4c231125",
      "f7dd810e69fa4f1f91acaec17fb8c64a",
      "68ba61411c5d4097883b053f06493415",
      "838fc6b6bb704fd897d9145830d7bb9f",
      "268c4187cfc9490bacfa1eafe1fbcca1",
      "940db33506ef463788996553c4bf5f74",
      "fb5c1e7223ac4634a16c161784505836",
      "7475bb3748de434eae59ef85715514da",
      "471a09375e984a31824b27e279a6c4f3",
      "27deb6f565ac4447a44770288071a0b8",
      "7a407d5347104eaa9ce6ec36250715d3",
      "37454b94184a4a10a9affa6e84e74f43",
      "e94b124aaf674431b6e424b9c6c1da87",
      "9a9728af9dcb4e67a1a006297cd7b74c",
      "e7fc29feb6d3404d83c1e455602d5c1b",
      "ddf41c306dc441eb85beb6ea7bfbfedd",
      "2d2b6b3effa34b809c30379c42c3c861",
      "f46251823d4f4d219bffc095047f8867",
      "5605c8c2ad12431b88e1404953ecd6b9",
      "ad0c71bcf6d945098f04025bc52055f9",
      "04619e3db74847f5b637c7d2b1d5b8b8",
      "9d3ae70779e447d0aa495a9872209d38",
      "906c310a405b4822a19d206cf3467f9b",
      "75b200a4d1cb4f1cab2204139ac8fff5",
      "61a4358811654212bd669c1c6c40b4cd",
      "917a8ab6a55b4cd382b1cd1982d5a227",
      "7b8fca08cafe4f7e9ad9f519bb005fd1",
      "2df67220b98547639c10a80ceb63b1ef",
      "58d8bd8caffa47788931111cd5d05409",
      "4778d193b45a4e2ca8871f19b195a26b",
      "267a56c7a2f542e3b24a5f790491a550",
      "dc94b3b543714dd0845fdadca7db22a3",
      "db85fdb064634d80b1904313a3b81ddb",
      "1cbf0dd906ac41e985bd752f526fa2d4",
      "ed804e9c6fae4499aa3e6fef00f5de44",
      "9459d0d307814c34aa8a31945a82adb7",
      "41ceec6b9c214b18891c8ab915d5c19c",
      "6005029df2504711a96df12e14290100"
     ]
    },
    "colab_type": "code",
    "id": "npvqrZ9L_Ufl",
    "outputId": "84bc79d3-9ae7-4882-d791-6c3699ca45fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjp-ishimwe\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.4<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">super-music-58</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jp-ishimwe/final-summarization-model\" target=\"_blank\">https://wandb.ai/jp-ishimwe/final-summarization-model</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jp-ishimwe/final-summarization-model/runs/1794x3vy\" target=\"_blank\">https://wandb.ai/jp-ishimwe/final-summarization-model/runs/1794x3vy</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20200930_070308-1794x3vy</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start training for epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17500/17500 [3:26:55<00:00,  1.41it/s, loss=1.79]  \n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation start:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:45<00:00,  3.50it/s, loss=1.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 1.7888\n",
      "Perplexity: 1.4163 | Eval loss: 0.3481\n",
      "--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start training for epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17500/17500 [3:26:48<00:00,  1.41it/s, loss=1.56]  \n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation start:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:46<00:00,  3.50it/s, loss=1.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss: 1.5586\n",
      "Perplexity: 1.4197 | Eval loss: 0.3505\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "train_loss, perplexity, eval_loss, outputs = run(my_model, Xtrain_trial, Xvalid_trial,lr= LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the gate distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 12, 700, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gates = outputs[-1].squeeze(-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0230],\n",
       "         [0.0192],\n",
       "         [0.0180],\n",
       "         [0.0172],\n",
       "         [0.0150],\n",
       "         [0.0217],\n",
       "         [0.0180],\n",
       "         [0.0249],\n",
       "         [0.0224],\n",
       "         [0.0185],\n",
       "         [0.0205],\n",
       "         [0.0135]],\n",
       "\n",
       "        [[0.0204],\n",
       "         [0.0142],\n",
       "         [0.0163],\n",
       "         [0.0162],\n",
       "         [0.0150],\n",
       "         [0.0186],\n",
       "         [0.0184],\n",
       "         [0.0224],\n",
       "         [0.0192],\n",
       "         [0.0157],\n",
       "         [0.0148],\n",
       "         [0.0142]],\n",
       "\n",
       "        [[0.0155],\n",
       "         [0.0214],\n",
       "         [0.0182],\n",
       "         [0.0195],\n",
       "         [0.0167],\n",
       "         [0.0214],\n",
       "         [0.0175],\n",
       "         [0.0262],\n",
       "         [0.0167],\n",
       "         [0.0190],\n",
       "         [0.0177],\n",
       "         [0.0167]],\n",
       "\n",
       "        [[0.0178],\n",
       "         [0.0154],\n",
       "         [0.0158],\n",
       "         [0.0223],\n",
       "         [0.0188],\n",
       "         [0.0201],\n",
       "         [0.0197],\n",
       "         [0.0238],\n",
       "         [0.0156],\n",
       "         [0.0120],\n",
       "         [0.0145],\n",
       "         [0.0181]]], device='cuda:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gates.mean(dim=-1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5556],\n",
       "         [0.5474],\n",
       "         [0.5299],\n",
       "         [0.5497],\n",
       "         [0.6138],\n",
       "         [0.5745],\n",
       "         [0.6458],\n",
       "         [0.5618],\n",
       "         [0.5960],\n",
       "         [0.5751],\n",
       "         [0.5647],\n",
       "         [0.5361]],\n",
       "\n",
       "        [[0.7161],\n",
       "         [0.5312],\n",
       "         [0.5149],\n",
       "         [0.5581],\n",
       "         [0.6196],\n",
       "         [0.5829],\n",
       "         [0.6106],\n",
       "         [0.5398],\n",
       "         [0.6018],\n",
       "         [0.5724],\n",
       "         [0.5520],\n",
       "         [0.5439]],\n",
       "\n",
       "        [[0.5691],\n",
       "         [0.5416],\n",
       "         [0.5387],\n",
       "         [0.5616],\n",
       "         [0.6563],\n",
       "         [0.5793],\n",
       "         [0.5981],\n",
       "         [0.6639],\n",
       "         [0.6038],\n",
       "         [0.5870],\n",
       "         [0.5671],\n",
       "         [0.5454]],\n",
       "\n",
       "        [[0.6276],\n",
       "         [0.5404],\n",
       "         [0.5256],\n",
       "         [0.7512],\n",
       "         [0.6301],\n",
       "         [0.5794],\n",
       "         [0.6428],\n",
       "         [0.6684],\n",
       "         [0.5898],\n",
       "         [0.5756],\n",
       "         [0.5582],\n",
       "         [0.5436]]], device='cuda:0', grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, _ = gates.max(dim=-1,keepdim=True)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[7.0345e-08],\n",
       "         [4.1337e-08],\n",
       "         [2.6812e-08],\n",
       "         [4.0297e-07],\n",
       "         [2.2037e-07],\n",
       "         [1.6189e-07],\n",
       "         [1.6748e-07],\n",
       "         [7.5303e-09],\n",
       "         [9.7933e-08],\n",
       "         [1.4658e-07],\n",
       "         [1.2262e-08],\n",
       "         [3.1700e-07]],\n",
       "\n",
       "        [[5.4738e-05],\n",
       "         [1.5335e-05],\n",
       "         [7.2741e-05],\n",
       "         [6.1705e-05],\n",
       "         [2.4383e-05],\n",
       "         [7.3563e-05],\n",
       "         [1.3537e-04],\n",
       "         [8.5712e-05],\n",
       "         [6.4411e-05],\n",
       "         [1.7773e-05],\n",
       "         [2.4363e-05],\n",
       "         [5.3521e-05]],\n",
       "\n",
       "        [[7.0225e-08],\n",
       "         [3.1434e-08],\n",
       "         [6.4151e-08],\n",
       "         [1.5729e-07],\n",
       "         [2.2112e-07],\n",
       "         [1.0597e-07],\n",
       "         [1.4586e-07],\n",
       "         [2.4986e-08],\n",
       "         [1.3904e-07],\n",
       "         [4.3302e-08],\n",
       "         [3.6379e-08],\n",
       "         [1.6424e-07]],\n",
       "\n",
       "        [[3.8869e-08],\n",
       "         [1.8022e-08],\n",
       "         [4.1672e-08],\n",
       "         [1.1658e-07],\n",
       "         [1.0712e-07],\n",
       "         [5.9701e-08],\n",
       "         [9.3210e-08],\n",
       "         [3.8641e-08],\n",
       "         [1.4196e-07],\n",
       "         [4.7157e-08],\n",
       "         [1.9362e-08],\n",
       "         [2.0062e-07]]], device='cuda:0', grad_fn=<MinBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals, _ = gates.min(dim=-1, keepdim=True)\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "jmJ94Ryul0vR",
    "outputId": "f5f05284-122e-4f8f-cb3c-176e845c19db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tr_los = np.array(train_loss)\n",
    "ev_los = np.array(eval_loss)\n",
    "per = np.array(perplexity)\n",
    "\n",
    "plt.plot(tr_los, label='Training loss')\n",
    "plt.plot(ev_los, label='Validation loss')\n",
    "plt.plot(per, label='Perplexity on val data')\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "plt.title('Train loss vs Eval loss and Perplexity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jsxZGr_bz0cv"
   },
   "outputs": [],
   "source": [
    "def generator(model, dataset_loader):\n",
    "  \n",
    "  model.eval()\n",
    "\n",
    "  results = {\"generated_summary\": [], \"golden_summary\": []}\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for idx, data_val in enumerate(dataset_loader):\n",
    "      \n",
    "      input_ids, source_mask, summary_ids, summary_mask = data_val \n",
    "      \n",
    "      input_ids = input_ids.to(device, dtype = torch.long)\n",
    "      source_mask = source_mask.to(device, dtype = torch.float)\n",
    "      summary_ids = summary_ids.to(device, dtype = torch.long)\n",
    "\n",
    "      generatation = model.generate(input_ids=input_ids,\n",
    "                                    attention_mask=source_mask, \n",
    "                                    min_length=30, \n",
    "                                    max_length=300, \n",
    "                                    num_beams=1,\n",
    "                                    repetition_penalty=2.5,\n",
    "                                    eos_token_id = model.decoder.config.eos_token_id,               \n",
    "                                    length_penalty=1.0, \n",
    "                                    early_stopping=True\n",
    "                                    )\n",
    "\n",
    "      for gen, sc in zip(generatation, summary_ids): # Taking whole document IDs and docode the summary\n",
    "\n",
    "        gen_tokens_dec = tokenizer.decode(gen, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        sc_tokens_dec = tokenizer.decode(sc, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "        results[\"generated_summary\"].append(gen_tokens_dec)\n",
    "        results[\"golden_summary\"].append(sc_tokens_dec)\n",
    "\n",
    "  return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwTbUyKag_8R"
   },
   "source": [
    "#### Loading Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tTLrSSGio-c-"
   },
   "outputs": [],
   "source": [
    "load_weights = False\n",
    "\n",
    "if load_weights:    \n",
    "\n",
    "    model = .... # first initialize the model and optimizer\n",
    "    optimizer = ... # optimizer then,\n",
    "    PATH = ...\n",
    "    \n",
    "    load_pretrained_weights(model, optimizer, PATH, pretrained=load_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final_Project.ipynb\t     Wheat_rust_classification.ipynb\n",
      "README.md\t\t     model.pt\n",
      "T5_ftransfer_learning.ipynb  valid_processed.pkl\n",
      "Untitled.ipynb\t\t     wandb\n"
     ]
    }
   ],
   "source": [
    "!ls /root/Projects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('/root/Projectsmodel0.pt'))\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivind = valind[5000:6000]\n",
    "\n",
    "X_trial = X_valid.iloc[ivind]\n",
    "\n",
    "Xtest_trial = X_trial.reset_index(drop=True)\n",
    "\n",
    "argsval = {'max_article_tokens': 700,\n",
    "                'max_summary_tokens': 250\n",
    "             }\n",
    "    \n",
    "    \n",
    "val_loader  = get_dataloader(Xtest_trial, 8,valid='valid', **argsval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 57s, sys: 20.5 s, total: 6min 17s\n",
      "Wall time: 5min 42s\n"
     ]
    }
   ],
   "source": [
    "%time results = generator(my_model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 17s, sys: 17.3 s, total: 7min 34s\n",
      "Wall time: 6min 52s\n"
     ]
    }
   ],
   "source": [
    "%time results = generator(my_model, val_loader) # 600, 5 bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kNpZ1c5TBmqD"
   },
   "source": [
    "#### Visualizing examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GkwqzhhvEXqt"
   },
   "source": [
    "**Example 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'In the World Cup in Mexico in 1986, England came up against Argentina in the quarter finals. The game took place four years after the Falklands War. The two countries were not best pals.\\n\\nSix minutes into the second half, Diego Maradona punched his way into history in a way Audley Harrison never quite managed. A few minutes later he scored one of the greatest goalsof all time, but the English prefer not to dwell on that one.\\n\\nBut what if the first goal had been disallowed? How might things have gone down?\\n\\nSix minutes into the second half and Maradona cuts inside from the left and plays a diagonal pass to Jorge Valdano on the edge of the area. The pass is slightly behind Valdano and England s Steve Hodge goes to hook the ball clear. He miscues it terribly and El Diego, having continued his run into the box, jumps in the air and uses his left hand to knock the ball past Peter Shilton in goal.\\n\\nThe infringement is so blatant that Tunisian referee Ali Bin Nasser cannot fail to spot it. And, indeed, he does not. Maradona is shown a red card for this blatant act of gamesmanship. Shilton and Hodge have a brief argument about who was at fault before Gary Lineker separates the pair.\\n\\nArgentina, without their captain and talisman, fall to pieces. Lineker gives England the lead on 72 minutes with a typical poacher s goal before heartthrob Peter Beardsley adds a second late on.\\n\\nMaradona, pictured in the changing room, looks distraught. In a post match interview with an Argentinian television station, he claims the mistake was the fault of the hand of Satan . Effigies are burned all over Buenos Aires and the team travels home in disgrace.\\n\\nEngland play Belgium in the semi final and an iconic photograph is taken of Glenn Hoddle surrounded by opposition defenders. The English triumph before losing to West Germany in the final on penalties. A distraught Bobby Robson breaks down in tears when interviewed by the BBC after the game.\\n\\nFour years later, Argentina win the World Cup in Italy. The German media suggests that their national team suffered from complacency having won the previous tournament. En route to the final, naturally, they beat England on penalties.\\n\\nMaradona is entirely rehabilitated and the Argentinian public builds statues in his honour. He scores the winner in the final and celebrates by imitating his famous handball from years earlier. The fans are delighted, because everything is so much funnier when you re winning.\\n\\nWant to read more about El Diego? here are 29 things you might not know about him.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_trial.iloc[0,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "6eQnF1XN_T8r",
    "outputId": "2f75a808-e1ea-44bd-c636-1e1d6a007111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'In theWorld CupinMexicoin 1986, England came up againstArgentina in the quarter finals. The game took place four years after the Falklands War. The two countries were not best pals. Six minutes into the second half,Diego Maradona punched his way into history in a wayAudley Harrisonnever quite managed. A few minutes later he scored one of the'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "colab_type": "code",
    "id": "PNXoHiQjBjAY",
    "outputId": "ee260cb0-641e-46ce-9a69-bd2ea8441a4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Diego Maradona s late goal in the quarter final was disallowed, but what if his first goal had been disallowed?'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xU7pMWeEfh8"
   },
   "source": [
    "**Example 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "g_K3Q-5GB92N",
    "outputId": "3b960f64-d419-41ab-bdf2-df342e9711ef"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'updated 07 30 2014 at 03 10 PM EDT\\n\\nIt s one of the paradoxes of globalization many of the people who produce the raw materials for products we take for granted can t afford to buy those products themselves.\\n\\nTake the case of cocoa farmers in the Ivory Coast, the world s leading exporter of cocoa beans. \\n\\n, only 3 of the money you pay for a chocolate bar makes it back to the farmers who grow the beans. The rest goes to the people further up the supply chain, the ones who transform the beans into chocolate and sell it it stores across the globe. Ivory Coast farmers make roughly 10 a day, putting a 2 chocolate bar out of reach.\\n\\nSo it was a heartwarming occasion when\\n\\n, a reporter for the Netherlands \\n\\n, traveled to the Ivory Coast to introduce cocoa farmers to the sweet taste they d helped bring into the world.\\n\\nwho had never seen the iPads he helped produce, this one appears to be legit. As N Da Alphonse, the first farmer in the clip, explained, he knew his cocoa beans were turned into food, but he never knew exactly what kind.\\n\\nWhen he tasted Kouassi s chocolate bar for the first time, his eyes lit up. Delicious! he exclaimed.\\n\\n I did not know that cocoa was so yummy, he told Kouassi.\\n\\nLater, Alphonse introduced some of his laborers to the chocolate. White people are addicted to it, he told them.\\n\\nJust like Alphonse, the men were enthralled.\\n\\n We complain because growing cocoa is hard work, said one. Now we enjoy the result. What a privilege to taste it. \\n\\nA woman holding cherry pie'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_trial.iloc[1,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "l_CBGaOSBvmL",
    "outputId": "1b18480c-dc94-4d98-dbd5-fada568312d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Farmers in the Ivory Coast can t afford to buy the chocolate they help produce'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "ITAC0YvZB0um",
    "outputId": "bff5f8b7-b225-44fa-f28a-91cfa698469d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Cocoa farmers in the Ivory Coast are bringing their sweet taste to the world. Here is a video of them making chocolate bars'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OuLET9kiEkTa"
   },
   "source": [
    "**Example 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "s6eSs1ZWD_sD",
    "outputId": "f9af3dd9-6e7a-4c32-9aa4-7a024bb8607e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'For Isaac Owusu, a widower, the revelation has forced him to rethink nearly everything he had taken for granted about his life and his family.\\n\\nIt has left him struggling to accept what was once unthinkable that his deceased wife had long been unfaithful that the children he loves are not his own and that his long efforts to reunite his family in this country may have been in vain.\\n\\nThe State Department let his oldest son, now 23, come to the United States last fall, but said the others a 19 year old and 17 year old twins could not come because they are not biologically related to him.\\n\\nIsaac Owusu, who asked that only his first and middle names be published because he would like to keep his family s pain private, is still hoping the government will allow the teenagers to join him, arguing that he has been a devoted stepfather, if not a biological parent.\\n\\nBut in recent months, he says, he has simply unraveled.\\n\\n Sometime when I get in bed, I don t sleep, said Isaac Owusu, 51, who works for an electrical equipment distributor and an auto supply shop.\\n\\n I say to myself, Why this one happen to me? he asked, his eyes wet with tears. Oh, mighty God, why this one happen to me? \\n\\nA similar sense of shock is reverberating through other families across the country as genetic testing becomes more common. State Department and Homeland Security Department officials do not keep statistics on the number of DNA tests taken by new citizens or permanent residents, who are allowed to bring some close relatives to the United States if they can document their family ties.\\n\\nBut Mary K. Mount, a DNA testing expert for the A.A.B.B. formerly known as the American Association of Blood Banks estimates that about 75,000 of the 390,000 DNA cases that involved families in 2004 were immigration cases. Of those, she estimates, 15 percent to 20 percent do not produce a match.\\n\\nNegative results can suggest an effort to bring in illegal immigrants or distant relatives, officials say, though they note that requests for DNA tests deter illicit activities. An official, who spoke anonymously because he was not authorized to discuss the cases, found no indication of wrongdoing by the families interviewed for this article.\\n\\nSuch genuinely unexpected results hit immigrant families particularly hard because DNA testing sometimes provides the best chance of reuniting with loved ones abroad.\\n\\n Sometimes these are complicated families, said Tony Edson, a deputy assistant secretary of state. People are learning things that they never knew about themselves. \\n\\nIn California, for example, a Mexican American family splintered after a DNA test showed that a young woman, a new citizen, was not related to the man she considered her father. The man, who was living in the United States, was ordered back to Mexico because his visitor s visa had expired.\\n\\nIn Maryland, a man from Sierra Leone discovered that his baby back home was the product of a hidden trauma. His wife, who was separated from him during their country s civil war, had been raped by rebels. In her shame, she had never revealed the truth.\\n\\nNew citizens and permanent residents are asked not required to take the tests if they lack documentation of ties to relatives overseas. Physicians designated by the State Department typically collect samples from relatives abroad and send them to this country for testing.\\n\\nA negative result does not eliminate the possibility of reunification. New citizens can adopt children under 16 and bring them to the United States, officials say. They can also petition for stepchildren or stepparents in certain circumstances.\\n\\nBut immigrants say officials rarely notify them of such alternatives. Meanwhile, lawyers say the government s growing reliance on DNA testing burdens immigrants who often pay 450 or more to test parent and child.\\n\\nOfficials counter that the process helps reunify families who might otherwise remain divided because they lack adequate documents. But they acknowledge that genetic testing can carry an emotional toll.\\n\\nTamara Gonzalez, a new citizen from Jamaica, said her test result has forced her to question her very identity.\\n\\nShe and her father, who lives in Jamaica, took the tests last year after she applied to bring him to the United States. When she learned they were not related, she confronted her mother, who said the result must be a mistake.\\n\\nMrs. Gonzalez, who works at a day care center in Brooklyn, said she would like to believe her mother. But she said her faith in her family bonds had been shaken. It changes my sense of who I am, said Mrs. Gonzalez, who is 31. And it has changed things between me and my mother. \\n\\n I wonder now if there s something she s hiding or not saying, she said. I start to wonder Who is my father? Am I ever going to know? \\n\\nClevy Muir, the man she knows as her father, says he is still trying to sort out their options.\\n\\n I m not going to give up my daughter, you understand? he said. But where can I turn? \\n\\nBalfour Francis, a 44 year old Jamaican born welder in Brooklyn, had even set aside a bedroom for the teenager he considers his daughter. She was born to a woman he had never married, but he had never doubted that she was his baby girl.\\n\\nThen came last year s DNA results. Now, he said, the bedroom is used for storage while he struggles to get immigration officials to tell him what he can do next.\\n\\n I will not let anybody dictate who is my child, said Mr. Francis, who is a permanent resident and has a wife and children in New York. I try to assure her I am who I will always be. \\n\\nMeanwhile, Isaac Owusu cannot keep the faces of his boys in Ghana out of his mind.\\n\\nThey call him collect on weekends, begging him to explain why he left them behind. At night, he sees them in his dreams with those big brown eyes that everyone used to say resembled his own.\\n\\n They ask me, Why? Why? Why? he said. You come and pick up our senior brother. What about us? \\n\\nHe blames the bureaucracy for the delay because he cannot bear to tell the truth. They are already motherless, he said. How can he tell them they are fatherless now, too?\\n\\nOver the years, while his sister cared for the boys, he has sent money for tuition and uniforms, doctors and food. He has saved their letters. Father, in Ghana we are in the rainy season so I need two thing, one son wrote, rain coat and rain boot. He has pored over their report cards Obedient and respectful, one teacher wrote , urging them to study harder so they could succeed here.\\n\\nHe moved, with a new wife, from an apartment to a house to make room for them all, and became a citizen in 2002. But last year s DNA tests dashed his hopes for a speedy reunion.\\n\\nAfter months of inquiries, Elizabeth M. Streefland, his immigration lawyer, finally determined that he could petition for the teenagers as their stepfather. He must prove that the boys are the children of his deceased wife. Isaac Owusu hopes that a DNA test of one of his wife s siblings, which could be compared with that of the teenagers, would provide that proof.\\n\\nThat will cost more money. But he says he simply cannot give up on his boys. I tell them, Daddy still loves you, he said. Anything it takes, I will do to get you over here. \\n\\nA version of this article appears in print on , on Page A1 of the New York edition with the headline DNA Tests Offer Immigrants Hope or Despair. Order Reprints Today s Paper Subscribe'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_trial.iloc[3,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "QTOwXNrqDUMp",
    "outputId": "22ea1bef-0ee9-41e4-9424-1747acabab9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Genetic tests are forcing some immigrant families to confront unexpected and sometimes unbearable truths.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "colab_type": "code",
    "id": "8KPpq-pUDcfe",
    "outputId": "f8042bcb-cf9a-4b20-88c9-df472a921934"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Isaac Owusu, a widower who was told his death would be the result of genetic testing. But is it possible to bring relatives close?'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C0TEEYozZ0wm"
   },
   "source": [
    "**Example 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J8J_ZRKZZ0wm",
    "outputId": "283a7426-78d2-4302-c7eb-8f435462639d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Their personalities contrast as starkly as their styles Smith is genial and expressive, Boldin private and intense but they are bonded by their past, by adversity that shaped them then, that influences them now.\\n\\nFor Smith, his electrifying performance in Denver was his most complete game since Sept. 23, when he carved up the Patriots with 6 catches for 127 yards and 2 touchdowns in a 31 30 victory. On Wednesday, he explained his success by saying, I just happened to play well against them. \\n\\nReceiver Jacoby Jones offered a different reaction.\\n\\n I told him, Man, I look up to you, Jones said. I couldn t have done what you did. \\n\\nJust before midnight on Sept. 22, Smith s younger brother Tevin Jones, 19, crashed his motorcycle into a utility pole in their native Virginia. He died at the scene. Smith left the Ravens hotel about 2 a.m. and raced home to grieve with his family. About 12 hours later, after barely sleeping, he rejoined his teammates. Kevin Glover, the longtime N.F.L. center who became a confidant of Smith s while working in Maryland s athletic department, attended the funeral. There, Smith presented his family with two footballs, from his touchdown catches against the Patriots.\\n\\nThat he had the courage to play and the focus to play well did not surprise those who know Smith best, those who know the details of a turbulent childhood that left him caring for his six younger siblings.\\n\\n He is so mentally tough, and I imagine it s because he s had to compartmentalize his entire life, said Vanderbilt Coach James Franklin, who was Smith s offensive coordinator at Maryland for three seasons. He s used that energy and passion and emotion for his benefit. \\n\\nFrom an early age, Smith did his siblings laundry. He changed their diapers. He fed them his proficiency in the kitchen earned him the nickname the Microwave King, from his mother, Monica Jenkins. She worked two jobs, and for a while she was involved in an abusive relationship with a man who was not Smith s father.\\n\\nThat humble upbringing produced a young man with no ego, said friends and coaches. Roger Pierce, Smith s coach for three years at Stafford High School in Virginia, remembers the day Tom Brattan, a coach at Maryland at the time, came to visit, and Smith transported a special needs student down a congested hallway.\\n\\n That s just who Torrey is, Pierce said. Always responsible for other people. \\n\\nAt Maryland, Smith shuttled between campus and his family whenever time allowed. He never missed class, practice, a team function. Once, he asked Dwight Galt, the strength and conditioning coach, who was then unaware of Smith s family circumstances, if he could work out early on Fridays so he could go home. Told no, Smith lifted with his group, then bolted to Virginia.\\n\\n It went on like this for about a year before he finally told me that he was going there to help out his brothers and sisters, Galt said. He wasn t embarrassed by anything. It was that it was part of his life, and he took care of it like he takes care of everything. \\n\\nWhen asked whether he has always considered football an escape, Smith spoke specifically about his brother s death. He called escape a weird term.\\n\\n I feel like these guys are my brothers, he said. I m in here the same as when I was home. Even after my brother passed, I left home and came up here and the love was still the same. \\n\\nPlayers speak about the team s closeness, forged by leaders like Ray Lewis and Ed Reed and Matt Birk, by coaches who say, iron sharpens iron. They protect their own, which might be why Smith and Boldin, for that matter fits in so well. Boldin arrived in a trade with Arizona in March 2010. The deal did more than furnish Joe Flacco with a No. 1 receiver. It added one of the toughest players in the sport.\\n\\nBoldin, 32, grew up in Pahokee, a South Florida town afflicted by unemployment and poverty but a place where, Ravens defensive end Pernell McPhee said, you come out of the womb ready to play football. Boldin s parents divorced when he was 9, and his mother, Brenda Banks, worked late hours, including as a day care teacher in West Palm Beach, an hour s drive away. He saw football as a means to leave Pahokee, but he returns often, to donate turkeys or outfit a team with new equipment.\\n\\n He uses football to express his anger, said D. J. Boldin, his younger brother. When he s on the field, he just has that dominant spirit. \\n\\nHad it at Pahokee High School, where an assistant coach, Blaze Thompson, recalled Boldin s running into a pile of five or so defenders and coming out the other end, just dragging guys. Had it at Florida State, where he began a stellar career by scoring two touchdowns in his first game. Has it in the N.F.L., where few are better, Hostler said, at catching contested balls.\\n\\n If you continue to come at a guy during a game, mentally he s going to break down, said the longtime N.F.L. receiver Derrick Mason, who played with Baltimore in 2010. Anquan uses that to his advantage his big body, his physical presence, not giving up. Guys get tired covering him. \\n\\nOne play has come to define his toughness. On Sept. 28, 2008, when Boldin was playing for the Arizona Cardinals, Eric Smith of the Jets drilled him with a helmet to helmet hit. Boldin s head snapped back. His body crashed to the turf. His sinus membrane was fractured, requiring 7 plates and 40 screws to fix. Boldin came back a month later, missing only two games. D. J. was in the stands for his brother s return, at Carolina. On the Cardinals first drive, Boldin gained 30 yards on an end around. Rather than veer out of bounds to avoid contact, Boldin lowered his shoulder and drove into the defender.\\n\\n I was like, He just broke his face, said D. J., his voice rising. He didn t just come back. He came back fearless. \\n\\nIn that area, Boldin and Smith have much experience. Jacoby Jones calls Boldin Quan the Bully because of his physical, unyielding style. Smith recently printed for his teammates purple T shirts that read, FINAO Failure Is Not an Option. It is not. Not for either of them. Not for both of them.\\n\\nA version of this article appears in print on January 20, 2013, on Page SP3 of the New York edition with the headline Smith and Boldin Give the Ravens Dynamic Bookends at Wide Receiver. Order Reprints Today s Paper Subscribe'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_trial.iloc[4,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQrei0JEZ0wo",
    "outputId": "1aa75634-2780-49c7-d0c3-0adae8f78971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Torrey Smith, who turns 24 next Saturday, cites Anquan Boldin s tutelage as a major factor in his development, but theirs is a symbiotic relationship.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OJIYcxJ4Z0wp",
    "outputId": "04e4d05f-fc82-4171-80ca-3032539cbf25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'The star quarterback s career was his most complete game since Sept. 23, when he carved up the Patriot defense with 6 catches for 127 yards and 2 touchdown passes in a 31 30 victory over the Ravens on Wednesday night, but it was his most complete performance since Sept'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'One of the most enduring stereotypes in the American workplace is that of the queen bee the executive female who, at best, doesn t help the women below her get ahead and, at worst, actively hinders them. This supposed species has been analyzed in newspaper essays, described in surveys and caricatured over and over again in Hollywood.\\n\\nBut a recent study casts doubt on the idea. Researchers at Columbia Business School and the University of Maryland s business school looked at what happens after a woman gets one of the five highest paying executive jobs at an SandP 1500 firm. They found that it decreased the probability of another woman also getting a top position by 51 percent though not for the reason often cited.\\n\\nGiven the queen bee stereotype, people have often posited that the woman at the top might be trying to hold other women back from joining her. Yet the researchers suggest that their findings instead suggest the culprit is implicit quotas, in which companies feel pressure to add women to their uppermost ranks to improve their public image but once they ve added one, they feel like they ve done their job.\\n\\n They try pretty hard to get a woman on their top management team, but then they will stop, said David Ross, a co author of the study. What I think our paper shows is that it s going to be harder for the low number of women in top management to be a problem that solves itself. \\n\\nPart of what supported their finding was that in companies where a woman was the CEO, rather than just a senior member of the team, other women actually had somewhat better chances of holding other top positions. If women are doing each other in, Ross said, you d expect to see it the most when women are CEO. \\n\\nThe paper, which is set to be published in the Strategic Management Journal, first got attention a few months ago but resurfaced this week since its findings will be presented at an upcoming conference of girls schools in the United Kingdom. Some headlines have said this research shows the queen bee syndrome is a myth, but Ross says the idea of implicit quotas doesn t exactly disprove the other argument, it just weakens it.\\n\\n We don t know if the queen bee syndrome exists, but if it exists it could well exist because of sexism, Ross said. If women are competitively vying for top positions, it s not arising from some kind of innate female quality, but from the behavior of the men and their colleagues. \\n\\nMeanwhile, there s other evidence that women may actually pay it forward to the next generation even more than men do. A 2012 study from the research firm Catalyst found, for instance, that 73 percent of the female mentors it studied were helping develop other women, whereas only 30 percent of the male mentors were doing the same.\\n\\nWomen, though, while perhaps more likely to help other women, aren t necessarily more likely to be in mentorship positions to begin with. A survey last year from the human resources consulting firm Development Dimensions International found that as many as 20 percent of the women it surveyed had never been asked to be mentors despite that most held management roles , and more than 50 percent had only been asked a few times.\\n\\nSharon Mavin, director of the business school at University of Roehampton in London, has also found in her research that women are readily open to helping and mentoring other women. The problem isn t an unwillingness to help, she said in an interview, but that when there are only one or two women at the top, there s not enough momentum for the culture that s already been established to change.\\n\\nMavin, who has also written about the queen bee phenomenon, added For a woman to survive in that context, there s a lot of strategies she can take. But a lot of them mean assimilating into that culture rather than changing it. \\n\\nHow much do women really help other women in the workplace?\\n\\n Queen bee CEOs get scrutiny and flak while king wasps get a free pass\\n\\nLike On Leadership? Follow us on Facebook and Twitter, and subscribe to our podcast on iTunes.\\n\\nJena McGregor writes a daily column analyzing leadership in the news for the Washington Post s On Leadership section.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_trial.iloc[5,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'A recent study casts doubt on the the long held stereotype that women who get ahead don t help other women.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'A new study suggests that the queen bee is a problem. But it may actually help women get ahead and at worst actively hinder them, too'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Louisiana Gov. Bobby Jindal will again carry the Republican mantle opposite a primetime appearance from President Obama on Tuesday.\\n\\nJindal, considered a potential GOP presidential candidate, is slated to headline a major congressional fundraiser that coincidentally fell on the same night as Obama s planned news conference.\\n\\nJindal was widely panned for his televised response to Obama s address to Congress last month. This time, he will speak to a live audience of Republican faithful in Washington. And his speech scheduled well before Obama s news conference will likely begin before Obama s evening remarks.\\n\\nJindal is likely to criticize Obama s 3.6 trillion budget request, which Republicans have repeatedly said borrows too much, spends too much and taxes too much. \\n\\nIn his response to Obama address last month, Jindal criticized the president s 787 billion economic stimulus package as laden with unnecessary spending that had been added by a Democratic Congress. He talked of the need to cut taxes and limit government spending at a time when polls show a majority of Americans are looking to the federal government to reverse the economic downturn.\\n\\nPolitical commentators, comics and bloggers derided the speech as simplistic, too sing songy and out of step with the American public.\\n\\nThe 37 year old governor has defended his speech, saying he sticks by the message, while acknowledging shortcomings in his delivery.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_trial.iloc[6,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Louisiana Gov. BobbyJindal is slated to headline a major congressional fundraiser that coincidentally fell on the same night as President Obama s planned news conference.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Louisiana Gov. Bobby Jindal will again carry the Republican mantle opposite a primetime appearance from President Obama on Tuesday, according to his presidential address at Congress last night'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'It s The Lyttleton Inn in Littleton, Mass., according to BedandBreakfast.com.\\n\\nThe inn took first price in BedandBreakfast.com s first Breakfast Recipe Challenge with its bittersweet chocolate waffles with mint buttercream and strawberry sauce.\\n\\nSeems as if voters like to start the day on a sugary note That confection barely beat pumpkin pancakes with caramelized pecans, whipped cream and ginger syrup, served at the Gracehill Bed and Breakfast in Townsend, Tenn.\\n\\nWant to see all 16 finalists or get a copy of the competing recipes? I like the one for lobster frittata at The Mill House Inn in East Hampton, N.Y. Click here.\\n\\nWinners were selected by BedandBreakfast.com s Facebook fans. More than 2,500 votes were recorded.\\n\\nFunny that sweet beat savory, because in a survey of BandB travelers, BedandBreakfast.com found that the bacon and eggs were the top breakfast choice 47 of votes , followed by carbs pancakes, waffles, bagels , fruit yogurt, granola and other cereals.\\n\\nReaders, care to share a BandB breakfast favorite you ve experienced?'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_trial.iloc[7,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Bedandbreakfast.com had a recipe contest. So which won? The chocolate waffles or pumpkin pancakes?'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'It s The Lytleton Inn in Littletown, Mass., according to BedandBreakfast andmdash the inn took first pricein Bedandrsquo s first Breakfast Recipe Challenge with its bittersweet chocolate waffle'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'An outsider might think Jami Rodman ruined the life of Suzy Favor Hamilton as a powerful madam in Las Vegas, Rodman took the former Olympian in as a call girl, leading to the explosive expose of their sex service in 2012 that put them out of sex work for good.\\n\\nBut Rodman tells the Daily News she and Hamilton are still good friends, so much so that Hamilton inspired Rodman s upcoming book about her hooker world history, The Las Vegas Madam The Escorts, The Clients, The Truth. \\n\\nHamilton encouraged me to work on the book, Rodman, 37, said. I think because a lot of it would be very cathartic. It s that whole theory of writing a diary to help understand yourself. \\n\\nRodman s book, which she s self publishing, comes out Dec. 11 just three months after Hamilton s own memoir, Fast Girl A Life Spent Running from Madness, which hits shelves Tuesday. Rodman calls it a coincidence.\\n\\nHamilton s book has been hyped as a wrenching recollection of the demons that drove the three time Olympic track and field star to working as a 600 an hour Vegas prostitute. Early word on Fast Girl says Hamilton points to her postpartum depression and then undiagnosed bipolar disorder as the biggest reasons she switched from competitive running to streetwalking. She told People this week sex was the biggest high to fuel my mania. \\n\\nNone of that will be news to Rodman, who says she has already read Fast Girl and didn t sense any negativity from Hamilton in its pages.\\n\\n We didn t write tell alls about each other, Rodman said.\\n\\nWhich is not to say she s done defending the role she played in Hamilton s once secret second life.\\n\\n Finding escorting is probably what saved her, because she would have found another outlet elsewhere, like drugs or having affairs, Rodman said when asked about Hamilton s mental health problems.\\n\\nJami Rodman s memoir The Las Vegas Madam is due out in December. Rodman s former escort Suzy Favor Hamilton, an ex Olympian, is releasing her memoir Fast Girl Tuesday.\\n\\n It if was bad for her, she would have stopped. This is a free country. None of the people I know were coerced into doing anything she didn t want to do. \\n\\n Reps for Hamilton, who now works as a yoga instructor, did not return request for comment. \\n\\nRodman said she was aware Hamilton was troubled when they started working together in 2011, but not in any way that seemed to stand out in their colorful line of work.\\n\\n I definitely saw the manic behavior . but most people who come to Vegas for an extended period of time show similar behavior, she said. They drink all the time, they stay out all hours, shop all the time it s just the whole atmosphere of Vegas. I didn t realize Sue was as manic as she was. \\n\\nThat said, Rodman isn t trying to focus much of that relationship she says little of The Las Vegas Madam talks about Hamilton. For the most part, it s about the decade that Rodman, a native of small town Oregon, spent working her way up from a call girl to a madam overseeing nearly 30 escorts in her now defunct business, Haley Heston s Private Collection.\\n\\n It s an erotic book, Rodman said. It has some very similar characteristics to 50 Shades of Grey. \\n\\nShe s keeping the dirty details to herself for now, but stated simply I really liked sex. It s like riding a bike you do it once and you do it again and again and again. Then you take off the training wheels and start exploring. \\n\\nThat wild ride eventually crashed, after a Smoking Gun story outed Rodman as the Haley Heston who employed a pricey staff of call girls, including Hamilton, who went by Kelly and was one of the service s most in demand girls. The operation unraveled soon afterward.\\n\\nRodman said she and Hamilton still hang out for hiking and surfing trips. Like Hamilton, Rodman says she s also trying to start a new, calmer life, working on a bachelor s degree at a northern California college. And, like her one time top escort, she s hoping her book can do some reputation repairing.\\n\\nBut Rodman says she has no regrets about her time in the Vegas sex business and, after getting it all on paper, she has no nostalgia either.\\n\\n I went to every little dark hole of that city I had a great decade and I had a lot of fun, but I m here now, she said. I had an absolutely amazing time there, and I ran it into the ground. \\n\\nON A MOBILE DEVICE? WATCH THE VIDEO HERE.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_trial.iloc[8,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Jami Rodman s book The Las Vegas Madam, out in December, tells the story of the madam who hired the former Olympian as a hooker.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Jami Rodman s new book, Fast Girl A Spy Running from Madness, hits shelves Dec. 11. She says she and Hamilton are still good friends'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'A Bangladeshi father nicknamed Tree Man for massive bark like warts on his hands and feet will finally have surgery to remove the growths that first began appearing 10 years ago, a hospital has said.\\n\\nAbul Bajandar, from the southern district of Khulna, was undergoing preparations for the surgery to cut out the growths weighing at least 5kg 11lb that have smothered his hands and feet.\\n\\n Initially, I thought that they re harmless, the 26 year old told AFP at the Dhaka Medical College hospital. But slowly I lost all my ability to work. There are now dozens of two to three inch roots in both my hands. And there are some small ones in my legs, said Bajandar who was forced to quit working as a bicycle puller.\\n\\nA team of doctors will perform the operation at DMCH, Bangladesh s largest state run hospital, which has decided to waive the costs of the treatment. Tests are under way to ensure Bajandar s warts can be removed surgically without damaging major nerves or causing any other health problems.\\n\\nThe warts, which first started appearing when he was a teenager but began spreading rapidly four years ago, have been diagnosed as epidermodysplasia verruciformis, an extremely rare genetic skin disease that makes the person susceptible to skin growths.\\n\\n Popularly it is known as tree man disease, the DMCH director, Samanta Lal Sen, told AFP. As far as we know there are three such cases in the world including Abul Bajandar. It is the first time we have found such a rare case in Bangladesh, he said.\\n\\nAn Indonesian villager with massive warts all over his body underwent a string of operations in 2008 to remove them.\\n\\nBajandar s elder sister, Adhuri Bibi, said hundreds of people have visited their home in Khulna over the years to see him. Even here at the hospital, hundreds have already gathered, she told AFP.\\n\\nBajandar said he tried cutting the warts when they first appeared, but it was extremely painful. After that I went to a village homeopath and herbal specialist. But those medicines only worsened my condition. \\n\\nHe also consulted doctors in neighbouring India, but he and his family could not afford the cost of an operation there.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_trial.iloc[9,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Abul Bajandar preparing for operation to remove extremely rare epidermodysplasia verruciformis warts'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'A Bangladeshi father nicknamed Tree Man for massive bark like warts on his hands and feet will finally have surgery to remove the growth that first began appearing 10 years ago, a hospital has said.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'By now all of us have heard the ominous warnings about the unraveling of the social safety net. But what does this really mean? And what can we as private citizens who have also been both personally and professionally deeply affected by the financial crisis do to repair it?\\n\\nThe social safety net encompasses the array of health and human services provided by state and local authorities. As the economic crisis causes state budgets to contract, funding for these services plummets, and the net that we collectively rely on to catch us from falling into extreme poverty begins to unravel. To be sure, private donors alone cannot single handedly save vital community services, but for those of us interested in maximizing the value of our charitable dollars in a time of crisis, investments in social service agencies can offer meaningful returns.\\n\\nLast month, Giving USA reported the largest decline in charitable giving in the U.S. Most alarming was the data showing a nearly 16 decrease in the amount given to social service agencies organizations that provide direct services to address basic human needs like food banks, job training centers and homeless shelters. Demand for these services has spiked over the past few months due to the growing number of the hungry, unemployed and homeless among us at the same time, state budgets across the nation are shrinking.\\n\\nFollow Intelligent Investing on Twitter\\n\\nSign Up For the Weekly Intelligent Investing Newsletter\\n\\nThe Center for Budget and Policy Priorities estimates that at least 36 states to date have cut social services since the recession began services that affect all of us the elderly, students, children, the employed and the jobless. At least 19 states have implemented budget cuts that will affect low income children or family eligibility for health insurance or reduce their access to health care services.\\n\\nAt least 21 states plus the District of Columbia are cutting rehabilitative medical home care or other services needed by low income people who are elderly or have disabilities. In my home state of Illinois, the proposed budget slashes in half funding for human services, leaving thousands of working mothers without child care and seniors without the services they require to stay in their homes.\\n\\nWhere is the federal government in all this? Through the American Recovery and Reinvestment Act, 50 million has been approved to help nonprofit organizations address the needs of disadvantaged and hard to reach populations suffering economic hardships.\\n\\nThis Strengthening Communities Fund has been established to build the capacity of nonprofit organizations both secular and faith based to address the broad economic recovery issues present in their communities, including helping low income individuals secure and retain employment, earn higher wages, obtain better quality jobs and gain greater access to state and federal benefits and tax credits. But this pot of money can only go so far, and deserving nonprofits have been pitted against each other in fierce competition for a piece of the pie.\\n\\nSo, what are the options? The starting point for donors is to revisit our giving strategies and to consider refocusing dollars where they can do the most immediate good. For example, rather than earmarking contributions for specific programs or giving multi year pledges to a charity s endowment, consider converting these funds into an immediate gift of operating support.\\n\\nCovering administrative costs may not feel like the most meaningful gift, but as my clients will tell you, organizations are never so grateful as when they receive the funding to keep the lights on and the doors open. At the end of the day, this core support enables them to deliver services to the neediest populations.\\n\\nAs executives, we can encourage our companies to continue and even enhance their commitments to social responsibility. At a time when the public has lost faith in the corporate sector, the economic crisis is viewed as a test of how genuine a company s commitment is to the greater good.\\n\\nThe good news for companies is that this commitment need not always be demonstrated by cash contributions nonprofit organizations are in need of assistance beyond the check. An April 2009 national survey of nonprofit organizations conducted by Deloitte found that only 22 of the organizations surveyed received assistance beyond a monetary donation, yet 95 reported a need for in kind contributions of white collar professional skills.\\n\\nBy donating pro bono services such as accounting, information technology and marketing assistance, you can help build the capacity of local social service organizations to serve those in need in the face of diminished government funding. Citi Foundation, run by struggling Citigroup C news people which is now one third owned by the federal government, recently reported plans to reduce its giving to microfinance, education and other causes by about one third a decline of roughly 25 million. But to offset some of this loss in funding, it intends to offer additional pro bono financial management advice to struggling charities.\\n\\nAnother option is to donate office equipment or to provide office or meeting space for local groups. Offering pro bono and in kind support can foster long term corporate nonprofit partnerships that serve not only to prop up organizations through the economic crisis but also to sustain them for the long term as they work to carry out their missions.\\n\\nThe old adage, There are no problems, only opportunities, is accurate in the current economic environment. Donors have a real opportunity to make their philanthropic dollars go further by strategically investing in the local social service agencies that sustain healthy and productive communities and support the most needy among us.\\n\\nSee More Intelligent Investing Features'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_trial.iloc[15,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Betsy Brill discusses what people can do to repair the unraveling social safety net.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'By now all of us have heard the ominous warnings aboutthe unravelingof social safety net. But what does this really mean? Andwhat can we as private citizens who'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4KX71gPzy_bH"
   },
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "rdMr6tAWFpG8",
    "outputId": "a0b7677b-be23-49cf-e215-d3f9b566084c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.15.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install rouge\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n-2UrHbnZ0wt",
    "outputId": "eb5d2867-4a2c-4d88-bf4e-44f6871e5dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from rouge-score) (3.2.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rouge-score) (1.18.5)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from rouge-score) (0.10.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from rouge-score) (1.15.0)\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install rouge-score tqdm\n",
    "from rouge_score import rouge_scorer, scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ter9ktdQ6_54"
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def get_score(summaries) -> Dict:  \n",
    "    \n",
    "    src_labels = summaries['golden_summary']\n",
    "    gen_summary = summaries['generated_summary']\n",
    "    \n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1','rouge2','rougeL'], use_stemmer=True)\n",
    "    aggregator = scoring.BootstrapAggregator()\n",
    "    \n",
    "    for src, gent in zip(src_labels, gen_summary):\n",
    "        scores = scorer.score(gent, src)\n",
    "        aggregator.add_scores(scores)\n",
    "        \n",
    "    results = aggregator.aggregate()\n",
    "    return {key: val.mid.fmeasure for key, val in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jfhyTtEwZ0ww",
    "outputId": "65e760cf-5c1d-4b3c-b73a-532fbfcf56fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.37884463730331164,\n",
       " 'rouge2': 0.22701712662455636,\n",
       " 'rougeL': 0.3251312465423435}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(results) # 700, 8 bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.37879043141411406,\n",
       " 'rouge2': 0.22828057620565184,\n",
       " 'rougeL': 0.3269038025069393}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(results) # 600, 5 bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6UtF_jowZ0wz",
    "outputId": "e969fe82-4e50-472f-d4ed-68a810008fbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': 0.3436117352541544,\n",
       " 'rouge-2': 0.2096320892460095,\n",
       " 'rouge-l': 0.3277109454445723}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "\n",
    "score = rouge.get_scores(results['generated_summary'], results['golden_summary'], avg=True)\n",
    "{key: val['f'] for key, val in score.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'rouge-1': 0.23891854897729273,\n",
    " 'rouge-2': 0.10855931785640041,\n",
    " 'rouge-l': 0.21982563644064748}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'rouge-1': 0.2934569607894014,\n",
    " 'rouge-2': 0.16207342615668757,\n",
    " 'rouge-l': 0.2762959592687011} #0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SuKNdMkjZ0w1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Final_Project",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "pytorch-gpu.1-4.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00632d7b23cc45f59515669601334fcd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "007752d9ce5e47f480ae606afeb2cd16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02d1d8ffcf3a4873880bb4ec2b7eefbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a0883324f8b4256adf0e8a54c77524f",
      "placeholder": "​",
      "style": "IPY_MODEL_1f778937b7484fac8de6530ea10a5470",
      "value": " 150/? [2:07:40&lt;00:00, 51.07s/it]"
     }
    },
    "04619e3db74847f5b637c7d2b1d5b8b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0551f8a91cb547948703416f5c200c93": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cdd1f83587643f68b9cc4659ba75fb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9efdf4e9fd8c42598cced165c426f5bf",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_598b0d3d4ba64ed48d511ce9dd360f64",
      "value": 1
     }
    },
    "1523672396354424b0658ce14786fbd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_864cb033af344f22b288a320088ec71c",
      "placeholder": "​",
      "style": "IPY_MODEL_ffc60b07ad704ea2afc0ac2c79c10c11",
      "value": " 150/? [01:24&lt;00:00,  1.77it/s]"
     }
    },
    "17e87d4a9a974aa6828c5ae0f9e0cf3a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1cbf0dd906ac41e985bd752f526fa2d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6005029df2504711a96df12e14290100",
      "placeholder": "​",
      "style": "IPY_MODEL_41ceec6b9c214b18891c8ab915d5c19c",
      "value": " 150/? [01:09&lt;00:00,  2.17it/s]"
     }
    },
    "1f778937b7484fac8de6530ea10a5470": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2004cd6b66034fdda39e09c4ea44b3ce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "200ba008099045719694899c681c2d16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22e8567701184b729be80c57098badc4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "267a56c7a2f542e3b24a5f790491a550": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_db85fdb064634d80b1904313a3b81ddb",
       "IPY_MODEL_1cbf0dd906ac41e985bd752f526fa2d4"
      ],
      "layout": "IPY_MODEL_dc94b3b543714dd0845fdadca7db22a3"
     }
    },
    "268c4187cfc9490bacfa1eafe1fbcca1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2732c77700724db3beb39d1c64469852": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a504d4571ae54c97a6fb586051f17b07",
      "placeholder": "​",
      "style": "IPY_MODEL_f1010194505c44b588ba44a39e4afd9f",
      "value": " 150/? [01:09&lt;00:00,  2.16it/s]"
     }
    },
    "273de981090749b29ce385706c449722": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "27afa2d568d6441690a6d0ee44e40e1c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27deb6f565ac4447a44770288071a0b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a9728af9dcb4e67a1a006297cd7b74c",
      "placeholder": "​",
      "style": "IPY_MODEL_e94b124aaf674431b6e424b9c6c1da87",
      "value": " 150/? [01:26&lt;00:00,  1.73it/s]"
     }
    },
    "2d2b6b3effa34b809c30379c42c3c861": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad0c71bcf6d945098f04025bc52055f9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5605c8c2ad12431b88e1404953ecd6b9",
      "value": 1
     }
    },
    "2d96618428094902b80450d649566a66": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a33ce8bb19284323a89a317403263c0d",
       "IPY_MODEL_90937a3fdc314010948a13e9e2c70e40"
      ],
      "layout": "IPY_MODEL_c7a670342db348f0b703a95438137574"
     }
    },
    "2df67220b98547639c10a80ceb63b1ef": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f28dc0b45cc4b30acb85fecdc128397": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3008461ae4e440d081f2f3ac46afa685": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3353a6712b3a482d8907ca80a0824020": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "354fdd4a6e064367be8398d996b63d38": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22e8567701184b729be80c57098badc4",
      "placeholder": "​",
      "style": "IPY_MODEL_3008461ae4e440d081f2f3ac46afa685",
      "value": " 150/? [01:10&lt;00:00,  2.12it/s]"
     }
    },
    "37454b94184a4a10a9affa6e84e74f43": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3856954e8b1e47a08fce9fff7a038027": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c42fdea3dcd4f2bbd6ba10777f27db3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40ef9fea4c03417db6bdc76b480fb59e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b5212a3ed9f49aea201644e1ed1ac53",
       "IPY_MODEL_a637e9d5dda44c3e9c8c3b9154b1b20d"
      ],
      "layout": "IPY_MODEL_3c42fdea3dcd4f2bbd6ba10777f27db3"
     }
    },
    "41ceec6b9c214b18891c8ab915d5c19c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "430de0fcf9ce45799f8cec7b508a8f7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e2be21b2cc584489b535309b9c8904e3",
       "IPY_MODEL_354fdd4a6e064367be8398d996b63d38"
      ],
      "layout": "IPY_MODEL_99791d40ec534ebc9a7f4b01767f9aad"
     }
    },
    "471a09375e984a31824b27e279a6c4f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37454b94184a4a10a9affa6e84e74f43",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7a407d5347104eaa9ce6ec36250715d3",
      "value": 1
     }
    },
    "4778d193b45a4e2ca8871f19b195a26b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4800749f8151430c8cc49570cd4ccaf7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a42cbf2455346818c8fb92da5665bca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d3bd152e2b14612bdec4f9692d48739": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e394e72017442e989642afdc2b8abcb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "501fe7de2d29471c9ad3580ba42b274d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53c9e46489fc4d708c7fe856173f3b12": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0cdd1f83587643f68b9cc4659ba75fb8",
       "IPY_MODEL_2732c77700724db3beb39d1c64469852"
      ],
      "layout": "IPY_MODEL_27afa2d568d6441690a6d0ee44e40e1c"
     }
    },
    "5605c8c2ad12431b88e1404953ecd6b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "58d8bd8caffa47788931111cd5d05409": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58fa30020dc14801a78967796be9df3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_501fe7de2d29471c9ad3580ba42b274d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_89f6bfd52126419ab7c6b6ba00894c24",
      "value": 1
     }
    },
    "598b0d3d4ba64ed48d511ce9dd360f64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6005029df2504711a96df12e14290100": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61a4358811654212bd669c1c6c40b4cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2df67220b98547639c10a80ceb63b1ef",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7b8fca08cafe4f7e9ad9f519bb005fd1",
      "value": 1
     }
    },
    "63ff13ee95f64beea555e0660be15eec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6736870c4aa94b20adeed80a00507dce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "68ba61411c5d4097883b053f06493415": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6e1089fcff4a4ad19de6fc9dfb87c171": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0551f8a91cb547948703416f5c200c93",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f28dc0b45cc4b30acb85fecdc128397",
      "value": 1
     }
    },
    "7475bb3748de434eae59ef85715514da": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75b200a4d1cb4f1cab2204139ac8fff5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a0883324f8b4256adf0e8a54c77524f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a407d5347104eaa9ce6ec36250715d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7b8fca08cafe4f7e9ad9f519bb005fd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8365405f8a1c4d178b5ab5cd9d905e32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "838fc6b6bb704fd897d9145830d7bb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8503f63352114056ace6ee5662d746da": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "864cb033af344f22b288a320088ec71c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87a5e794f5ff408ebbf2a740a7560adb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "888804a45395411cb9db622b0e6878cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89f6bfd52126419ab7c6b6ba00894c24": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8b0a112033ab4a3a9a970c6eaaec5531": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8ef3688940ae4ff4840fc3ca4c231125",
       "IPY_MODEL_f7dd810e69fa4f1f91acaec17fb8c64a"
      ],
      "layout": "IPY_MODEL_9acb641a7ede4dd6b68097dbff290ce1"
     }
    },
    "8b5212a3ed9f49aea201644e1ed1ac53": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e394e72017442e989642afdc2b8abcb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7ccb000bd83423fb4693a908c638ddb",
      "value": 1
     }
    },
    "8ef3688940ae4ff4840fc3ca4c231125": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_838fc6b6bb704fd897d9145830d7bb9f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68ba61411c5d4097883b053f06493415",
      "value": 1
     }
    },
    "906c310a405b4822a19d206cf3467f9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_61a4358811654212bd669c1c6c40b4cd",
       "IPY_MODEL_917a8ab6a55b4cd382b1cd1982d5a227"
      ],
      "layout": "IPY_MODEL_75b200a4d1cb4f1cab2204139ac8fff5"
     }
    },
    "90937a3fdc314010948a13e9e2c70e40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2004cd6b66034fdda39e09c4ea44b3ce",
      "placeholder": "​",
      "style": "IPY_MODEL_a56cd84f576841259aace5b34b0efda7",
      "value": " 150/? [14:16&lt;00:00,  5.71s/it]"
     }
    },
    "90f39af76e9846b18c45633dce765584": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d2a4e7e937804562a63d0191223c0dd0",
       "IPY_MODEL_02d1d8ffcf3a4873880bb4ec2b7eefbf"
      ],
      "layout": "IPY_MODEL_4a42cbf2455346818c8fb92da5665bca"
     }
    },
    "917a8ab6a55b4cd382b1cd1982d5a227": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4778d193b45a4e2ca8871f19b195a26b",
      "placeholder": "​",
      "style": "IPY_MODEL_58d8bd8caffa47788931111cd5d05409",
      "value": " 150/? [01:08&lt;00:00,  2.18it/s]"
     }
    },
    "940db33506ef463788996553c4bf5f74": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9459d0d307814c34aa8a31945a82adb7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9712936912b84e498783132d111037bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e595378941654a4dbe560a646dc52272",
      "placeholder": "​",
      "style": "IPY_MODEL_9e0d68b268384372ae1ec48b6c363b3a",
      "value": " 150/? [1:39:19&lt;00:00, 39.73s/it]"
     }
    },
    "992143ed056d4a23afff16b83c514432": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99791d40ec534ebc9a7f4b01767f9aad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a9728af9dcb4e67a1a006297cd7b74c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9acb641a7ede4dd6b68097dbff290ce1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d3ae70779e447d0aa495a9872209d38": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e0d68b268384372ae1ec48b6c363b3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9efdf4e9fd8c42598cced165c426f5bf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2026ad15de541eebf332cb4ce4e1ad2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a33ce8bb19284323a89a317403263c0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2026ad15de541eebf332cb4ce4e1ad2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b506bbd1464b407980a6ef55a7819828",
      "value": 1
     }
    },
    "a504d4571ae54c97a6fb586051f17b07": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a56cd84f576841259aace5b34b0efda7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a633f4726f6a4ba5babb0e0414e6c5e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58fa30020dc14801a78967796be9df3e",
       "IPY_MODEL_9712936912b84e498783132d111037bf"
      ],
      "layout": "IPY_MODEL_007752d9ce5e47f480ae606afeb2cd16"
     }
    },
    "a637e9d5dda44c3e9c8c3b9154b1b20d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_200ba008099045719694899c681c2d16",
      "placeholder": "​",
      "style": "IPY_MODEL_87a5e794f5ff408ebbf2a740a7560adb",
      "value": " 150/? [14:12&lt;00:00,  5.68s/it]"
     }
    },
    "a694fbafc40c41e98fe568668e4db732": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_992143ed056d4a23afff16b83c514432",
      "placeholder": "​",
      "style": "IPY_MODEL_dc75ce283dff4270b9c537d4e057d416",
      "value": " 150/? [01:11&lt;00:00,  2.10it/s]"
     }
    },
    "ad0c71bcf6d945098f04025bc52055f9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b506bbd1464b407980a6ef55a7819828": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b986d76f127a48669bfaf9c674079d87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d3bd152e2b14612bdec4f9692d48739",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6736870c4aa94b20adeed80a00507dce",
      "value": 1
     }
    },
    "c56a3c25a1284582bdfb1ad9e02ccb06": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b986d76f127a48669bfaf9c674079d87",
       "IPY_MODEL_e941a8dd61c641c88445eb5497fd2760"
      ],
      "layout": "IPY_MODEL_888804a45395411cb9db622b0e6878cb"
     }
    },
    "c5b5410811de4ab59ff76737f353ce27": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd662889ecd24a5fbfbf078039e270a8",
      "placeholder": "​",
      "style": "IPY_MODEL_e8fbc6f859784253a0cf6fe88cc0d9ca",
      "value": " 150/? [01:08&lt;00:00,  2.19it/s]"
     }
    },
    "c7a670342db348f0b703a95438137574": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb47163880b644e99674d508f1407349": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e1089fcff4a4ad19de6fc9dfb87c171",
       "IPY_MODEL_c5b5410811de4ab59ff76737f353ce27"
      ],
      "layout": "IPY_MODEL_e94c000d5060445ca93691f6af42e70c"
     }
    },
    "cd662889ecd24a5fbfbf078039e270a8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce7dc5c992754af5a545aa408ed67c88": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2a4e7e937804562a63d0191223c0dd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17e87d4a9a974aa6828c5ae0f9e0cf3a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d689f347b2e040d186d0353abaa96dd4",
      "value": 1
     }
    },
    "d689f347b2e040d186d0353abaa96dd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d9fb635e32cd4ed4bcddf6574de80b1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3353a6712b3a482d8907ca80a0824020",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_273de981090749b29ce385706c449722",
      "value": 1
     }
    },
    "db85fdb064634d80b1904313a3b81ddb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9459d0d307814c34aa8a31945a82adb7",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ed804e9c6fae4499aa3e6fef00f5de44",
      "value": 1
     }
    },
    "dc75ce283dff4270b9c537d4e057d416": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc94b3b543714dd0845fdadca7db22a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddd0f5a0f838494daf3d0581081c3e86": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f842c10d414f41c6846c1dc74200f301",
       "IPY_MODEL_a694fbafc40c41e98fe568668e4db732"
      ],
      "layout": "IPY_MODEL_3856954e8b1e47a08fce9fff7a038027"
     }
    },
    "ddf41c306dc441eb85beb6ea7bfbfedd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dffe3b78e72e4c309bda155884c2c7a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d9fb635e32cd4ed4bcddf6574de80b1b",
       "IPY_MODEL_1523672396354424b0658ce14786fbd2"
      ],
      "layout": "IPY_MODEL_00632d7b23cc45f59515669601334fcd"
     }
    },
    "e2be21b2cc584489b535309b9c8904e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fca884b72b1946cd8403edac7d41924e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8503f63352114056ace6ee5662d746da",
      "value": 1
     }
    },
    "e595378941654a4dbe560a646dc52272": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7ccb000bd83423fb4693a908c638ddb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e7fc29feb6d3404d83c1e455602d5c1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2d2b6b3effa34b809c30379c42c3c861",
       "IPY_MODEL_f46251823d4f4d219bffc095047f8867"
      ],
      "layout": "IPY_MODEL_ddf41c306dc441eb85beb6ea7bfbfedd"
     }
    },
    "e8fbc6f859784253a0cf6fe88cc0d9ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e941a8dd61c641c88445eb5497fd2760": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce7dc5c992754af5a545aa408ed67c88",
      "placeholder": "​",
      "style": "IPY_MODEL_63ff13ee95f64beea555e0660be15eec",
      "value": " 150/? [01:09&lt;00:00,  2.17it/s]"
     }
    },
    "e94b124aaf674431b6e424b9c6c1da87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e94c000d5060445ca93691f6af42e70c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed804e9c6fae4499aa3e6fef00f5de44": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f1010194505c44b588ba44a39e4afd9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f46251823d4f4d219bffc095047f8867": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d3ae70779e447d0aa495a9872209d38",
      "placeholder": "​",
      "style": "IPY_MODEL_04619e3db74847f5b637c7d2b1d5b8b8",
      "value": " 150/? [14:12&lt;00:00,  5.68s/it]"
     }
    },
    "f7dd810e69fa4f1f91acaec17fb8c64a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_940db33506ef463788996553c4bf5f74",
      "placeholder": "​",
      "style": "IPY_MODEL_268c4187cfc9490bacfa1eafe1fbcca1",
      "value": " 150/? [42:34&lt;00:00, 17.03s/it]"
     }
    },
    "f842c10d414f41c6846c1dc74200f301": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4800749f8151430c8cc49570cd4ccaf7",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8365405f8a1c4d178b5ab5cd9d905e32",
      "value": 1
     }
    },
    "fb5c1e7223ac4634a16c161784505836": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_471a09375e984a31824b27e279a6c4f3",
       "IPY_MODEL_27deb6f565ac4447a44770288071a0b8"
      ],
      "layout": "IPY_MODEL_7475bb3748de434eae59ef85715514da"
     }
    },
    "fca884b72b1946cd8403edac7d41924e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffc60b07ad704ea2afc0ac2c79c10c11": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
