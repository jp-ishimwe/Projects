{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jp-ishimwe/Projects/blob/master/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mC1GOaVUZ0tj"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install transformers==3.0.2 \n",
    "#!pip install transformers -q\n",
    "#!pip install wandb -q\n",
    "!pip3 install --upgrade wandb\n",
    "!pip3 install rouge-score tqdm\n",
    "!pip3 install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "vxxkIi-xDrUz",
    "outputId": "3089c626-558c-4033-df7a-4a87e7c3743a"
   },
   "outputs": [],
   "source": [
    "#@title Import packages { run: \"auto\", vertical-output: true, display-mode: \"both\" }\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "\n",
    "from collections import defaultdict, OrderedDict\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "#import progressbar\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "#import dill\n",
    "import tarfile\n",
    "import json, gzip\n",
    "import math\n",
    "from typing import Optional, Union, Iterable, NamedTuple, Dict, List\n",
    "\n",
    "\n",
    "#!pip install transformers==3.0.2 -qq\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from rouge import Rouge\n",
    "from rouge_score import rouge_scorer, scoring\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "from transformers.modeling_t5 import T5Stack, T5LayerCrossAttention, T5Block, T5Attention\n",
    "\n",
    "# Ignore excessive warnings\n",
    "import logging\n",
    "logging.propagate = False \n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed():\n",
    "    SEED = 123\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "LME26NCmM8ne",
    "outputId": "70fadb92-ca06-4952-aa13-baf78a7f8000"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting the environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'Final-Model-Project.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-t7E9fLj8Zjd"
   },
   "outputs": [],
   "source": [
    "#!cp '/root/optimizers.py' '/root/Projects/' # SSH\n",
    "#!cp '/home/jupyter/optimizers.py' '/home/jupyter/Projects/' # for GCP\n",
    "#!cp '/content/drive/My Drive/Colab Notebooks/optimizers.py' .\n",
    "#from optimizers import AdaFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "colab_type": "code",
    "id": "7rF67H7GnK2U",
    "outputId": "73b7b959-b7c0-46b0-dfab-5d17f41d8b1d"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!/usr/local/cuda/bin/nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1g1xKdoCnMAq",
    "outputId": "eb74740f-11c0-4e87-86c3-ab1bcc3a6255"
   },
   "outputs": [],
   "source": [
    "#@title To proceed should be cuda { run: \"auto\", vertical-output: true }\n",
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jvIoL5I0Eb5"
   },
   "source": [
    "## Getting dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wGVOHhrk0GOP"
   },
   "source": [
    "You can find the dataset [here](http://lil.nlp.cornell.edu/newsroom/download/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkDYkbKV0SUM"
   },
   "source": [
    "**Loading dataset and unzip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AoIiFXg1juKC"
   },
   "outputs": [],
   "source": [
    "fname = '/content/drive/My Drive/Colab Notebooks/newsroom-release.tar'\n",
    "\n",
    "tar = tarfile.open(fname, \"r:\")\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1YuQmBQpP3C7"
   },
   "outputs": [],
   "source": [
    "!mv '/content/data/' '/content/drive/My Drive/Colab Notebooks'\n",
    "!cp -r '/content/release/' '/content/drive/My Drive/Colab Notebooks/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Z9YGB5TmYqR"
   },
   "outputs": [],
   "source": [
    "#path = '/home/jupyter/' # For GCp\n",
    "path = '/root/release/' # For SSH\n",
    "#path = \"/content/drive/My Drive/Colab Notebooks/data/release/\" # For Colab\n",
    "\n",
    "def read_data(path, name):\n",
    "  data = []\n",
    "  with gzip.open(path + name + \".jsonl.gz\") as f: #+\".jsonl.gz\" with GCP\n",
    "      for ln in f:\n",
    "          obj = json.loads(ln)\n",
    "          data.append(obj)\n",
    "  return data\n",
    "\n",
    "trainset = read_data(path, 'train') \n",
    "devset = read_data(path, 'dev')\n",
    "testset = read_data(path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gv1SfBCrIaW4"
   },
   "outputs": [],
   "source": [
    "def get_data(data):\n",
    "  data_dict = {'text': [], 'summary': []}\n",
    "  for article in data:\n",
    "    data_dict['text'].append(article['text'])\n",
    "    data_dict['summary'].append(article['summary'])\n",
    "  return pd.DataFrame(data_dict)\n",
    "\n",
    "train_data = get_data(trainset)\n",
    "valid_data = get_data(devset)\n",
    "test_data = get_data(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "id": "k3sSaZA_Z0ul",
    "outputId": "56ff0a7d-bb37-4fc0-88f6-1d37b35dfee6"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eia69USAvek8",
    "outputId": "5de67e80-2788-4f05-ba70-f3e43ca044ed"
   },
   "outputs": [],
   "source": [
    "print(f'The size of training dataset:{train_data.shape} | validation dataset: {valid_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JX6clAc9wHuy"
   },
   "outputs": [],
   "source": [
    "contraction = {\"isn't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you ll\":\"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you re\": \"you are\" , \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E38ktgfStkI9"
   },
   "source": [
    "###### Checking for NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "b-NTfClirfL3",
    "outputId": "10a3b951-f509-471f-9549-dae2a8f265d1"
   },
   "outputs": [],
   "source": [
    "train_data.isna().sum(), valid_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0HQ2wJrXEAcr"
   },
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6_qmLtaZp9s0"
   },
   "outputs": [],
   "source": [
    "class TextProccessing(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, column, contraction):\n",
    "    self.column = column\n",
    "    self.contraction = contraction\n",
    "  def fit(self, x, y=None):\n",
    "    return self\n",
    "  @staticmethod\n",
    "  def preprocessing(line):\n",
    "    date_pattern = r'(0?[1-9]/|1[0-2]/)(0?[1-9]/|[1-2][0-9]/|3[0-1]/)[0-9]{4}'\n",
    "    line = line.split(\"\\n\")\n",
    "    clean_line = []\n",
    "    for l in line:\n",
    "        if re.match(date_pattern, l) is not None:\n",
    "            pass\n",
    "        else:\n",
    "            clean_line.append(l)\n",
    "    line = \"\\n\".join(clean_line)\n",
    "\n",
    "    line = re.sub(r\"http\\S+\", \" \",line)\n",
    "    line = re.sub(r\"www\\S+\", \" \",line)\n",
    "    line = line.replace('—', ' ')\n",
    "    line = line.replace('-', ' ')\n",
    "    line = line.replace('&', 'and')\n",
    "    line = line.replace('[...]', '')\n",
    "    line = line.replace('...', '.')\n",
    "    line = line.replace('…', ' ')\n",
    "    line = re.sub(re.compile('<.*?>'), '', line)\n",
    "    line = re.sub(re.compile('@\\S+'), r'', line)\n",
    "    line = re.sub(r'#\\S+ ', r'', line)\n",
    "    line = line.replace(\"â\", \"'\") \n",
    "    line = line.replace('--', ' ')\n",
    "    line = re.sub(r'[^\\sa-zA-Z0-9.,!?]',' ',line)\n",
    "    line = line.strip()\n",
    "    line = line.replace(\"\\xa0\", \"\")\n",
    "    line = line.replace(\"click to share on twitter\", \"\")\n",
    "\n",
    "    line = re.sub(r'[ \\t]{2,}',' ', line)\n",
    "    return line\n",
    "\n",
    "  def transform(self, X):\n",
    "    return X[self.column].replace(self.contraction).fillna('').apply(lambda x: self.preprocessing(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m-XAtbFVI24a"
   },
   "outputs": [],
   "source": [
    "class Processor:\n",
    "\n",
    "  def __init__(self, data, \n",
    "               contraction,\n",
    "               max_length = None):\n",
    "    \n",
    "    self.max_length = max_length\n",
    "    self.data = data\n",
    "    self.contraction = contraction\n",
    "\n",
    "    \n",
    "  def cleaning(self, data):\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "      raise TypeError('Only Dataframes are allowed, but got data={}'.format(data))\n",
    "    else:\n",
    "      print('Please wait, we are cleaning...')\n",
    "      titles = ['text', 'summary']\n",
    "      data_dict = {}\n",
    "\n",
    "      for title in titles:\n",
    "        proc = TextProccessing(title, self.contraction)\n",
    "        res = proc.fit_transform(data)\n",
    "        data_dict[title] = res\n",
    "\n",
    "      ss = pd.DataFrame(data_dict)\n",
    "      \n",
    "      return ss\n",
    "\n",
    "  @staticmethod\n",
    "  def split(data):\n",
    "    return len(data.split())\n",
    "\n",
    "  def get_max_tokens(self, dataframe):\n",
    "\n",
    "    dataframe['article_len'] = dataframe['text'].apply(self.split)\n",
    "    dataframe['summary_len'] = dataframe['summary'].apply(self.split)\n",
    "    \n",
    "    max_len = {'max_article_tokens': max(dataframe['article_len']), \n",
    "                'min_article_tokens': min(dataframe['article_len']),\n",
    "                'max_summary_tokens': max(dataframe['summary_len']),\n",
    "                'min_summary_tokens': min(dataframe['summary_len'])}\n",
    "    return max_len, dataframe\n",
    "\n",
    "  def cleaned_data(self):\n",
    "    dataframe = self.cleaning(self.data)\n",
    "    \n",
    "    if self.max_length is None:\n",
    "      min_len, dataframe = self.get_max_tokens(dataframe)\n",
    "    else:\n",
    "      min_len = self.max_length\n",
    "\n",
    "    min_length = min_len['min_article_tokens']\n",
    "    idx_list = []\n",
    "    for idx, paragraph in tqdm(enumerate(dataframe['text'])):\n",
    "        pragraph = len(paragraph.split())\n",
    "        if pragraph < min_length:\n",
    "          idx_list.append(idx)\n",
    "    final_data = dataframe.drop(idx_list)\n",
    "    final_data = final_data.reset_index(drop=True)\n",
    "    \n",
    "    if self.max_length is not None:\n",
    "        min_len, final_data = self.get_max_tokens(final_data)\n",
    "\n",
    "    print('Done!')\n",
    "    \n",
    "    return final_data, min_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bNRiUhXoVkvY"
   },
   "outputs": [],
   "source": [
    "maxlen = {'max_article_tokens': 512,\n",
    "          'max_summary_tokens': 300,\n",
    "          'min_article_tokens': 100,\n",
    "          'min_summary_tokens': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oBiSvEkhz2ol",
    "outputId": "1e7a03cb-5f67-456c-e00c-5cca001aad15"
   },
   "outputs": [],
   "source": [
    "textproc = Processor(train_data, contraction, maxlen)\n",
    "train_processed, doc_lengths = textproc.cleaned_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AeW5BNIkZ0u7"
   },
   "outputs": [],
   "source": [
    "textproc = Processor(valid_data, contraction, maxlen)\n",
    "valid_processed, valid_doc_lengths = textproc.cleaned_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed.to_pickle(\"./train_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_processed.to_pickle(\"./valid_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "MNmq9Mgx_BNx",
    "outputId": "76787690-88a2-49c8-eed6-de45a698b67f"
   },
   "outputs": [],
   "source": [
    "train_processed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ko-HBLqNZ0vA"
   },
   "source": [
    "Only one article droped that was having zeros length. However we still have some article with no summaries. Therefore we can get rid off them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading pre-processed data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "ngCA4TwV1YBW",
    "outputId": "35a242e0-e94a-434d-e6ab-2f4dcaf6022d"
   },
   "outputs": [],
   "source": [
    "train_processed = pd.read_pickle(\"./train_processed.pkl\")\n",
    "valid_processed = pd.read_pickle(\"./valid_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6jOAe_ZbZ0vD"
   },
   "outputs": [],
   "source": [
    "indices = np.where(train_processed['summary_len'] < 10)\n",
    "train_processed_data = train_processed.drop(indices[0])\n",
    "train_processed_data = train_processed_data.reset_index(drop=True)\n",
    "#train_processed.iloc[indices[0]]\n",
    "\n",
    "inds = np.where(valid_processed['summary_len'] < 10)\n",
    "valid_processed_data = valid_processed.drop(inds[0])\n",
    "valid_processed_data = valid_processed_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tcp3ytvbZ0vF"
   },
   "outputs": [],
   "source": [
    "#train_data.iloc[954753]['summary'] # '<ul>\\n\\t<li><b>£', 'Ø¨Ø§ Ø§Û\\x8cÙ\\x86 Ø§Ø\\xadØ³Ø§Ø³ Ø¯Ø±Ù\\x85Ø§Ù\\x86Ø¯Ú¯Û\\x8cØ\\x8c Ø¨Ù\\x87 Ù\\x86Ø¸Ø±Øª Ù\\x85Û\\x8câ\\x80\\x8fØ±Ø³Ø¯ Ú©Ù\\x87 ØªØ\\xadØ±Û\\x8cÙ\\x85â\\x80\\x8fÙ\\x87Ø§ Ø¯Ø§Ø±Ù\\x86Ø¯ Ú©Ø§Ø± Ù\\x85Û\\x8câ\\x80\\x8fÚ©Ù\\x86Ù\\x86Ø¯'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m3FQWdFDZ0vK",
    "outputId": "25b1562f-26fc-4abb-b594-65e3be8cdd6e"
   },
   "outputs": [],
   "source": [
    "train_processed_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "x9chLqw-PK9e",
    "outputId": "e2cebd34-52fa-4767-d432-c8b0c9af6d9d"
   },
   "outputs": [],
   "source": [
    "train_processed_data['summary_len'].quantile([0.5, 0.75, 0.9, 0.95, 0.99, 0.999, 0.9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "hBlW5wqJpmJK",
    "outputId": "7a8991bf-5f84-4e1a-9a00-e071c1ee35e3"
   },
   "outputs": [],
   "source": [
    "train_processed_data['article_len'].quantile([0.1,0.25,0.4,0.5, 0.75, 0.9, 0.95, 0.99, 0.999, 0.9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kv13R15mZ0vR",
    "outputId": "65161116-70d3-47cb-891a-6ab9b410c845"
   },
   "outputs": [],
   "source": [
    "valid_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7yoTzCmZ0vZ",
    "outputId": "5a1ff212-0dbf-403f-8b94-fe2078e9104a"
   },
   "outputs": [],
   "source": [
    "valid_processed_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nMUVVJVZ0vc",
    "outputId": "d29ff526-5af4-4521-f8c4-bea7da5bd62d"
   },
   "outputs": [],
   "source": [
    "valid_processed_data['article_len'].quantile([0.5, 0.75, 0.9, 0.95, 0.99, 0.999, 0.9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70NxcZwHZ0ve",
    "outputId": "23d8a423-31aa-4394-abdc-9c85a4b93123"
   },
   "outputs": [],
   "source": [
    "valid_processed_data['summary_len'].quantile([0.5, 0.75, 0.9, 0.95, 0.99, 0.999, 0.9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bFFt1a_35GZR",
    "outputId": "f0e6781d-9141-4f4b-d915-9c6d5000a5dc"
   },
   "outputs": [],
   "source": [
    "art = 700 #int(train_processed_data['article_len'].quantile(0.9900))\n",
    "sum_ = 250# int(train_processed_data['summary_len'].quantile(0.9900))\n",
    "\n",
    "print(f'art len:{art}, sum len:{sum_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dxo2FbB0Z0vj",
    "outputId": "ea4b1e36-8de2-4621-f5b1-4d61bb65c352"
   },
   "outputs": [],
   "source": [
    "artV = 700 #int(valid_processed_data['article_len'].quantile(0.9900))\n",
    "sumV = 250# int(valid_processed_data['summary_len'].quantile(0.9900))\n",
    "\n",
    "print(f'art len:{artV}, sum len:{sumV}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dtuTFeLttppa"
   },
   "source": [
    "#### Creating Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYEBtk-Ctyy4"
   },
   "outputs": [],
   "source": [
    "class CustomDataReader(Dataset):\n",
    "  \"\"\"\n",
    "  Loading data to be used in pytorch pre-trained models\n",
    "  \n",
    "  \"\"\"\n",
    "  def __init__(self, dataframe, T5tokenizer, max_article_tokens=None,max_summary_tokens=None ):\n",
    "    self.tokenizer = T5tokenizer\n",
    "    self.dataframe = dataframe\n",
    "    self.eos = ' </s>'  #tokenizer.eos_token\n",
    "    self.sos = '<pad> ' #tokenizer.pad_token\n",
    "    self.source_len = max_article_tokens\n",
    "    self.target_len = max_summary_tokens\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.dataframe)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    articles = \"summarize: \" + self.dataframe.text[idx] + self.eos\n",
    "    articles = ' '.join(articles.split())\n",
    "\n",
    "    summary = self.sos + self.dataframe.summary[idx] + self.eos\n",
    "    summary = ' '.join(summary.split())\n",
    "\n",
    "    source_tokenized = self.tokenizer.batch_encode_plus([articles], max_length= self.source_len, pad_to_max_length=True, truncation=True,return_tensors='pt')\n",
    "    target_tokenized = self.tokenizer.batch_encode_plus([summary], max_length= self.target_len, pad_to_max_length=True, truncation=True,return_tensors='pt')\n",
    "\n",
    "    source_ids = source_tokenized['input_ids'].squeeze(0)\n",
    "    source_mask = source_tokenized['attention_mask'].squeeze(0)\n",
    "\n",
    "    summary_ids = target_tokenized['input_ids'].squeeze(0)\n",
    "    summary_mask = target_tokenized['attention_mask'].squeeze(0)\n",
    "\n",
    "    return source_ids, source_mask, summary_ids, summary_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqfiCrePYQIK"
   },
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hQwJS66iz0uS"
   },
   "outputs": [],
   "source": [
    "def training(model, dataset_loader, optimizer,log_interval,regularizer, eps_sched=None, batchs=None,epoch=0, use_wandb=True):\n",
    "\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    nItem = 0\n",
    "\n",
    "\n",
    "    print(f'\\nStart training for epoch: {epoch}')\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    tqdok = tqdm(dataset_loader, total=len(dataset_loader))\n",
    " \n",
    "    for idx, data_train in enumerate(tqdok):\n",
    "\n",
    "        input_ids, source_mask, summary_ids, summary_mask = data_train\n",
    "\n",
    "        input_ids = input_ids.to(device, dtype = torch.long)\n",
    "        source_mask = source_mask.to(device, dtype = torch.float)\n",
    "        summary_ids = summary_ids.to(device, dtype = torch.long)\n",
    "\n",
    "        target_labels = summary_ids[:, :-1].contiguous()\n",
    "        langm_labels = summary_ids[:, 1:].clone().detach()\n",
    "        langm_labels[summary_ids[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(input_ids=input_ids, attention_mask = source_mask, decoder_input_ids=target_labels, labels=langm_labels, lambd=regularizer)\n",
    "\n",
    "        loss = output[0]\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = input_ids.size(0)\n",
    "        nItem += bs\n",
    "        \n",
    "        # Before next loop: anneal optimizer variables \n",
    "        \n",
    "        if eps_sched is not None and  batchs is not None:\n",
    "            itr = epoch*(len(dataset_loader.dataset)//batchs) + idx\n",
    "            optimizer.param_groups[0]['eps'] = eps_sched[itr]\n",
    "\n",
    "        avg_loss += loss.item() * bs\n",
    "\n",
    "        if use_wandb and idx%log_interval == 0:\n",
    "            wandb.log({\"Training Loss\": loss.item()})\n",
    "        else:\n",
    "            if idx % 5000 == 0:\n",
    "                print(f'[{idx * len(input_ids)}/{len(dataset_loader.dataset)} ({100. * idx / len(dataset_loader):.0f})%] \\t Training loss: {loss:.3f}')\n",
    "   \n",
    "\n",
    "        losses.update(loss.item(), bs)\n",
    "        tqdok.set_postfix(loss=losses.avg)\n",
    "        \n",
    "    avg_loss /= nItem\n",
    "  \n",
    "    return avg_loss, output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYQaqTmxRtzQ"
   },
   "outputs": [],
   "source": [
    "def validation(model, dataset_loader, regularizer, token_summaries=False):\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss = 0\n",
    "    nItem = 0\n",
    "    droped = 0\n",
    "    open_gates = 0\n",
    "    total_doc_tokens = 0\n",
    "    tokens_info = None\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    tqdok = tqdm(dataset_loader, total=len(dataset_loader))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data_val in enumerate(tqdok):\n",
    "            input_ids, source_mask, summary_ids, summary_mask = data_val\n",
    "\n",
    "            input_ids = input_ids.to(device, dtype = torch.long)\n",
    "            source_mask = source_mask.to(device, dtype = torch.float)\n",
    "            summary_ids = summary_ids.to(device, dtype = torch.long)\n",
    "\n",
    "            target_labels = summary_ids[:, :-1].contiguous()\n",
    "            langm_labels = summary_ids[:, 1:].clone().detach()\n",
    "            langm_labels[summary_ids[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "\n",
    "            output = model(input_ids=input_ids, attention_mask = source_mask, decoder_input_ids=target_labels, labels=langm_labels, lambd=regularizer)\n",
    "\n",
    "            loss = output[0]\n",
    "            \n",
    "            if token_summaries:                \n",
    "                droped_number, nbr_of_nonzero_gates, total_tokens = output[-1] \n",
    "                droped += droped_number\n",
    "                open_gates += nbr_of_nonzero_gates\n",
    "                total_doc_tokens += total_tokens\n",
    "\n",
    "            bs = input_ids.size(0)\n",
    "            nItem += bs\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            losses.update(loss.item(), bs)\n",
    "            tqdok.set_postfix(loss=losses.avg)\n",
    "\n",
    "    eval_loss /= nItem\n",
    "    \n",
    "    if token_summaries:\n",
    "        tokens_info = (droped, open_gates, total_doc_tokens)\n",
    "\n",
    "    return eval_loss, tokens_info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h5ZhapbZawXG"
   },
   "outputs": [],
   "source": [
    "def saving(PATH, epoch, optm, model, LEARNING_RATE):\n",
    "  torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optm.state_dict(),\n",
    "            'learning_rate': LEARNING_RATE\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZsdXt4STdroJ"
   },
   "source": [
    "#### The model evaluation\n",
    "\n",
    "The perplexity:\n",
    "\n",
    "\\begin{align}\n",
    "\\large \\text{ppl}(p, D) &\\large = 2^{-\\frac{1}{N_{total}}\\log_2 p(D)}\n",
    "\\end{align}\n",
    "\n",
    "where $D=\\{(w_1,\\ldots,w_{N_i})_i\\}_{i=1}^M$ is a dataset of $M$ sequences with total length $N_{\\text{total}}=\\sum_{i}N_i$.\n",
    "\n",
    "\n",
    "#### Computing perplexity\n",
    "\n",
    "Our model's loss is the (negative) log probability of every token in the output sequence, which can be used to compute perplexity.\n",
    "\n",
    "We define perplexity using the **base 2** logarithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FarmceVkcm-Y"
   },
   "outputs": [],
   "source": [
    "def get_perplexity(epoc_loss):\n",
    "  rs = epoc_loss/np.log(2)\n",
    "  pp = 2**rs\n",
    "  return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "eDlcT25-F-sO"
   },
   "outputs": [],
   "source": [
    "#@title #### Loading T5 model and its Tokenizer { run: \"auto\" }\n",
    "\n",
    "LEARNING_RATE = 3.55e-4\n",
    "MODEL_NAME = 't5-base' # or T5-Large:770 params, T5-3B, T5-Base: 220 Params, T5-11B\n",
    "t5model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedFilterLayer(nn.Module):\n",
    "  r\"\"\"\n",
    "  Receives the keys from the encoder output.\n",
    "\n",
    "  Returns:\n",
    "    Output the values between [0,1]\n",
    "   \"\"\"\n",
    "\n",
    "  def __init__(self, config ):\n",
    "    super(GatedFilterLayer, self).__init__()\n",
    "\n",
    "    self.d_kv = config.d_kv\n",
    "    self.n_heads = config.num_heads\n",
    "    self.projector = nn.Linear(self.d_kv, 1,bias=False)\n",
    "\n",
    "  def forward(self, last_hidden_encoder):\n",
    "    \n",
    "    bs = last_hidden_encoder.shape[0]\n",
    "    keys = last_hidden_encoder.view(bs, -1, self.n_heads, self.d_kv).transpose(1, 2)\n",
    "    proj = self.projector(keys)\n",
    "    gate = torch.sigmoid(proj)\n",
    "\n",
    "    return gate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderStack(T5Stack):\n",
    "\n",
    "  def __init__(self,config, embed_tokens=None):\n",
    "    super().__init__(config)\n",
    "\n",
    "    self.embed_tokens = embed_tokens \n",
    "    self.is_decoder = config.is_decoder\n",
    "    self.config = config\n",
    "    self.gatefilter = GatedFilterLayer(config)\n",
    "\n",
    "  def forward(self, \n",
    "              input_ids=None,\n",
    "              attention_mask=None,\n",
    "              encoder_hidden_states=None,\n",
    "              encoder_attention_mask=None,\n",
    "              inputs_embeds=None,\n",
    "              head_mask=None,\n",
    "              past_key_value_states=None,\n",
    "              use_cache=False,\n",
    "              output_attentions=None,\n",
    "              output_hidden_states=None,\n",
    "          ):\n",
    "    \n",
    "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "            input_ids = input_ids.view(-1, input_shape[-1])\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            if self.is_decoder:\n",
    "                raise ValueError(\"You have to specify either decoder_input_ids or decoder_inputs_embeds\")\n",
    "            else:\n",
    "                raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            assert self.embed_tokens is not None, \"You have to intialize the model with valid token embeddings\"\n",
    "            inputs_embeds = self.embed_tokens(input_ids)\n",
    "\n",
    "        batch_size, seq_length = input_shape\n",
    "\n",
    "        if past_key_value_states is not None:\n",
    "            assert seq_length == 1, \"Input shape is {}, but should be {} when using past_key_value_sates\".format(\n",
    "                input_shape, (batch_size, 1)\n",
    "            )\n",
    "            # required mask seq length can be calculated via length of past\n",
    "            # key value states and seq_length = 1 for the last token\n",
    "            mask_seq_length = past_key_value_states[0][0].shape[2] + seq_length\n",
    "        else:\n",
    "            mask_seq_length = seq_length\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(batch_size, mask_seq_length).to(inputs_embeds.device)\n",
    "        if self.is_decoder and encoder_attention_mask is None and encoder_hidden_states is not None:\n",
    "            encoder_seq_length = encoder_hidden_states.shape[1]\n",
    "            encoder_attention_mask = torch.ones(\n",
    "                batch_size, encoder_seq_length, device=inputs_embeds.device, dtype=torch.long\n",
    "            )\n",
    "\n",
    "        # initialize past_key_value_states with `None` if past does not exist\n",
    "        if past_key_value_states is None:\n",
    "            past_key_value_states = [None] * len(self.block)\n",
    "\n",
    "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "        extended_attention_mask = self.get_extended_attention_mask(attention_mask, input_shape, inputs_embeds.device)\n",
    "\n",
    "        if self.is_decoder and encoder_attention_mask is not None:\n",
    "            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        head_mask = self.get_head_mask(head_mask, self.config.num_layers)\n",
    "        present_key_value_states = ()\n",
    "        all_hidden_states = ()\n",
    "        all_attentions = ()\n",
    "        position_bias = None\n",
    "        encoder_decoder_position_bias = None\n",
    "\n",
    "        hidden_states = self.dropout(inputs_embeds)\n",
    "\n",
    "        for i, (layer_module, past_key_value_state) in enumerate(zip(self.block, past_key_value_states)):\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            layer_outputs = layer_module(\n",
    "                hidden_states,\n",
    "                attention_mask=extended_attention_mask,\n",
    "                position_bias=position_bias,\n",
    "                encoder_hidden_states=encoder_hidden_states,\n",
    "                encoder_attention_mask=encoder_extended_attention_mask,\n",
    "                encoder_decoder_position_bias=encoder_decoder_position_bias,\n",
    "                head_mask=head_mask[i],\n",
    "                past_key_value_state=past_key_value_state,\n",
    "                use_cache=use_cache,\n",
    "                output_attentions=output_attentions,\n",
    "            )\n",
    "            # layer_outputs is a tuple with:\n",
    "            # hidden-states, key-value-states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)\n",
    "            hidden_states, present_key_value_state = layer_outputs[:2]\n",
    "\n",
    "            if i == 0:\n",
    "                # We share the position biases between the layers - the first layer store them\n",
    "                # layer_outputs = hidden-states, key-value-states (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)\n",
    "                position_bias = layer_outputs[3 if output_attentions else 2]\n",
    "                if self.is_decoder and encoder_hidden_states is not None:\n",
    "                    encoder_decoder_position_bias = layer_outputs[5 if output_attentions else 3]\n",
    "            # append next layer key value states\n",
    "            present_key_value_states = present_key_value_states + (present_key_value_state,)\n",
    "\n",
    "            if output_attentions:\n",
    "                all_attentions = all_attentions + (layer_outputs[2],)  # We keep only self-attention weights for now\n",
    "\n",
    "        hidden_states = self.final_layer_norm(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        \n",
    "        # Add last layer\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        outputs = (hidden_states,)\n",
    "        if use_cache is True:\n",
    "            assert self.is_decoder, \"`use_cache` can only be set to `True` if {} is used as a decoder\".format(self)\n",
    "            outputs = outputs + (present_key_value_states,)\n",
    "        if output_hidden_states:\n",
    "            outputs = outputs + (all_hidden_states,)\n",
    "        if output_attentions:\n",
    "            outputs = outputs + (all_attentions,)\n",
    "\n",
    "        # Defining gates\n",
    "\n",
    "        last_hidden_state = outputs[0]\n",
    "        gates = self.gatefilter(last_hidden_state)\n",
    "        outputs = outputs + (gates,)\n",
    "\n",
    "        return outputs  # last-layer hidden state, (presents,) (all hidden states), (all attentions), (gates,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(scores,g):\n",
    "\n",
    "  scores_max = torch.max(scores,dim=-1)[0].unsqueeze(-1)\n",
    "  scores = scores - scores_max\n",
    "  A = torch.exp(scores) # (bs, n_heads, qlen, klen)\n",
    "  g= g.permute(0,1,3,2) # (bs, n_heads,1, klen)\n",
    "  A_g = g * A\n",
    "  sum_norm = torch.sum(A_g,axis=-1).unsqueeze(-1)\n",
    "  weights = A_g/sum_norm\n",
    "  return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5GatedAtention(T5Attention):\n",
    "  r\"\"\"\n",
    "  The source code is from huggingface. For more details, check their github \n",
    "  @https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_t5.py#L204\n",
    "  \n",
    "  Retuns:\n",
    "    Context, attentions weights on the keys for the provided queries  \n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, config, has_relative_attention_bias = False): \n",
    "    super(T5GatedAtention, self).__init__(config)\n",
    "\n",
    "    self.has_relative_attention_bias = has_relative_attention_bias \n",
    "    self.relative_attention_num_buckets = config.relative_attention_num_buckets\n",
    "    self.config = config\n",
    "    self.config.is_decoder = True\n",
    "    self.n_heads = config.num_heads\n",
    "\n",
    "    if self.has_relative_attention_bias:\n",
    "      self.relative_attention_bias = nn.Embedding(self.relative_attention_num_buckets, self.n_heads)\n",
    "\n",
    "#   def extract_for_test(self, hidden_states, gates):\n",
    "    \n",
    "#     # thresholding gates values\n",
    "#     gate_indices = gates > self.config.threshold \n",
    "#     # Creating gate mask\n",
    "#     gate_mask = gate_indices * 1\n",
    "#     # getting extracted valid values of gates and last hidden states\n",
    "#     extracted_gates = gate_mask * gates\n",
    "#     extracted_hidden_state = hidden_states * gate_mask    \n",
    "\n",
    "#     return extracted_hidden_state, extracted_gates\n",
    "\n",
    "  def forward(\n",
    "        self,\n",
    "        input,\n",
    "        gates,\n",
    "        mask=None,\n",
    "        kv=None,\n",
    "        position_bias=None,\n",
    "        past_key_value_state=None,\n",
    "        head_mask=None,\n",
    "        query_length=None,\n",
    "        use_cache=True,\n",
    "        output_attentions=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Self-attention (if kv is None) or attention over source sentence (provided by kv).\n",
    "        \"\"\"\n",
    "        # Input is (bs, qlen, dim)\n",
    "        # Mask is (bs, klen) (non-causal) or (bs, klen, klen)\n",
    "        # past_key_value_state[0] is (bs, n_heads, q_len - 1, dim_per_head)\n",
    "        bs, qlen, dim = input.size()\n",
    "\n",
    "        if past_key_value_state is not None:\n",
    "            assert self.config.is_decoder is True, \"Encoder cannot cache past key value states\"\n",
    "            assert (\n",
    "                len(past_key_value_state) == 2\n",
    "            ), \"past_key_value_state should have 2 past states: keys and values. Got {} past states\".format(\n",
    "                len(past_key_value_state)\n",
    "            )\n",
    "            real_qlen = qlen + past_key_value_state[0].shape[2] if query_length is None else query_length\n",
    "        else:\n",
    "            real_qlen = qlen\n",
    "\n",
    "        if kv is None:\n",
    "            klen = real_qlen\n",
    "        else:\n",
    "            klen = kv.size(1)\n",
    "\n",
    "        def shape(x):\n",
    "            \"\"\"  projection \"\"\"\n",
    "            return x.view(bs, -1, self.n_heads, self.d_kv).transpose(1, 2)\n",
    "\n",
    "        def unshape(x):\n",
    "            \"\"\"  compute context \"\"\"\n",
    "            return x.transpose(1, 2).contiguous().view(bs, -1, self.inner_dim)\n",
    "\n",
    "        q = shape(self.q(input))  # (bs, n_heads, qlen, dim_per_head)\n",
    "        \n",
    "\n",
    "        if kv is None:\n",
    "            k = shape(self.k(input))  # (bs, n_heads, qlen, dim_per_head)\n",
    "            v = shape(self.v(input))  # (bs, n_heads, qlen, dim_per_head)\n",
    "\n",
    "        elif past_key_value_state is None:\n",
    "            k = v = kv\n",
    "            k = shape(self.k(k))  # (bs, n_heads, qlen, dim_per_head)\n",
    "            v = shape(self.v(v))  # (bs, n_heads, qlen, dim_per_head)\n",
    "\n",
    "        if past_key_value_state is not None:\n",
    "            if kv is None:\n",
    "                k_, v_ = past_key_value_state\n",
    "                k = torch.cat([k_, k], dim=2)  # (bs, n_heads, klen, dim_per_head)\n",
    "                v = torch.cat([v_, v], dim=2)  # (bs, n_heads, klen, dim_per_head)\n",
    "            else:\n",
    "                k, v = past_key_value_state\n",
    "\n",
    "        if self.config.is_decoder and use_cache is True:\n",
    "            present_key_value_state = ((k, v),)\n",
    "        else:\n",
    "            present_key_value_state = (None,)\n",
    "\n",
    "        # For evaluation remove irrelevant info if we want to\n",
    "        if not self.training:\n",
    "            gates, gate_mask, _ = gates\n",
    "            k = k * gate_mask\n",
    "            v = v * gate_mask\n",
    "\n",
    "        scores = torch.einsum(\"bnqd,bnkd->bnqk\", q, k)  # (bs, n_heads, qlen, klen)\n",
    "\n",
    "        if position_bias is None:\n",
    "            if not self.has_relative_attention_bias:\n",
    "                raise ValueError(\"No position_bias provided and no weights to compute position_bias\")\n",
    "            position_bias = self.compute_bias(real_qlen, klen)\n",
    "\n",
    "            # if key and values are already calculated\n",
    "            # we want only the last query position bias\n",
    "            if past_key_value_state is not None:\n",
    "                position_bias = position_bias[:, :, -1:, :]\n",
    "\n",
    "            if mask is not None:\n",
    "                position_bias = position_bias + mask  # (bs, n_heads, qlen, klen)\n",
    "\n",
    "        scores += position_bias\n",
    "\n",
    "        #if gate_filter_output is not None:\n",
    "        bsk, n_headsk, klenk, _ = k.size()\n",
    "        bsg, n_headsg, kleng, _ = gates.size()\n",
    "\n",
    "        error_message = \"Shapes missmatch. There should be gates of shape {}. Got {}\".format(k.shape,gates.shape)\n",
    "        assert (bsg, n_headsg, kleng) == (bsk, n_headsk, klenk), error_message\n",
    "\n",
    "\n",
    "        weights = softmax(scores.float(), g=gates).type_as(scores)  # (bs, n_heads, qlen, klen)\n",
    "        #weights = F.softmax(scores.float()).type_as(scores)  # (bs, n_heads, qlen, klen)\n",
    "\n",
    "        weights = F.dropout(weights, p=self.dropout, training=self.training)  # (bs, n_heads, qlen, klen)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if head_mask is not None:\n",
    "            weights = weights * head_mask\n",
    "\n",
    "        context = torch.matmul(weights, v)  # (bs, n_heads, qlen, dim_per_head)\n",
    "        context = unshape(context)  # (bs, qlen, dim)\n",
    "\n",
    "        context = self.o(context)\n",
    "\n",
    "        outputs = (context,) + present_key_value_state \n",
    "\n",
    "        if output_attentions: \n",
    "            outputs = outputs + (weights,)\n",
    "        if self.has_relative_attention_bias:\n",
    "            outputs = outputs + (position_bias,)                \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5LayerGatedCrossAttention(T5LayerCrossAttention):\n",
    "\n",
    "  def __init__(self, config, has_relative_attention_bias=False):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.EncDecAttention = T5GatedAtention(config, has_relative_attention_bias)\n",
    "\n",
    "  def forward(\n",
    "      self,\n",
    "      hidden_states,\n",
    "      gates,\n",
    "      kv,\n",
    "      attention_mask=None,\n",
    "      position_bias=None,\n",
    "      head_mask=None,\n",
    "      past_key_value_state=None,\n",
    "      use_cache=True,\n",
    "      query_length=None,\n",
    "      output_attentions=False,\n",
    "  ):\n",
    "      norm_x = self.layer_norm(hidden_states)\n",
    "      attention_output = self.EncDecAttention(\n",
    "          norm_x,\n",
    "          gates = gates,\n",
    "          mask=attention_mask,\n",
    "          kv=kv,\n",
    "          position_bias=position_bias,\n",
    "          head_mask=head_mask,\n",
    "          past_key_value_state=past_key_value_state,\n",
    "          use_cache=use_cache,\n",
    "          query_length=query_length,\n",
    "          output_attentions=output_attentions,\n",
    "      )\n",
    "      y = attention_output[0]\n",
    "      layer_output = hidden_states + self.dropout(y)\n",
    "      outputs = (layer_output,) + attention_output[1:]  # add attentions if we output them\n",
    "      return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedT5Block(T5Block):\n",
    "\n",
    "  def __init__(self,config,DecodBlock):\n",
    "    super(GatedT5Block, self).__init__(config)\n",
    "\n",
    "    self.config = config\n",
    "    self.layer = DecodBlock.layer\n",
    "\n",
    "  def forward(\n",
    "      self,\n",
    "      hidden_states,\n",
    "      gates,\n",
    "      attention_mask=None,\n",
    "      position_bias=None,\n",
    "      encoder_hidden_states=None,\n",
    "      encoder_attention_mask=None,\n",
    "      encoder_decoder_position_bias=None,\n",
    "      head_mask=None,\n",
    "      past_key_value_state=None,\n",
    "      use_cache=True,\n",
    "      output_attentions=False,\n",
    "  ):\n",
    "\n",
    "      if past_key_value_state is not None:\n",
    "          assert self.config.is_decoder, \"Only decoder can use `past_key_value_states`\"\n",
    "          expected_num_past_key_value_states = 2 if encoder_hidden_states is None else 4\n",
    "\n",
    "          error_message = \"There should be {} past states. 2 (past / key) for self attention.{} Got {} past key / value states\".format(\n",
    "              expected_num_past_key_value_states,\n",
    "              \"2 (past / key) for cross attention\" if expected_num_past_key_value_states == 4 else \"\",\n",
    "              len(past_key_value_state),\n",
    "          )\n",
    "          assert len(past_key_value_state) == expected_num_past_key_value_states, error_message\n",
    "\n",
    "          self_attn_past_key_value_state = past_key_value_state[:2]\n",
    "          cross_attn_past_key_value_state = past_key_value_state[2:]\n",
    "      else:\n",
    "          self_attn_past_key_value_state, cross_attn_past_key_value_state = None, None\n",
    "\n",
    "      self_attention_outputs = self.layer[0](\n",
    "          hidden_states,\n",
    "          attention_mask=attention_mask,\n",
    "          position_bias=position_bias,\n",
    "          head_mask=head_mask,\n",
    "          past_key_value_state=self_attn_past_key_value_state,\n",
    "          use_cache=use_cache,\n",
    "          output_attentions=output_attentions,\n",
    "      )\n",
    "      hidden_states, present_key_value_state = self_attention_outputs[:2]\n",
    "      attention_outputs = self_attention_outputs[2:]  # Keep self-attention outputs and relative position weights\n",
    "\n",
    "      if self.config.is_decoder and encoder_hidden_states is not None:\n",
    "          # the actual query length is unknown for cross attention\n",
    "          # if using past key value states. Need to inject it here\n",
    "          if present_key_value_state is not None:\n",
    "              query_length = present_key_value_state[0].shape[2]\n",
    "          else:\n",
    "              query_length = None\n",
    "\n",
    "          cross_attention_outputs = self.layer[1](\n",
    "              hidden_states,\n",
    "              gates=gates,\n",
    "              kv=encoder_hidden_states,\n",
    "              attention_mask=encoder_attention_mask,\n",
    "              position_bias=encoder_decoder_position_bias,\n",
    "              head_mask=head_mask,\n",
    "              past_key_value_state=cross_attn_past_key_value_state,\n",
    "              query_length=query_length,\n",
    "              use_cache=use_cache,\n",
    "              output_attentions=output_attentions,\n",
    "          )\n",
    "          hidden_states = cross_attention_outputs[0]\n",
    "          # Combine self attn and cross attn key value states\n",
    "          \n",
    "          # print('present_key_value_state',present_key_value_state)\n",
    "          # print('cross_attention_outputs[1]', cross_attention_outputs[1])\n",
    "          \n",
    "          if present_key_value_state is not None:\n",
    "              present_key_value_state = present_key_value_state + cross_attention_outputs[1]\n",
    "\n",
    "          # Keep cross-attention outputs and relative position weights\n",
    "          attention_outputs = attention_outputs + cross_attention_outputs[2:]\n",
    "\n",
    "      # Apply Feed Forward layer\n",
    "      hidden_states = self.layer[-1](hidden_states)\n",
    "      outputs = (hidden_states,)\n",
    "\n",
    "      # Add attentions if we output them\n",
    "      outputs = outputs + (present_key_value_state,) + attention_outputs\n",
    "      return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedT5Stack(T5Stack):\n",
    "    def __init__(self, config, t5model, embed_tokens=None):\n",
    "        super(GatedT5Stack, self).__init__(config)\n",
    "\n",
    "        self.embed_tokens = embed_tokens\n",
    "        self.block = nn.ModuleList([GatedT5Block(config, t5model.decoder.block[i]) for i in range(config.num_layers)])\n",
    "        self.config = config\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        gates,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        head_mask=None,\n",
    "        past_key_value_states=None,\n",
    "        use_cache=True,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "    ):\n",
    "\n",
    "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "            input_ids = input_ids.view(-1, input_shape[-1])\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            if self.config.is_decoder:\n",
    "                raise ValueError(\"You have to specify either decoder_input_ids or decoder_inputs_embeds\")\n",
    "            else:\n",
    "                raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            assert self.embed_tokens is not None, \"You have to intialize the model with valid token embeddings\"\n",
    "            inputs_embeds = self.embed_tokens(input_ids)\n",
    "\n",
    "        batch_size, seq_length = input_shape\n",
    "\n",
    "        if past_key_value_states is not None:\n",
    "            assert seq_length == 1, \"Input shape is {}, but should be {} when using past_key_value_sates\".format(\n",
    "                input_shape, (batch_size, 1)\n",
    "            )\n",
    "            # required mask seq length can be calculated via length of past\n",
    "            # key value states and seq_length = 1 for the last token\n",
    "            mask_seq_length = past_key_value_states[0][0].shape[2] + seq_length\n",
    "        else:\n",
    "            mask_seq_length = seq_length\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(batch_size, mask_seq_length).to(inputs_embeds.device)\n",
    "        if self.config.is_decoder and encoder_attention_mask is None and encoder_hidden_states is not None:\n",
    "            encoder_seq_length = encoder_hidden_states.shape[1]\n",
    "            encoder_attention_mask = torch.ones(\n",
    "                batch_size, encoder_seq_length, device=inputs_embeds.device, dtype=torch.long\n",
    "            )\n",
    "\n",
    "        # initialize past_key_value_states with `None` if past does not exist\n",
    "        if past_key_value_states is None:\n",
    "            past_key_value_states = [None] * len(self.block)\n",
    "\n",
    "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "        extended_attention_mask = self.get_extended_attention_mask(attention_mask, input_shape, inputs_embeds.device)\n",
    "\n",
    "        if self.config.is_decoder and encoder_attention_mask is not None:\n",
    "            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        head_mask = self.get_head_mask(head_mask, self.config.num_layers)\n",
    "        present_key_value_states = ()\n",
    "        all_hidden_states = ()\n",
    "        all_attentions = ()\n",
    "        position_bias = None\n",
    "        encoder_decoder_position_bias = None\n",
    "\n",
    "        hidden_states = self.dropout(inputs_embeds)\n",
    "\n",
    "        for i, (layer_module, past_key_value_state) in enumerate(zip(self.block, past_key_value_states)):\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            layer_outputs = layer_module(\n",
    "                hidden_states,\n",
    "                gates = gates,\n",
    "                attention_mask=extended_attention_mask,\n",
    "                position_bias=position_bias,\n",
    "                encoder_hidden_states=encoder_hidden_states,\n",
    "                encoder_attention_mask=encoder_extended_attention_mask,\n",
    "                encoder_decoder_position_bias=encoder_decoder_position_bias,\n",
    "                head_mask=head_mask[i],\n",
    "                past_key_value_state=past_key_value_state,\n",
    "                use_cache=use_cache,\n",
    "                output_attentions=output_attentions,\n",
    "            )\n",
    "            # layer_outputs is a tuple with:\n",
    "            # hidden-states, key-value-states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)\n",
    "            hidden_states, present_key_value_state = layer_outputs[:2]\n",
    "\n",
    "            if i == 0:\n",
    "                # We share the position biases between the layers - the first layer store them\n",
    "                # layer_outputs = hidden-states, key-value-states (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)\n",
    "                position_bias = layer_outputs[3 if output_attentions else 2]\n",
    "                if self.config.is_decoder and encoder_hidden_states is not None:\n",
    "                    encoder_decoder_position_bias = layer_outputs[5 if output_attentions else 3]\n",
    "            # append next layer key value states\n",
    "            present_key_value_states = present_key_value_states + (present_key_value_state,)\n",
    "\n",
    "            if output_attentions:\n",
    "                all_attentions = all_attentions + (layer_outputs[2],)  # We keep only self-attention weights for now\n",
    "\n",
    "        hidden_states = self.final_layer_norm(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "\n",
    "        # Add last layer\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        outputs = (hidden_states,)\n",
    "        if use_cache is True:\n",
    "            assert self.config.is_decoder, \"`use_cache` can only be set to `True` if {} is used as a decoder\".format(self)\n",
    "            outputs = outputs + (present_key_value_states,)\n",
    "        if output_hidden_states:\n",
    "            outputs = outputs + (all_hidden_states,)\n",
    "        if output_attentions:\n",
    "            outputs = outputs + (all_attentions,)\n",
    "        return outputs  # last-layer hidden state, (presents,) (all hidden states), (all attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5ForGenerationWithGate(T5ForConditionalGeneration):\n",
    "\n",
    "    def __init__(self, config, t5model):\n",
    "        super().__init__(config)\n",
    "\n",
    "        encoder_config = copy.deepcopy(t5model.encoder.config)\n",
    "        encoder_config.is_decoder = False   \n",
    "        encoder_config.use_cache = False \n",
    "\n",
    "        self.encoder = EncoderStack(encoder_config, embed_tokens=self.shared)\n",
    "\n",
    "        self.decoder_config = copy.deepcopy(t5model.decoder.config)\n",
    "        self.decoder_config.is_decoder = True\n",
    "        self.config = config\n",
    "        self.decoder = GatedT5Stack(self.decoder_config, t5model, embed_tokens=self.shared)\n",
    "\n",
    "    def forward(self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        encoder_outputs=None,\n",
    "        decoder_input_ids=None,\n",
    "        decoder_attention_mask=None,\n",
    "        decoder_past_key_value_states=None,\n",
    "        use_cache=True,\n",
    "        labels=None,\n",
    "        inputs_embeds=None,\n",
    "        decoder_inputs_embeds=None,\n",
    "        head_mask=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        lambd = 0.0,\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        if \"lm_labels\" in kwargs:\n",
    "            warnings.warn(\n",
    "                \"The `lm_labels` argument is deprecated and will be removed in a future version, use `labels` instead.\",\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "            labels = kwargs.pop(\"lm_labels\")\n",
    "        assert kwargs == {}, f\"Unexpected keyword arguments: {list(kwargs.keys())}.\"\n",
    "\n",
    "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "\n",
    "        # Encode if needed (training, first prediction pass)\n",
    "        if encoder_outputs is None:\n",
    "            # Convert encoder inputs in embeddings if needed\n",
    "            encoder_outputs = self.encoder(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                inputs_embeds=inputs_embeds,\n",
    "                head_mask=head_mask,\n",
    "                output_attentions=output_attentions,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "            )\n",
    "\n",
    "        # Getting the last hidden states and the gates\n",
    "\n",
    "        hidden_states = encoder_outputs[0]\n",
    "        gates = encoder_outputs[-1]\n",
    "\n",
    "\n",
    "        if labels is not None and decoder_input_ids is None and decoder_inputs_embeds is None:\n",
    "            # get decoder inputs from shifting lm labels to the right\n",
    "            decoder_input_ids = self._shift_right(labels)\n",
    "\n",
    "        # If decoding with past key value states, only the last tokens\n",
    "        # should be given as an input\n",
    "        if decoder_past_key_value_states is not None:\n",
    "            assert labels is None, \"Decoder should not use cached key value states when training.\"\n",
    "            if decoder_input_ids is not None:\n",
    "                decoder_input_ids = decoder_input_ids[:, -1:]\n",
    "            if decoder_inputs_embeds is not None:\n",
    "                decoder_inputs_embeds = decoder_inputs_embeds[:, -1:]\n",
    "\n",
    "\n",
    "        if not self.training:\n",
    "            gates = self.extract_for_test(gates)\n",
    "            tokens_info = self.get_droped_tot_num_encodings(gates, attention_mask)\n",
    "            extracted_gates = gates[0]\n",
    "            encoder_outputs = encoder_outputs[:-1] + (tokens_info,) + (extracted_gates,) # Add tokens summaries and extracted gates\n",
    "\n",
    "        # Decode\n",
    "        decoder_outputs = self.decoder(\n",
    "            gates = gates,\n",
    "            input_ids=decoder_input_ids,\n",
    "            attention_mask=decoder_attention_mask,\n",
    "            inputs_embeds=decoder_inputs_embeds,\n",
    "            past_key_value_states=decoder_past_key_value_states,\n",
    "            encoder_hidden_states=hidden_states,\n",
    "            encoder_attention_mask=attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "        )\n",
    "\n",
    "        # insert decoder past at right place\n",
    "        # to speed up decoding\n",
    "        if use_cache is True:\n",
    "            past = ((encoder_outputs, decoder_outputs[1]),)\n",
    "            decoder_outputs = decoder_outputs[:1] + past + decoder_outputs[2:]\n",
    "\n",
    "        sequence_output = decoder_outputs[0]\n",
    "\n",
    "        # print('\\ndecoder hidden nan', torch.sum(torch.isnan(sequence_output)))\n",
    "\n",
    "        # Rescale output before projecting on vocab\n",
    "        # See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586\n",
    "        sequence_output = sequence_output * (self.model_dim ** -0.5)\n",
    "        lm_logits = self.lm_head(sequence_output)\n",
    "\n",
    "        decoder_outputs = (lm_logits,) + decoder_outputs[1:]  # Add hidden states and attention if they are here\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "            loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), labels.view(-1))\n",
    "\n",
    "            # get extracted gates if want to\n",
    "            if not self.training:\n",
    "                gates = gates[0]              \n",
    "\n",
    "            loss_gate = torch.sum(gates.squeeze(-1))/(gates.shape[0]*gates.shape[1]*gates.shape[2])\n",
    "\n",
    "            # print('loss_gate', loss_gate)\n",
    "\n",
    "            Loss = loss + loss_gate * lambd\n",
    "\n",
    "            # TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666\n",
    "            decoder_outputs = (Loss,) + decoder_outputs\n",
    "\n",
    "        return decoder_outputs + encoder_outputs\n",
    "\n",
    "    def extract_for_test(self, gates):\n",
    "\n",
    "        # thresholding gates values\n",
    "        gate_indices = gates > self.config.threshold \n",
    "        # Creating gate mask\n",
    "        gate_mask = gate_indices * 1\n",
    "        # getting extracted valid values of gates and last hidden states\n",
    "        extracted_gates = gate_mask * gates\n",
    "\n",
    "        return extracted_gates, gate_mask, gates\n",
    "\n",
    "    def get_droped_tot_num_encodings(self, gates, source_mask=None):\n",
    "\n",
    "        gate_mask, gates = gates[1],gates[-1]    \n",
    "        number_of_nonzeros_gates = torch.sum(gate_mask)#.type(torch.int32)\n",
    "\n",
    "        if source_mask is not None:\n",
    "            total_tokens = torch.sum(source_mask)\n",
    "            droped_number = total_tokens - number_of_nonzeros_gates\n",
    "        else:\n",
    "            total_tokens = torch.sum((gates >= 0.0) * 1)   \n",
    "            droped_number = total_tokens - number_of_nonzeros_gates\n",
    "\n",
    "        return droped_number, number_of_nonzeros_gates, total_tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = t5model.config\n",
    "config.reg = 0.4\n",
    "config.threshold = 0.6\n",
    "\n",
    "#torch.save(t5model.state_dict(),\"pretrained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_to_replace=[]\n",
    "for block in t5model.decoder.block:\n",
    "  layers_to_replace.append(block)\n",
    "for idx,block in enumerate(layers_to_replace):\n",
    "\n",
    "  # Attention\n",
    "  EncoderDecodBlock = t5model.decoder.block[idx]\n",
    "  block.layer[1].EncDecAttention = T5GatedAtention(config)\n",
    "\n",
    "  # CrossAttention\n",
    "  if idx == 0:\n",
    "    block.layer[1] = T5LayerGatedCrossAttention(config, has_relative_attention_bias=True)\n",
    "  else:\n",
    "    block.layer[1] = T5LayerGatedCrossAttention(config, has_relative_attention_bias=False)\n",
    "\n",
    "\n",
    "# Define Decoder\n",
    "t5model.decoder = GatedT5Stack(config, t5model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = T5ForGenerationWithGate(config, t5model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"pretrained.pth\")\n",
    "state_dict[\"encoder.gatefilter.projector.weight\"] = model.encoder.gatefilter.projector.weight\n",
    "state_dict[\"encoder.gatefilter.projector.weight\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Jkp7dIU9-ZO3",
    "outputId": "f18b53f5-38d8-4bc1-c664-98b01f61f546"
   },
   "outputs": [],
   "source": [
    "eos = tokenizer.eos_token\n",
    "sos = tokenizer.pad_token\n",
    "eos, sos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W51Hk0xEz0sH"
   },
   "outputs": [],
   "source": [
    "#@title Train, Validation and Test splits { run: \"auto\" }\n",
    "\n",
    "columns = [\"text\",\"summary\"]\n",
    "\n",
    "X_train = train_processed_data[columns] #X_train.reset_index(drop=True)\n",
    "X_valid = valid_processed_data[columns] #X_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "sQeVMTtGz0p7",
    "outputId": "3e428252-9f55-4243-8cd2-a5d6f4c6641d"
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n97QsOoCZ0v8"
   },
   "outputs": [],
   "source": [
    "def get_dataloader(X, BATCH_SIZE,valid=None, **kwargs):\n",
    "\n",
    "    if valid == 'valid':\n",
    "        val_params = {\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'shuffle': False,\n",
    "            'num_workers': 2\n",
    "            }\n",
    "        data_set = CustomDataReader(X, tokenizer,**kwargs)\n",
    "        data_loader = DataLoader(data_set, **val_params)\n",
    "        \n",
    "    else:\n",
    "        data_set = CustomDataReader(X, tokenizer,**kwargs)     \n",
    "        train_params = {\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'shuffle': True,\n",
    "            'num_workers': 2\n",
    "            }\n",
    "        data_loader = DataLoader(data_set, **train_params)\n",
    "    \n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting samples of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08lW8ejhmgya"
   },
   "outputs": [],
   "source": [
    "# Xtrain_trial = X_train.iloc[:50000]\n",
    "# Xvalid_trial = X_valid.iloc[:3600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(X_train))\n",
    "valind = np.random.permutation(len(X_valid))\n",
    "\n",
    "ind = indices[:70000]\n",
    "vind = valind[:5000]\n",
    "\n",
    "Xtrain_trial = X_train.iloc[ind]\n",
    "Xvalid_trial = X_valid.iloc[vind]\n",
    "\n",
    "Xtrain_trial = Xtrain_trial.reset_index(drop=True)\n",
    "Xvalid_trial = Xvalid_trial.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGaGMwWLzfVE"
   },
   "outputs": [],
   "source": [
    "def load_pretrained_weights(model, optimizer, PATH, pretrained: Optional[bool]=False):\n",
    "\n",
    "    if pretrained:\n",
    "        checkpoint = torch.load(PATH)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        #LEARNING_RATE = checkpoint['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csfO3UdlJtEf"
   },
   "outputs": [],
   "source": [
    "def run(model,\n",
    "        X_train, X_valid, \n",
    "        weights_dir=None,filename=None,\n",
    "        eps_aneal = False, pretrained=False,\n",
    "        lr= LEARNING_RATE):\n",
    "\n",
    "    # WandB – Initialize a new run\n",
    "    wandb.init(entity=\"jp-ishimwe\", project=\"final-summarization-model\")\n",
    "    \n",
    "#     wandb.init(entity=\"jp-ishimwe\", project=\"test-summaries\") \n",
    "#     wandb.init(entity=\"jp-ishimwe\", project=\"document-summarization-test\")\n",
    "#     wandb.init(entity=\"jp-ishimwe\", project=\"document-summarization-using-transformer\")\n",
    " \n",
    "    config = wandb.config          \n",
    "    config.BATCH_SIZE = 4\n",
    "    config.EVAL_BATCH_SIZE = 5\n",
    "    config.N_EPOCHS = 2 \n",
    "    config.LEARNING_RATE = lr\n",
    "    config.SEED = 123               \n",
    "    config.art_maxlen = art\n",
    "    config.summary_maxlen = sum_\n",
    "    config.Valid_art_maxlen = artV\n",
    "    config.Valid_summary_maxlen = sumV\n",
    "    config.log_interval = 500     # how many batches to wait before logging training status\n",
    "    config.reg = 0.4\n",
    "\n",
    "    set_seed()\n",
    "    \n",
    "    kwargs = {'max_article_tokens': config.art_maxlen,\n",
    "                'max_summary_tokens': config.summary_maxlen\n",
    "             }\n",
    "    \n",
    "    kwargsval = {'max_article_tokens': config.Valid_art_maxlen,\n",
    "                'max_summary_tokens': config.Valid_summary_maxlen\n",
    "             }\n",
    "    \n",
    "    \n",
    "    train_loader = get_dataloader(X_train, config.BATCH_SIZE,valid=None, **kwargs)\n",
    "    val_loader  = get_dataloader(X_valid, config.EVAL_BATCH_SIZE,valid='valid', **kwargsval)\n",
    "    \n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    perplexity = []\n",
    "    \n",
    "    model = model.to(device)\n",
    "    params = {'params': model.parameters()}\n",
    "    optimizer = optim.Adam([params], lr=config.LEARNING_RATE)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=0)\n",
    "    \n",
    "    if pretrained and weights_dir is not None:\n",
    "        path = os.path.join(weights_dir, \"final_model.pth\")\n",
    "        if os.path.exists(path):\n",
    "            load_pretrained_weights(model, optimizer, path, pretrained=pretrained)\n",
    "        else:\n",
    "            raise NameError(\"The specified weight path does not exist\")\n",
    "            \n",
    "\n",
    "    if eps_aneal:\n",
    "        maxiter = config.N_EPOCHS*(len(train_loader.dataset)//config.BATCH_SIZE)\n",
    "        eps_sched = 1e-8 + 0.5-0.5*np.cos(np.linspace(0, np.pi, maxiter))\n",
    "        batchs = config.BATCH_SIZE\n",
    "    else:\n",
    "        eps_sched = None\n",
    "        batchs = None\n",
    "    \n",
    "    #wandb.watch(model, log=\"all\")\n",
    "\n",
    "    for epoch in range(config.N_EPOCHS): \n",
    "\n",
    "        avg_loss, outputs = training(model, train_loader, optimizer, config.log_interval,regularizer=config.reg, eps_sched=eps_sched, batchs=batchs,epoch=epoch)\n",
    "        \n",
    "        print('\\nValidation start:')\n",
    "        eval_loss, tokens_info = validation(model, val_loader, regularizer=config.reg)\n",
    "         \n",
    "        pp = get_perplexity(eval_loss)\n",
    "\n",
    "        perplexity.append(pp)\n",
    "        train_loss.append(avg_loss)\n",
    "        val_loss.append(eval_loss)\n",
    "        scheduler.step(eval_loss)\n",
    "\n",
    "\n",
    "        print(f'Epoch loss: {avg_loss:.4f}')\n",
    "        print(f'Perplexity: {pp:.4f} | Eval loss: {eval_loss:.4f}')\n",
    "        print(\"--------------\")\n",
    "\n",
    "\n",
    "        wandb.log({\n",
    "            \"Epoc Training Loss\": avg_loss,\n",
    "            \"Perplexity \": pp,\n",
    "            \"Eval Loss\": eval_loss})\n",
    "\n",
    "\n",
    "        # Save model to wandb\n",
    "\n",
    "        PATH = os.path.join(wandb.run.dir, 'final_model_0.1.pth')\n",
    "        saving(PATH, epoch, optimizer, model, config.LEARNING_RATE)\n",
    "\n",
    "    return train_loss, perplexity, val_loss, outputs, tokens_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "cb47163880b644e99674d508f1407349",
      "e94c000d5060445ca93691f6af42e70c",
      "6e1089fcff4a4ad19de6fc9dfb87c171",
      "c5b5410811de4ab59ff76737f353ce27",
      "2f28dc0b45cc4b30acb85fecdc128397",
      "0551f8a91cb547948703416f5c200c93",
      "e8fbc6f859784253a0cf6fe88cc0d9ca",
      "cd662889ecd24a5fbfbf078039e270a8",
      "ddd0f5a0f838494daf3d0581081c3e86",
      "3856954e8b1e47a08fce9fff7a038027",
      "f842c10d414f41c6846c1dc74200f301",
      "a694fbafc40c41e98fe568668e4db732",
      "8365405f8a1c4d178b5ab5cd9d905e32",
      "4800749f8151430c8cc49570cd4ccaf7",
      "dc75ce283dff4270b9c537d4e057d416",
      "992143ed056d4a23afff16b83c514432",
      "dffe3b78e72e4c309bda155884c2c7a7",
      "00632d7b23cc45f59515669601334fcd",
      "d9fb635e32cd4ed4bcddf6574de80b1b",
      "1523672396354424b0658ce14786fbd2",
      "273de981090749b29ce385706c449722",
      "3353a6712b3a482d8907ca80a0824020",
      "ffc60b07ad704ea2afc0ac2c79c10c11",
      "864cb033af344f22b288a320088ec71c",
      "2d96618428094902b80450d649566a66",
      "c7a670342db348f0b703a95438137574",
      "a33ce8bb19284323a89a317403263c0d",
      "90937a3fdc314010948a13e9e2c70e40",
      "b506bbd1464b407980a6ef55a7819828",
      "a2026ad15de541eebf332cb4ce4e1ad2",
      "a56cd84f576841259aace5b34b0efda7",
      "2004cd6b66034fdda39e09c4ea44b3ce",
      "90f39af76e9846b18c45633dce765584",
      "4a42cbf2455346818c8fb92da5665bca",
      "d2a4e7e937804562a63d0191223c0dd0",
      "02d1d8ffcf3a4873880bb4ec2b7eefbf",
      "d689f347b2e040d186d0353abaa96dd4",
      "17e87d4a9a974aa6828c5ae0f9e0cf3a",
      "1f778937b7484fac8de6530ea10a5470",
      "7a0883324f8b4256adf0e8a54c77524f",
      "53c9e46489fc4d708c7fe856173f3b12",
      "27afa2d568d6441690a6d0ee44e40e1c",
      "0cdd1f83587643f68b9cc4659ba75fb8",
      "2732c77700724db3beb39d1c64469852",
      "598b0d3d4ba64ed48d511ce9dd360f64",
      "9efdf4e9fd8c42598cced165c426f5bf",
      "f1010194505c44b588ba44a39e4afd9f",
      "a504d4571ae54c97a6fb586051f17b07",
      "a633f4726f6a4ba5babb0e0414e6c5e1",
      "007752d9ce5e47f480ae606afeb2cd16",
      "58fa30020dc14801a78967796be9df3e",
      "9712936912b84e498783132d111037bf",
      "89f6bfd52126419ab7c6b6ba00894c24",
      "501fe7de2d29471c9ad3580ba42b274d",
      "9e0d68b268384372ae1ec48b6c363b3a",
      "e595378941654a4dbe560a646dc52272",
      "c56a3c25a1284582bdfb1ad9e02ccb06",
      "888804a45395411cb9db622b0e6878cb",
      "b986d76f127a48669bfaf9c674079d87",
      "e941a8dd61c641c88445eb5497fd2760",
      "6736870c4aa94b20adeed80a00507dce",
      "4d3bd152e2b14612bdec4f9692d48739",
      "63ff13ee95f64beea555e0660be15eec",
      "ce7dc5c992754af5a545aa408ed67c88",
      "430de0fcf9ce45799f8cec7b508a8f7f",
      "99791d40ec534ebc9a7f4b01767f9aad",
      "e2be21b2cc584489b535309b9c8904e3",
      "354fdd4a6e064367be8398d996b63d38",
      "8503f63352114056ace6ee5662d746da",
      "fca884b72b1946cd8403edac7d41924e",
      "3008461ae4e440d081f2f3ac46afa685",
      "22e8567701184b729be80c57098badc4",
      "40ef9fea4c03417db6bdc76b480fb59e",
      "3c42fdea3dcd4f2bbd6ba10777f27db3",
      "8b5212a3ed9f49aea201644e1ed1ac53",
      "a637e9d5dda44c3e9c8c3b9154b1b20d",
      "e7ccb000bd83423fb4693a908c638ddb",
      "4e394e72017442e989642afdc2b8abcb",
      "87a5e794f5ff408ebbf2a740a7560adb",
      "200ba008099045719694899c681c2d16",
      "8b0a112033ab4a3a9a970c6eaaec5531",
      "9acb641a7ede4dd6b68097dbff290ce1",
      "8ef3688940ae4ff4840fc3ca4c231125",
      "f7dd810e69fa4f1f91acaec17fb8c64a",
      "68ba61411c5d4097883b053f06493415",
      "838fc6b6bb704fd897d9145830d7bb9f",
      "268c4187cfc9490bacfa1eafe1fbcca1",
      "940db33506ef463788996553c4bf5f74",
      "fb5c1e7223ac4634a16c161784505836",
      "7475bb3748de434eae59ef85715514da",
      "471a09375e984a31824b27e279a6c4f3",
      "27deb6f565ac4447a44770288071a0b8",
      "7a407d5347104eaa9ce6ec36250715d3",
      "37454b94184a4a10a9affa6e84e74f43",
      "e94b124aaf674431b6e424b9c6c1da87",
      "9a9728af9dcb4e67a1a006297cd7b74c",
      "e7fc29feb6d3404d83c1e455602d5c1b",
      "ddf41c306dc441eb85beb6ea7bfbfedd",
      "2d2b6b3effa34b809c30379c42c3c861",
      "f46251823d4f4d219bffc095047f8867",
      "5605c8c2ad12431b88e1404953ecd6b9",
      "ad0c71bcf6d945098f04025bc52055f9",
      "04619e3db74847f5b637c7d2b1d5b8b8",
      "9d3ae70779e447d0aa495a9872209d38",
      "906c310a405b4822a19d206cf3467f9b",
      "75b200a4d1cb4f1cab2204139ac8fff5",
      "61a4358811654212bd669c1c6c40b4cd",
      "917a8ab6a55b4cd382b1cd1982d5a227",
      "7b8fca08cafe4f7e9ad9f519bb005fd1",
      "2df67220b98547639c10a80ceb63b1ef",
      "58d8bd8caffa47788931111cd5d05409",
      "4778d193b45a4e2ca8871f19b195a26b",
      "267a56c7a2f542e3b24a5f790491a550",
      "dc94b3b543714dd0845fdadca7db22a3",
      "db85fdb064634d80b1904313a3b81ddb",
      "1cbf0dd906ac41e985bd752f526fa2d4",
      "ed804e9c6fae4499aa3e6fef00f5de44",
      "9459d0d307814c34aa8a31945a82adb7",
      "41ceec6b9c214b18891c8ab915d5c19c",
      "6005029df2504711a96df12e14290100"
     ]
    },
    "colab_type": "code",
    "id": "npvqrZ9L_Ufl",
    "outputId": "84bc79d3-9ae7-4882-d791-6c3699ca45fb"
   },
   "outputs": [],
   "source": [
    "train_loss, perplexity, eval_loss, outputs, tokens_info = run(model, Xtrain_trial, Xvalid_trial,lr= LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the gate distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gates = outputs[-1].squeeze(-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gates.mean(dim=-1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, _ = gates.max(dim=-1,keepdim=True)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, _ = gates.min(dim=-1, keepdim=True)\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "jmJ94Ryul0vR",
    "outputId": "f5f05284-122e-4f8f-cb3c-176e845c19db"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tr_los = np.array(train_loss)\n",
    "ev_los = np.array(eval_loss)\n",
    "per = np.array(perplexity)\n",
    "\n",
    "plt.plot(tr_los, label='Training loss')\n",
    "plt.plot(ev_los, label='Validation loss')\n",
    "plt.plot(per, label='Perplexity on val data')\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "plt.title('Train loss vs Eval loss and Perplexity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jsxZGr_bz0cv"
   },
   "outputs": [],
   "source": [
    "def generator(model, dataset_loader):\n",
    "  \n",
    "  model.eval()\n",
    "\n",
    "  results = {\"generated_summary\": [], \"golden_summary\": []}\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for idx, data_val in enumerate(dataset_loader):\n",
    "      \n",
    "      input_ids, source_mask, summary_ids, summary_mask = data_val \n",
    "      \n",
    "      input_ids = input_ids.to(device, dtype = torch.long)\n",
    "      source_mask = source_mask.to(device, dtype = torch.float)\n",
    "      summary_ids = summary_ids.to(device, dtype = torch.long)\n",
    "\n",
    "      generatation = model.generate(input_ids=input_ids,\n",
    "                                    attention_mask=source_mask, \n",
    "                                    min_length=30, \n",
    "                                    max_length=300, \n",
    "                                    num_beams=1,\n",
    "                                    repetition_penalty=2.5,\n",
    "                                    eos_token_id = model.decoder.config.eos_token_id,               \n",
    "                                    length_penalty=1.0, \n",
    "                                    early_stopping=True\n",
    "                                    )\n",
    "\n",
    "      for gen, sc in zip(generatation, summary_ids): # Taking whole document IDs and docode the summary\n",
    "\n",
    "        gen_tokens_dec = tokenizer.decode(gen, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        sc_tokens_dec = tokenizer.decode(sc, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "        results[\"generated_summary\"].append(gen_tokens_dec)\n",
    "        results[\"golden_summary\"].append(sc_tokens_dec)\n",
    "\n",
    "  return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= 5\n",
    "thresholds = [0.01 * i for i in range(n)] + [0.1 * (i+1) for i in range(n)]\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def get_scores_experiment(my_model, val_loader, config, thresholds: List):\n",
    "    print(\"Start time\")\n",
    "    score_dict = {}\n",
    "    result_dict = {}\n",
    "    valid_tokens_info_dict = {}\n",
    "        \n",
    "    for threshold in thresholds:\n",
    "        config.threshold = threshold\n",
    "        _results = generator(my_model, val_loader)\n",
    "        score_ = scores(_results)\n",
    "        _, tokens_info = validation(my_model, val_loader, regularizer=config.reg)\n",
    "        score_dict[\"scores_on_threshold\"+str(threshold)] = score_\n",
    "        result_dict[\"results_wth_threshold\"+str(threshold)] = _results\n",
    "        valid_tokens_info_dict[\"tonkens_wth_threshold\"+str(threshold)] = tokens_info\n",
    "    \n",
    "    print(\"End time\")\n",
    "\n",
    "    return score_dict, result_dict, valid_tokens_info_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwTbUyKag_8R"
   },
   "source": [
    "#### Loading Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tTLrSSGio-c-"
   },
   "outputs": [],
   "source": [
    "load_weights = False\n",
    "\n",
    "if load_weights:    \n",
    "\n",
    "    model = .... # first initialize the model and optimizer\n",
    "    optimizer = ... # optimizer then,\n",
    "    PATH = ...\n",
    "    \n",
    "    load_pretrained_weights(model, optimizer, PATH, pretrained=load_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /root/Projects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('/root/Projectsmodel0.pt'))\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivind = valind[5000:6000]\n",
    "\n",
    "X_trial = X_valid.iloc[ivind]\n",
    "\n",
    "Xtest_trial = X_trial.reset_index(drop=True)\n",
    "\n",
    "argsval = {'max_article_tokens': 700,\n",
    "                'max_summary_tokens': 250\n",
    "             }\n",
    "    \n",
    "    \n",
    "val_loader  = get_dataloader(Xtest_trial, 8,valid='valid', **argsval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time results = generator(my_model, val_loader)\n",
    "score_dict, result_dict, valid_tokens_info_dict = get_scores_experiment(my_model, val_loader, config, thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kNpZ1c5TBmqD"
   },
   "source": [
    "#### Visualizing examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GkwqzhhvEXqt"
   },
   "source": [
    "**Example 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_trial.iloc[0,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "6eQnF1XN_T8r",
    "outputId": "2f75a808-e1ea-44bd-c636-1e1d6a007111"
   },
   "outputs": [],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "colab_type": "code",
    "id": "PNXoHiQjBjAY",
    "outputId": "ee260cb0-641e-46ce-9a69-bd2ea8441a4f"
   },
   "outputs": [],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xU7pMWeEfh8"
   },
   "source": [
    "**Example 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "g_K3Q-5GB92N",
    "outputId": "3b960f64-d419-41ab-bdf2-df342e9711ef"
   },
   "outputs": [],
   "source": [
    "Xtest_trial.iloc[1,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "l_CBGaOSBvmL",
    "outputId": "1b18480c-dc94-4d98-dbd5-fada568312d2"
   },
   "outputs": [],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "ITAC0YvZB0um",
    "outputId": "bff5f8b7-b225-44fa-f28a-91cfa698469d"
   },
   "outputs": [],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OuLET9kiEkTa"
   },
   "source": [
    "**Example 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "s6eSs1ZWD_sD",
    "outputId": "f9af3dd9-6e7a-4c32-9aa4-7a024bb8607e"
   },
   "outputs": [],
   "source": [
    "Xtest_trial.iloc[3,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "QTOwXNrqDUMp",
    "outputId": "22ea1bef-0ee9-41e4-9424-1747acabab9f"
   },
   "outputs": [],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "colab_type": "code",
    "id": "8KPpq-pUDcfe",
    "outputId": "f8042bcb-cf9a-4b20-88c9-df472a921934"
   },
   "outputs": [],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C0TEEYozZ0wm"
   },
   "source": [
    "**Example 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J8J_ZRKZZ0wm",
    "outputId": "283a7426-78d2-4302-c7eb-8f435462639d"
   },
   "outputs": [],
   "source": [
    "Xtest_trial.iloc[4,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQrei0JEZ0wo",
    "outputId": "1aa75634-2780-49c7-d0c3-0adae8f78971"
   },
   "outputs": [],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OJIYcxJ4Z0wp",
    "outputId": "04e4d05f-fc82-4171-80ca-3032539cbf25"
   },
   "outputs": [],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_trial.iloc[5,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_trial.iloc[6,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_trial.iloc[7,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_trial.iloc[8,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_trial.iloc[9,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_trial.iloc[15,:]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Actual summary:\")\n",
    "results['golden_summary'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generated summary:')\n",
    "results['generated_summary'][15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4KX71gPzy_bH"
   },
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ter9ktdQ6_54"
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def get_score(summaries) -> Dict:  \n",
    "    \n",
    "    src_labels = summaries['golden_summary']\n",
    "    gen_summary = summaries['generated_summary']\n",
    "    \n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1','rouge2','rougeL'], use_stemmer=True)\n",
    "    aggregator = scoring.BootstrapAggregator()\n",
    "    \n",
    "    for src, gent in zip(src_labels, gen_summary):\n",
    "        scores = scorer.score(gent, src)\n",
    "        aggregator.add_scores(scores)\n",
    "        \n",
    "    results = aggregator.aggregate()\n",
    "    return {key: val.mid.fmeasure for key, val in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jfhyTtEwZ0ww",
    "outputId": "65e760cf-5c1d-4b3c-b73a-532fbfcf56fa"
   },
   "outputs": [],
   "source": [
    "get_score(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6UtF_jowZ0wz",
    "outputId": "e969fe82-4e50-472f-d4ed-68a810008fbe"
   },
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "\n",
    "score = rouge.get_scores(results['generated_summary'], results['golden_summary'], avg=True)\n",
    "{key: val['f'] for key, val in score.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'rouge-1': 0.23891854897729273,\n",
    " 'rouge-2': 0.10855931785640041,\n",
    " 'rouge-l': 0.21982563644064748}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'rouge-1': 0.2934569607894014,\n",
    " 'rouge-2': 0.16207342615668757,\n",
    " 'rouge-l': 0.2762959592687011} #0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SuKNdMkjZ0w1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Final_Project",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "pytorch-gpu.1-4.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00632d7b23cc45f59515669601334fcd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "007752d9ce5e47f480ae606afeb2cd16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02d1d8ffcf3a4873880bb4ec2b7eefbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a0883324f8b4256adf0e8a54c77524f",
      "placeholder": "​",
      "style": "IPY_MODEL_1f778937b7484fac8de6530ea10a5470",
      "value": " 150/? [2:07:40&lt;00:00, 51.07s/it]"
     }
    },
    "04619e3db74847f5b637c7d2b1d5b8b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0551f8a91cb547948703416f5c200c93": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cdd1f83587643f68b9cc4659ba75fb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9efdf4e9fd8c42598cced165c426f5bf",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_598b0d3d4ba64ed48d511ce9dd360f64",
      "value": 1
     }
    },
    "1523672396354424b0658ce14786fbd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_864cb033af344f22b288a320088ec71c",
      "placeholder": "​",
      "style": "IPY_MODEL_ffc60b07ad704ea2afc0ac2c79c10c11",
      "value": " 150/? [01:24&lt;00:00,  1.77it/s]"
     }
    },
    "17e87d4a9a974aa6828c5ae0f9e0cf3a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1cbf0dd906ac41e985bd752f526fa2d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6005029df2504711a96df12e14290100",
      "placeholder": "​",
      "style": "IPY_MODEL_41ceec6b9c214b18891c8ab915d5c19c",
      "value": " 150/? [01:09&lt;00:00,  2.17it/s]"
     }
    },
    "1f778937b7484fac8de6530ea10a5470": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2004cd6b66034fdda39e09c4ea44b3ce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "200ba008099045719694899c681c2d16": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22e8567701184b729be80c57098badc4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "267a56c7a2f542e3b24a5f790491a550": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_db85fdb064634d80b1904313a3b81ddb",
       "IPY_MODEL_1cbf0dd906ac41e985bd752f526fa2d4"
      ],
      "layout": "IPY_MODEL_dc94b3b543714dd0845fdadca7db22a3"
     }
    },
    "268c4187cfc9490bacfa1eafe1fbcca1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2732c77700724db3beb39d1c64469852": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a504d4571ae54c97a6fb586051f17b07",
      "placeholder": "​",
      "style": "IPY_MODEL_f1010194505c44b588ba44a39e4afd9f",
      "value": " 150/? [01:09&lt;00:00,  2.16it/s]"
     }
    },
    "273de981090749b29ce385706c449722": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "27afa2d568d6441690a6d0ee44e40e1c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27deb6f565ac4447a44770288071a0b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a9728af9dcb4e67a1a006297cd7b74c",
      "placeholder": "​",
      "style": "IPY_MODEL_e94b124aaf674431b6e424b9c6c1da87",
      "value": " 150/? [01:26&lt;00:00,  1.73it/s]"
     }
    },
    "2d2b6b3effa34b809c30379c42c3c861": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad0c71bcf6d945098f04025bc52055f9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5605c8c2ad12431b88e1404953ecd6b9",
      "value": 1
     }
    },
    "2d96618428094902b80450d649566a66": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a33ce8bb19284323a89a317403263c0d",
       "IPY_MODEL_90937a3fdc314010948a13e9e2c70e40"
      ],
      "layout": "IPY_MODEL_c7a670342db348f0b703a95438137574"
     }
    },
    "2df67220b98547639c10a80ceb63b1ef": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f28dc0b45cc4b30acb85fecdc128397": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3008461ae4e440d081f2f3ac46afa685": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3353a6712b3a482d8907ca80a0824020": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "354fdd4a6e064367be8398d996b63d38": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22e8567701184b729be80c57098badc4",
      "placeholder": "​",
      "style": "IPY_MODEL_3008461ae4e440d081f2f3ac46afa685",
      "value": " 150/? [01:10&lt;00:00,  2.12it/s]"
     }
    },
    "37454b94184a4a10a9affa6e84e74f43": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3856954e8b1e47a08fce9fff7a038027": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c42fdea3dcd4f2bbd6ba10777f27db3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40ef9fea4c03417db6bdc76b480fb59e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b5212a3ed9f49aea201644e1ed1ac53",
       "IPY_MODEL_a637e9d5dda44c3e9c8c3b9154b1b20d"
      ],
      "layout": "IPY_MODEL_3c42fdea3dcd4f2bbd6ba10777f27db3"
     }
    },
    "41ceec6b9c214b18891c8ab915d5c19c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "430de0fcf9ce45799f8cec7b508a8f7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e2be21b2cc584489b535309b9c8904e3",
       "IPY_MODEL_354fdd4a6e064367be8398d996b63d38"
      ],
      "layout": "IPY_MODEL_99791d40ec534ebc9a7f4b01767f9aad"
     }
    },
    "471a09375e984a31824b27e279a6c4f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37454b94184a4a10a9affa6e84e74f43",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7a407d5347104eaa9ce6ec36250715d3",
      "value": 1
     }
    },
    "4778d193b45a4e2ca8871f19b195a26b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4800749f8151430c8cc49570cd4ccaf7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a42cbf2455346818c8fb92da5665bca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d3bd152e2b14612bdec4f9692d48739": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e394e72017442e989642afdc2b8abcb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "501fe7de2d29471c9ad3580ba42b274d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53c9e46489fc4d708c7fe856173f3b12": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0cdd1f83587643f68b9cc4659ba75fb8",
       "IPY_MODEL_2732c77700724db3beb39d1c64469852"
      ],
      "layout": "IPY_MODEL_27afa2d568d6441690a6d0ee44e40e1c"
     }
    },
    "5605c8c2ad12431b88e1404953ecd6b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "58d8bd8caffa47788931111cd5d05409": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58fa30020dc14801a78967796be9df3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_501fe7de2d29471c9ad3580ba42b274d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_89f6bfd52126419ab7c6b6ba00894c24",
      "value": 1
     }
    },
    "598b0d3d4ba64ed48d511ce9dd360f64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6005029df2504711a96df12e14290100": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61a4358811654212bd669c1c6c40b4cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2df67220b98547639c10a80ceb63b1ef",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7b8fca08cafe4f7e9ad9f519bb005fd1",
      "value": 1
     }
    },
    "63ff13ee95f64beea555e0660be15eec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6736870c4aa94b20adeed80a00507dce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "68ba61411c5d4097883b053f06493415": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6e1089fcff4a4ad19de6fc9dfb87c171": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0551f8a91cb547948703416f5c200c93",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2f28dc0b45cc4b30acb85fecdc128397",
      "value": 1
     }
    },
    "7475bb3748de434eae59ef85715514da": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75b200a4d1cb4f1cab2204139ac8fff5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a0883324f8b4256adf0e8a54c77524f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a407d5347104eaa9ce6ec36250715d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7b8fca08cafe4f7e9ad9f519bb005fd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8365405f8a1c4d178b5ab5cd9d905e32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "838fc6b6bb704fd897d9145830d7bb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8503f63352114056ace6ee5662d746da": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "864cb033af344f22b288a320088ec71c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87a5e794f5ff408ebbf2a740a7560adb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "888804a45395411cb9db622b0e6878cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89f6bfd52126419ab7c6b6ba00894c24": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8b0a112033ab4a3a9a970c6eaaec5531": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8ef3688940ae4ff4840fc3ca4c231125",
       "IPY_MODEL_f7dd810e69fa4f1f91acaec17fb8c64a"
      ],
      "layout": "IPY_MODEL_9acb641a7ede4dd6b68097dbff290ce1"
     }
    },
    "8b5212a3ed9f49aea201644e1ed1ac53": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e394e72017442e989642afdc2b8abcb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7ccb000bd83423fb4693a908c638ddb",
      "value": 1
     }
    },
    "8ef3688940ae4ff4840fc3ca4c231125": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_838fc6b6bb704fd897d9145830d7bb9f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68ba61411c5d4097883b053f06493415",
      "value": 1
     }
    },
    "906c310a405b4822a19d206cf3467f9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_61a4358811654212bd669c1c6c40b4cd",
       "IPY_MODEL_917a8ab6a55b4cd382b1cd1982d5a227"
      ],
      "layout": "IPY_MODEL_75b200a4d1cb4f1cab2204139ac8fff5"
     }
    },
    "90937a3fdc314010948a13e9e2c70e40": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2004cd6b66034fdda39e09c4ea44b3ce",
      "placeholder": "​",
      "style": "IPY_MODEL_a56cd84f576841259aace5b34b0efda7",
      "value": " 150/? [14:16&lt;00:00,  5.71s/it]"
     }
    },
    "90f39af76e9846b18c45633dce765584": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d2a4e7e937804562a63d0191223c0dd0",
       "IPY_MODEL_02d1d8ffcf3a4873880bb4ec2b7eefbf"
      ],
      "layout": "IPY_MODEL_4a42cbf2455346818c8fb92da5665bca"
     }
    },
    "917a8ab6a55b4cd382b1cd1982d5a227": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4778d193b45a4e2ca8871f19b195a26b",
      "placeholder": "​",
      "style": "IPY_MODEL_58d8bd8caffa47788931111cd5d05409",
      "value": " 150/? [01:08&lt;00:00,  2.18it/s]"
     }
    },
    "940db33506ef463788996553c4bf5f74": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9459d0d307814c34aa8a31945a82adb7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9712936912b84e498783132d111037bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e595378941654a4dbe560a646dc52272",
      "placeholder": "​",
      "style": "IPY_MODEL_9e0d68b268384372ae1ec48b6c363b3a",
      "value": " 150/? [1:39:19&lt;00:00, 39.73s/it]"
     }
    },
    "992143ed056d4a23afff16b83c514432": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99791d40ec534ebc9a7f4b01767f9aad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a9728af9dcb4e67a1a006297cd7b74c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9acb641a7ede4dd6b68097dbff290ce1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d3ae70779e447d0aa495a9872209d38": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e0d68b268384372ae1ec48b6c363b3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9efdf4e9fd8c42598cced165c426f5bf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2026ad15de541eebf332cb4ce4e1ad2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a33ce8bb19284323a89a317403263c0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2026ad15de541eebf332cb4ce4e1ad2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b506bbd1464b407980a6ef55a7819828",
      "value": 1
     }
    },
    "a504d4571ae54c97a6fb586051f17b07": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a56cd84f576841259aace5b34b0efda7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a633f4726f6a4ba5babb0e0414e6c5e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58fa30020dc14801a78967796be9df3e",
       "IPY_MODEL_9712936912b84e498783132d111037bf"
      ],
      "layout": "IPY_MODEL_007752d9ce5e47f480ae606afeb2cd16"
     }
    },
    "a637e9d5dda44c3e9c8c3b9154b1b20d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_200ba008099045719694899c681c2d16",
      "placeholder": "​",
      "style": "IPY_MODEL_87a5e794f5ff408ebbf2a740a7560adb",
      "value": " 150/? [14:12&lt;00:00,  5.68s/it]"
     }
    },
    "a694fbafc40c41e98fe568668e4db732": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_992143ed056d4a23afff16b83c514432",
      "placeholder": "​",
      "style": "IPY_MODEL_dc75ce283dff4270b9c537d4e057d416",
      "value": " 150/? [01:11&lt;00:00,  2.10it/s]"
     }
    },
    "ad0c71bcf6d945098f04025bc52055f9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b506bbd1464b407980a6ef55a7819828": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b986d76f127a48669bfaf9c674079d87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d3bd152e2b14612bdec4f9692d48739",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6736870c4aa94b20adeed80a00507dce",
      "value": 1
     }
    },
    "c56a3c25a1284582bdfb1ad9e02ccb06": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b986d76f127a48669bfaf9c674079d87",
       "IPY_MODEL_e941a8dd61c641c88445eb5497fd2760"
      ],
      "layout": "IPY_MODEL_888804a45395411cb9db622b0e6878cb"
     }
    },
    "c5b5410811de4ab59ff76737f353ce27": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd662889ecd24a5fbfbf078039e270a8",
      "placeholder": "​",
      "style": "IPY_MODEL_e8fbc6f859784253a0cf6fe88cc0d9ca",
      "value": " 150/? [01:08&lt;00:00,  2.19it/s]"
     }
    },
    "c7a670342db348f0b703a95438137574": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb47163880b644e99674d508f1407349": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e1089fcff4a4ad19de6fc9dfb87c171",
       "IPY_MODEL_c5b5410811de4ab59ff76737f353ce27"
      ],
      "layout": "IPY_MODEL_e94c000d5060445ca93691f6af42e70c"
     }
    },
    "cd662889ecd24a5fbfbf078039e270a8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce7dc5c992754af5a545aa408ed67c88": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2a4e7e937804562a63d0191223c0dd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17e87d4a9a974aa6828c5ae0f9e0cf3a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d689f347b2e040d186d0353abaa96dd4",
      "value": 1
     }
    },
    "d689f347b2e040d186d0353abaa96dd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d9fb635e32cd4ed4bcddf6574de80b1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3353a6712b3a482d8907ca80a0824020",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_273de981090749b29ce385706c449722",
      "value": 1
     }
    },
    "db85fdb064634d80b1904313a3b81ddb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9459d0d307814c34aa8a31945a82adb7",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ed804e9c6fae4499aa3e6fef00f5de44",
      "value": 1
     }
    },
    "dc75ce283dff4270b9c537d4e057d416": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc94b3b543714dd0845fdadca7db22a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddd0f5a0f838494daf3d0581081c3e86": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f842c10d414f41c6846c1dc74200f301",
       "IPY_MODEL_a694fbafc40c41e98fe568668e4db732"
      ],
      "layout": "IPY_MODEL_3856954e8b1e47a08fce9fff7a038027"
     }
    },
    "ddf41c306dc441eb85beb6ea7bfbfedd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dffe3b78e72e4c309bda155884c2c7a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d9fb635e32cd4ed4bcddf6574de80b1b",
       "IPY_MODEL_1523672396354424b0658ce14786fbd2"
      ],
      "layout": "IPY_MODEL_00632d7b23cc45f59515669601334fcd"
     }
    },
    "e2be21b2cc584489b535309b9c8904e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fca884b72b1946cd8403edac7d41924e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8503f63352114056ace6ee5662d746da",
      "value": 1
     }
    },
    "e595378941654a4dbe560a646dc52272": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7ccb000bd83423fb4693a908c638ddb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e7fc29feb6d3404d83c1e455602d5c1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2d2b6b3effa34b809c30379c42c3c861",
       "IPY_MODEL_f46251823d4f4d219bffc095047f8867"
      ],
      "layout": "IPY_MODEL_ddf41c306dc441eb85beb6ea7bfbfedd"
     }
    },
    "e8fbc6f859784253a0cf6fe88cc0d9ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e941a8dd61c641c88445eb5497fd2760": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce7dc5c992754af5a545aa408ed67c88",
      "placeholder": "​",
      "style": "IPY_MODEL_63ff13ee95f64beea555e0660be15eec",
      "value": " 150/? [01:09&lt;00:00,  2.17it/s]"
     }
    },
    "e94b124aaf674431b6e424b9c6c1da87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e94c000d5060445ca93691f6af42e70c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed804e9c6fae4499aa3e6fef00f5de44": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f1010194505c44b588ba44a39e4afd9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f46251823d4f4d219bffc095047f8867": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d3ae70779e447d0aa495a9872209d38",
      "placeholder": "​",
      "style": "IPY_MODEL_04619e3db74847f5b637c7d2b1d5b8b8",
      "value": " 150/? [14:12&lt;00:00,  5.68s/it]"
     }
    },
    "f7dd810e69fa4f1f91acaec17fb8c64a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_940db33506ef463788996553c4bf5f74",
      "placeholder": "​",
      "style": "IPY_MODEL_268c4187cfc9490bacfa1eafe1fbcca1",
      "value": " 150/? [42:34&lt;00:00, 17.03s/it]"
     }
    },
    "f842c10d414f41c6846c1dc74200f301": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4800749f8151430c8cc49570cd4ccaf7",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8365405f8a1c4d178b5ab5cd9d905e32",
      "value": 1
     }
    },
    "fb5c1e7223ac4634a16c161784505836": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_471a09375e984a31824b27e279a6c4f3",
       "IPY_MODEL_27deb6f565ac4447a44770288071a0b8"
      ],
      "layout": "IPY_MODEL_7475bb3748de434eae59ef85715514da"
     }
    },
    "fca884b72b1946cd8403edac7d41924e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffc60b07ad704ea2afc0ac2c79c10c11": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
